{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"https://imalan6.github.io/hexo_blog","root":"/hexo_blog/"},"pages":[{"title":"about","date":"2024-02-12T13:28:14.000Z","updated":"2024-02-14T09:06:03.538Z","comments":false,"path":"about/index.html","permalink":"https://imalan6.github.io/hexo_blog/about/index.html","excerpt":"","text":"Alan，毕业于四川大学，计算机硕，程序猿。主要从事 Java 开发，架构设计，软件项目管理。热爱技术，喜欢研究解决技术问题。 业余爱好：运动健身，看书，电影，爬山。 座右铭：认真做人，踏实做事。 个人邮箱：&#51;&#54;&#x31;&#x35;&#50;&#x36;&#x30;&#53;&#53;&#x40;&#113;&#x71;&#x2e;&#99;&#111;&#109;"},{"title":"books","date":"2024-02-12T14:44:38.000Z","updated":"2024-02-13T08:32:38.870Z","comments":true,"path":"books/index.html","permalink":"https://imalan6.github.io/hexo_blog/books/index.html","excerpt":"","text":""},{"title":"categories","date":"2022-02-12T11:27:29.000Z","updated":"2024-02-12T11:54:47.595Z","comments":false,"path":"categories/index.html","permalink":"https://imalan6.github.io/hexo_blog/categories/index.html","excerpt":"","text":""},{"title":"links","date":"2024-02-12T14:42:23.000Z","updated":"2024-02-12T14:44:18.003Z","comments":false,"path":"links/index.html","permalink":"https://imalan6.github.io/hexo_blog/links/index.html","excerpt":"","text":""},{"title":"repository","date":"2024-02-12T13:23:03.000Z","updated":"2024-02-12T13:27:17.075Z","comments":false,"path":"repository/index.html","permalink":"https://imalan6.github.io/hexo_blog/repository/index.html","excerpt":"","text":""},{"title":"tags","date":"2024-02-12T13:21:10.000Z","updated":"2024-02-12T13:21:44.017Z","comments":false,"path":"tags/index.html","permalink":"https://imalan6.github.io/hexo_blog/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"用tushare和akshare获取股票历史行情和每日的成交明细","slug":"python/用tushare和akshare获取股票历史行情和每日的成交明细","date":"2024-01-06T15:16:21.000Z","updated":"2024-02-16T06:52:23.352Z","comments":false,"path":"2024/01/06/python/用tushare和akshare获取股票历史行情和每日的成交明细/","permalink":"https://imalan6.github.io/hexo_blog/2024/01/06/python/%E7%94%A8tushare%E5%92%8Cakshare%E8%8E%B7%E5%8F%96%E8%82%A1%E7%A5%A8%E5%8E%86%E5%8F%B2%E8%A1%8C%E6%83%85%E5%92%8C%E6%AF%8F%E6%97%A5%E7%9A%84%E6%88%90%E4%BA%A4%E6%98%8E%E7%BB%86/","excerpt":"","text":"朋友最近想要获取所有股票的每日逐笔成交明细用来分析，找我帮我。于是网上搜了一遍，发现免费提供这种功能的接口并不多，但也有一些。 其中，tu_share和akshare两个开源的金融工具包有类似接口，但也只能获取最近交易日的成交明细，没法获取所有的成交明细（历史+当日）。后来获取一次才发现，仅一个交易日的成交明细就高达1300多万条记录（还只是沪深A股），数据量太大了。所以，没有接口提供历史成交明细，也能理解了。 虽然没有成交明细，但可以获取历史日行情用于分析，tu_share的就可以。 tu_share有些接口需要充值获取积分才能调用，就是变相的付费接口。akshare是免费的，但只能获取最近交易日的成交明细。因此，两者综合一下，用tu_share获取历史每日行情，用akshare每天定时获取当日的成交明细。要分析历史成交明细就办不到了，只能分析以后的。 一、tu_share获取股票历史日行情1、tu_share介绍 tu_share是国内现有的免费数据接口中，比较好的股票&#x2F;基金数据获取方式。但新版的tushare pro对于提取数据有积分要求，具体要求详见tushare pro官网。 官方网站：https://tushare.pro/ 获取股票历史日行情，需要调用 行情数据—日线行情 接口，如下： 2、实现功能 这种调接口获取数据，再加工处理分析的，还是用python写比较方便快捷。同时，用之前 获取的股票列表依次批量获取。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 根据股票列表，开始/结束日期，获取股票成交明细def get_stock_data(stock_list, start_date, end_date): count = 0 while True: df = fetch_stock_data(stock_list, start_date, end_date) if df is not None and len(df) &gt; 0: print(&#x27;查询 &#123;&#125; 数据成功，共 &#123;&#125; 条&#x27;.format(stock_list, len(df))) to_mysql(df) break else: if count == 3: file = r&#x27;D:\\\\stock\\\\error.txt&#x27; with open(file, &#x27;a+&#x27;) as f: f.write(stock_list + &#x27;\\n&#x27;) # 加\\n换行显示 print(&#x27;查询 &#123;&#125; 数据失败，已记录...&#x27;.format(stock_list)) break else: print(&#x27;查询 &#123;&#125; 数据失败，共 &#123;&#125; 条&#x27;.format(stock_list, len(df))) print(&#x27;&#123;&#125;秒后重新获取...&#x27;.format(count * 5 + 5)) time.sleep(count * 5 + 5) count += 1# 调用tu_share日行情接口获取数据def fetch_stock_data(stock_list, start_date, end_date): # 初始化pro接口 pro = ts.pro_api(&#x27;2c69591b5e3e77669c4e4269a72620****************&#x27;) # 拉取数据 df = pro.daily(**&#123; &quot;ts_code&quot;: stock_list, &quot;trade_date&quot;: &quot;&quot;, &quot;start_date&quot;: start_date, &quot;end_date&quot;: end_date, &quot;offset&quot;: &quot;&quot;, &quot;limit&quot;: &quot;&quot; &#125;, fields=[ &quot;ts_code&quot;, &quot;trade_date&quot;, &quot;open&quot;, &quot;high&quot;, &quot;low&quot;, &quot;close&quot;, &quot;pre_close&quot;, &quot;change&quot;, &quot;pct_chg&quot;, &quot;vol&quot;, &quot;amount&quot; ]) return df 保存进mysql数据库，代码如下： 12345def to_mysql(dataframe): # 将数据存入数据库 engine = create_engine(&#x27;mysql://root:******@localhost:3306/a_stock?charset=utf8&#x27;) dataframe.to_sql(&#x27;stock_tu_daily&#x27;, con=engine, if_exists=&#x27;append&#x27;, index=False) print(&#x27;写入数据库成功！&#x27;) 不得不说，python写数据库真是太方便了，dataframe数据格式写数据库，一个to_sql函数直接搞定！！！ 4000多只股票（60&#x2F;00&#x2F;30开头的A股），从2017年1月1日 ~ 2024年1月1日，总共630多万条记录，也还好，不算多。 二、akshare获取当日逐笔成交明细1、akshare介绍 AKShare是基于 Python 的财经数据接口库，目的是实现对股票、期货、期权、基金、外汇、债券、指数、加密货币等金融产品的基本面数据、实时和历史行情数据、衍生数据从数据采集、数据清洗到数据落地的一套工具。akshare是完全免费的。 官方网址：https://akshare.akfamily.xyz/ 获取股票最近交易日成交明细，需要调用 历史分笔 数据接口： 2、实现功能 同样地，用之前获取的股票列表依次批量获取，代码如下： 123456789101112131415# 获取历史成交明细数据def get_data(engine, stock_list, index): stock_zh_a_tick_tx_js_df = ak.stock_zh_a_tick_tx_js(symbol=stock_list[index]) print(&quot;thread:&#123;&#125;, index:&#123;&#125;, code:&#123;&#125;, number:&#123;&#125;&quot;.format(threading.current_thread().name, index, stock_list[index], len(stock_zh_a_tick_tx_js_df))) try: stock_zh_a_tick_tx_js_df.columns = [&#x27;trade_time&#x27;, &#x27;trade_price&#x27;, &#x27;change&#x27;, &#x27;vol&#x27;, &#x27;amount&#x27;, &#x27;type&#x27;] stock_zh_a_tick_tx_js_df[&#x27;code&#x27;] = stock_list[index][2:] stock_zh_a_tick_tx_js_df[&#x27;trade_date&#x27;] = &#x27;2024-02-07&#x27; stock_zh_a_tick_tx_js_df.to_sql(&#x27;stock_ak_trade_detail&#x27;, con=engine, if_exists=&#x27;append&#x27;, index=False) print(&#x27;写入数据库成功！&#x27;) except Exception as e: print(e) 因为数据量太大，最好开个线程池多线程获取： 1234567891011121314 # 将数据存入数据库 engine = create_engine(&#x27;mysql://root:******@localhost:3306/a_stock?charset=utf8&#x27;) stock_list = pd.read_sql(sql=&quot;select code, market from stock_list where market != &#x27;&#x27;&quot;, con=engine) stock_list = (stock_list[&#x27;market&#x27;].str.lower()).str.cat(stock_list[&#x27;code&#x27;])# 创建线程池，开50个线程 threadPool = ThreadPoolExecutor(max_workers=50, thread_name_prefix=&quot;stock_&quot;) # 根据股票代码列表，循环依次获取数据 for i in range(len(stock_list)): threadPool.submit(get_data, engine, stock_list, i) threadPool.shutdown(wait=True) 一个交易日的成交明细数据量大概在1300万~1500万之间，耗时几十分钟。主要是接口返回数据太慢了，单次10来秒 ~ 一两分钟不等，可能跟IP访问频次有关，接口有一定限制。 现在问题来了，前期没想到数据量这么大，每日近1500万条记录，用Mysql存显然是不现实的。虽然表字段不多也不复杂，还添加了索引，几千万至上亿条记录也是没问题的。但是随着时间增长，可能再过一两周问题就出现了。得尽快考虑新的存储方式。","categories":[{"name":"python","slug":"python","permalink":"https://imalan6.github.io/hexo_blog/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://imalan6.github.io/hexo_blog/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"用python爬股票列表数据","slug":"python/用python爬股票列表数据","date":"2024-01-02T05:12:33.000Z","updated":"2024-02-15T11:54:51.642Z","comments":false,"path":"2024/01/02/python/用python爬股票列表数据/","permalink":"https://imalan6.github.io/hexo_blog/2024/01/02/python/%E7%94%A8python%E7%88%AC%E8%82%A1%E7%A5%A8%E5%88%97%E8%A1%A8%E6%95%B0%E6%8D%AE/","excerpt":"","text":"最近帮一个做金融的朋友爬股票数据。网上找遍了居然没有免费获取A股列表的接口，没办法只能去股票网站爬数据。 一、访问目标网站同花顺行情中心：https://q.10jqka.com.cn/，打开开发者工具，查看代码，找到数据所在位置。有股票名称，代码，相关属性 但是在爬取过程中发现一个问题：程序自动打开的浏览器，程序模拟点击下一页，网页没有任何反应，一直卡住。但是手动打开网站，下一页是可以点击的。估计是网站做了反爬虫处理。 既然手动打开浏览器访问一切正常，那就换个思路：先手动打开浏览器访问，再用selenium连接已经打开的浏览器操作就可以了。 二、用selenium连接已经打开的浏览器通过 selenium 连接浏览器，需要用到两个参数 –remote-debugging-port 和 –user-data-dir --remote-debugging-port 这个参数允许通过远程的方式连接，selenium 当然也可以。 --user-data-dir 这个参数指定一个目录存放用户数据，在连接时也要设置，否则会失效。 1、通过命令行打开浏览器： 1chrome.exe --remote-debugging-port=9222 --user-data-dir=&quot;C:\\selenium\\ChromeProfile&quot; 2、快捷方式设置参数 用命令行打开浏览器不常用，可以在 chrome 的快捷方式上添加参数。右击快捷方式，选择属性，在目标栏后面加上： 1--remote-debugging-port=9222 --user-data-dir=&quot;C:\\selenium\\ChromeProfile&quot; 现在，通过快捷方式直接打开浏览器也可以远程调试了。 3、selenium操作浏览器时，记得加上参数 options.add_experimental_option(“debuggerAddress”, “127.0.0.1:9222”)，关键代码如下： 1234567891011121314151617181920212223def selenium_url_chrome(url, id, stock_values): # 谷歌浏览器位置 chrome_location = r&#x27;C:\\Users\\admin\\Downloads\\chrome-win64\\chrome.exe&#x27; # 谷歌浏览器驱动地址 service = Service(&#x27;D:\\chromedriver.exe&#x27;) # 创建option对象 options = Options() # 指定连接端口 options.add_experimental_option(&quot;debuggerAddress&quot;, &quot;127.0.0.1:9222&quot;) options.binary_location = chrome_location driver = webdriver.Chrome(options=options, service=service) # 访问指定的url地址 driver.get(url) # 等待指定元素加载成功 WebDriverWait(driver, 10).until(EC.visibility_of(driver.find_element(by=By.ID, value=&#x27;maincont&#x27;))) return get_data(driver, driver.page_source, id, stock_values) 4、解析元素，抓取数据，关键代码如下： 123456789101112131415161718192021222324252627282930313233343536373839def get_data(driver, html_text, id, stock_values): bs = BeautifulSoup(html_text, &quot;html.parser&quot;) # 创建BeautifulSoup对象 body = bs.body # 获取body部分 data = body.find(&#x27;div&#x27;, &#123;&#x27;id&#x27;: &#x27;maincont&#x27;&#125;) tbody = data.find(&#x27;table&#x27;) # 获取ul部分 trs = tbody.find_all(&#x27;tr&#x27;) # 获取所有的li stock_value_temp = [] for tr in trs: # 对每个li标签中的内容进行遍历 tds = tr.find_all(&#x27;td&#x27;) if len(tds) == 0: continue if tds[1].text.startswith(&#x27;60&#x27;): # 代码60开头的是上海市场 market = &#x27;SH&#x27; elif tds[1].text.startswith(&#x27;30&#x27;) or tds[1].text.startswith(&#x27;00&#x27;): # 代码00、30开头的是深圳市场 market = &#x27;SZ&#x27; else: market = &#x27;&#x27; stock_value_temp.append((id, tds[1].text, market, tds[2].text, tds[12].text, tds[13].text, &#x27;2024-01-02&#x27;, 0)) stock_values.append((id, tds[1].text, market, tds[2].text, tds[12].text, tds[13].text, &#x27;2024-01-02&#x27;, 0)) id += 1 print(&#x27;第 &#123;&#125; 页数据 &#123;&#125;：&#x27;.format(math.floor(id / 20), stock_value_temp)) # 写入excel表格 excel.write_excel_xlsx_append(&#x27;D:\\\\stock\\\\stock.xlsx&#x27;, stock_value_temp) try: el = driver.find_element(By.XPATH, &quot;//a[contains(text(),&#x27;下一页&#x27;)]&quot;) # driver.execute_script(&quot;arguments[0].click();&quot;, el) el.click() except: raise CustomError(&quot;已到最后一页&quot;) WebDriverWait(driver, 5).until(EC.visibility_of(driver.find_element(by=By.ID, value=&#x27;maincont&#x27;))) time.sleep(0.5) 5、同时保存进数据库mysql中，关键代码： 1234567891011121314151617181920def insert_data(stock_values): # 打开数据库连接 try: db = pymysql.connect(host=&#x27;localhost&#x27;, user=&#x27;root&#x27;, passwd=&#x27;888888&#x27;, port=3306, db=&#x27;a_stock&#x27;) print(&#x27;连接数据库成功！&#x27;) except Exception as e: print(&quot;pymysql数据库连接异常：&quot;, e) # 使用 cursor() 方法创建一个游标对象 cursor cursor = db.cursor() try: # 执行sql语句 cursor.executemany(&#x27;INSERT INTO stock_list(id, code, market, name, pe, ltsz, date, del) values(%s, %s, %s, %s, %s, %s, %s, %s)&#x27;, stock_values) # 提交到数据库执行 db.commit() print(&#x27;数据插入数据库成功！&#x27;) except Exception as e: print(&quot;数据库异常：&quot;, e)","categories":[{"name":"python","slug":"python","permalink":"https://imalan6.github.io/hexo_blog/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://imalan6.github.io/hexo_blog/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"用python爬china_radio音频","slug":"python/用python爬china_radio音频","date":"2023-03-02T05:12:33.000Z","updated":"2024-02-15T11:30:02.121Z","comments":false,"path":"2023/03/02/python/用python爬china_radio音频/","permalink":"https://imalan6.github.io/hexo_blog/2023/03/02/python/%E7%94%A8python%E7%88%ACchina_radio%E9%9F%B3%E9%A2%91/","excerpt":"","text":"最近练英语听力，感觉china_radio的roundtable圆桌会议节目不错，但是音频没法下载，于是准备爬虫获取。 1、音频网址：https://chinaplus.cri.cn/podcast/list/10 ，打开chrome开发者工具查看html代码，找到音频链接。这个还是比较简单，没有动态加载，直接就有mp3链接。 2、准备写抓取代码。由于页面每次显示10条，需要点击下方的more按钮，才能继续加载。于是采用selenium模拟手动点击按钮（喜欢用模拟手动操作网页，可以避免很多反爬虫）。需要先安装selenium模拟操作网页环境，见文章 模拟点击页面关键代码如下： 12345678910111213141516171819202122232425262728293031323334def get_html_by_selenium_chrome(url): # 谷歌浏览器位置 chrome_location = r&#x27;C:\\Users\\admin\\Downloads\\chrome-win64\\chrome.exe&#x27; # 谷歌浏览器驱动地址 service = Service(&#x27;D:\\chromedriver.exe&#x27;) options = Options() options.binary_location = chrome_location # 指定chrome的路径 options.add_argument(&#x27;–-incognito&#x27;) options.add_argument(&#x27;--disable-infobars&#x27;) options.add_argument(&#x27;--start-maximized&#x27;) # 创建一个浏览器对象 driver = webdriver.Chrome(options=options, service=service) # 访问指定的url地址 driver.get(url) # 等待指定id元素加载完成，表示网页内容加载完成 WebDriverWait(driver, 10).until(EC.visibility_of(driver.find_element(by=By.ID, value=&#x27;js-podcastList-right-latestEpisodes&#x27;))) # 循环点击加载更多按钮，每次加载10条，想抓取多少，就循环多少次 for i in range(5): # 获取more元素 el = driver.find_element(By.XPATH, &quot;//span[contains(text(),&#x27;Load more&#x27;)]&quot;) # js模拟点击，selenium原生点击不成功 driver.execute_script(&quot;arguments[0].click();&quot;, el) time.sleep(1) return driver.page_source 采用原生的BeautifulSoup解析页面，获取音频关键代码如下： 123456789101112131415161718192021222324def parse_html(html_text): final = [] bs = BeautifulSoup(html_text, &quot;html.parser&quot;) # 创建BeautifulSoup对象 body = bs.body # 获取body部分 data = body.find(&#x27;div&#x27;, &#123;&#x27;id&#x27;: &#x27;js-podcastList-right-latestEpisodes&#x27;&#125;) # 找到id为js-podcastList-right-latestEpisodes的div ul = data.find(&#x27;ul&#x27;) # 获取ul部分 li = ul.find_all(&#x27;li&#x27;) # 获取所有的li store_res.mkdir(&#x27;D:\\\\&#x27;, &#x27;china_radio&#x27;) for day in li: # 对每个li标签中的内容进行遍历 date = day.find(&#x27;span&#x27;, &#123;&#x27;class&#x27;: &#x27;js-latestEpisodes-item-time&#x27;&#125;) # 获取日期 store_res.mkdir(&#x27;D:\\\\china_radio\\\\&#x27;, date.text) # 按日期建文件夹 play_div = day.find(&#x27;div&#x27;, &#123;&#x27;class&#x27;: &#x27;js-latestEpisodes-item-playBtn play&#x27;&#125;) mp3_file = play_div.get(&#x27;data-url&#x27;) # 获取音频 print(mp3_file) introduction = day.find(&#x27;p&#x27;, &#123;&#x27;class&#x27;: &#x27;js-latestEpisodes-item-info&#x27;&#125;) # 获取介绍 # 音频介绍存入文件中 store_res.create_txt_file(&#x27;introduction&#x27;, &#x27;D:\\\\china_radio\\\\&#x27; + date.text, introduction.contents[0].text)","categories":[{"name":"python","slug":"python","permalink":"https://imalan6.github.io/hexo_blog/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://imalan6.github.io/hexo_blog/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"kafka集群部署（无zookeep方式）","slug":"kafka/kafka集群部署","date":"2022-11-18T14:26:17.000Z","updated":"2024-02-14T12:11:38.233Z","comments":false,"path":"2022/11/18/kafka/kafka集群部署/","permalink":"https://imalan6.github.io/hexo_blog/2022/11/18/kafka/kafka%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"","text":"kafka部署docker安装kafka集群1、docker-compose 安装带kafka-ui的kafka集群kafka2.8版本以后可以采用kraft协议，不再需要zookeeper。安装kafka-3.3.1（不带zookeeper版本）的集群。仅需将下面配置中的192.168.101.103 改为自己本机的ip即可。docker-compose-kafka-cluster.yml配置文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144version: &quot;3&quot;services: #kafka可视化工具 kafka-ui: container_name: kafka-ui image: provectuslabs/kafka-ui:latest ports: - 8989:8080 depends_on: - kafka1 - kafka2 - kafka3 environment: - KAFKA_CLUSTERS_0_NAME=kafkaCluster - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=192.168.101.103:9192,192.168.101.103:9292,192.168.101.103:9392 - DYNAMIC_CONFIG_ENABLED=true networks: - mynetwork # kafka集群 kafka1: image: &#x27;bitnami/kafka:3.3.1&#x27; container_name: kafka1 user: root ports: - 9192:9092 - 9193:9093 environment: ### 通用配置 # 允许使用kraft，即Kafka替代Zookeeper - KAFKA_ENABLE_KRAFT=yes # kafka角色，做broker，也要做controller - KAFKA_CFG_PROCESS_ROLES=broker,controller # 指定供外部使用的控制类请求信息 - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER # 定义kafka服务端socket监听端口 - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 # 定义安全协议 - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT # 使用Kafka时的集群id，集群内的Kafka都要用这个id做初始化，生成一个UUID即可 - KAFKA_KRAFT_CLUSTER_ID=LelM2dIFQkiUFvXCEcqRWA # 集群地址 - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9093,3@kafka3:9093 # 允许使用PLAINTEXT监听器，默认false，不建议在生产环境使用 - ALLOW_PLAINTEXT_LISTENER=yes # 设置broker最大内存，和初始内存 - KAFKA_HEAP_OPTS=-Xmx512M -Xms256M # 允许自动创建主题 - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true # 消息保留时长（毫秒），保留7天 - KAFKA_LOG_RETENTION_MS=604800000 ### broker配置 # 定义外网访问地址（宿主机ip地址和端口） - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.101.103:9192 # broker.id，必须唯一 - KAFKA_BROKER_ID=1 volumes: - /data/bitnami/kafka1:/bitnami/kafka networks: - mynetwork kafka2: image: &#x27;bitnami/kafka:3.3.1&#x27; container_name: kafka2 user: root ports: - 9292:9092 - 9293:9093 environment: ### 通用配置 # 允许使用kraft，即Kafka替代Zookeeper - KAFKA_ENABLE_KRAFT=yes # kafka角色，做broker，也要做controller - KAFKA_CFG_PROCESS_ROLES=broker,controller # 指定供外部使用的控制类请求信息 - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER # 定义kafka服务端socket监听端口 - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 # 定义安全协议 - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT # 使用Kafka时的集群id，集群内的Kafka都要用这个id做初始化，生成一个UUID即可 - KAFKA_KRAFT_CLUSTER_ID=LelM2dIFQkiUFvXCEcqRWA # 集群地址 - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9093,3@kafka3:9093 # 允许使用PLAINTEXT监听器，默认false，不建议在生产环境使用 - ALLOW_PLAINTEXT_LISTENER=yes # 设置broker最大内存，和初始内存 - KAFKA_HEAP_OPTS=-Xmx512M -Xms256M # 允许自动创建主题 - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true # 消息保留时长（毫秒），保留7天 - KAFKA_LOG_RETENTION_MS=604800000 ### broker配置 # 定义外网访问地址（宿主机ip地址和端口） - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.101.103:9292 # broker.id，必须唯一 - KAFKA_BROKER_ID=2 volumes: - /data/bitnami/kafka2:/bitnami/kafka networks: - mynetwork kafka3: image: &#x27;bitnami/kafka:3.3.1&#x27; container_name: kafka3 user: root ports: - 9392:9092 - 9393:9093 environment: ### 通用配置 # 允许使用kraft，即Kafka替代Zookeeper - KAFKA_ENABLE_KRAFT=yes # kafka角色，做broker，也要做controller - KAFKA_CFG_PROCESS_ROLES=broker,controller # 指定供外部使用的控制类请求信息 - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER # 定义kafka服务端socket监听端口 - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 # 定义安全协议 - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT # 使用Kafka时的集群id，集群内的Kafka都要用这个id做初始化，生成一个UUID即可 - KAFKA_KRAFT_CLUSTER_ID=LelM2dIFQkiUFvXCEcqRWA # 集群地址 - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9093,3@kafka3:9093 # 允许使用PLAINTEXT监听器，默认false，不建议在生产环境使用 - ALLOW_PLAINTEXT_LISTENER=yes # 设置broker最大内存，和初始内存 - KAFKA_HEAP_OPTS=-Xmx512M -Xms256M # 允许自动创建主题 - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true # 消息保留时长（毫秒），保留7天 - KAFKA_LOG_RETENTION_MS=604800000 ### broker配置 # 定义外网访问地址（宿主机ip地址和端口） - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.101.103:9392 # broker.id，必须唯一 - KAFKA_BROKER_ID=3 volumes: - /data/bitnami/kafka3:/bitnami/kafka networks: - mynetworknetworks: mynetwork: driver: bridge 执行命令，启动容器： 1docker-compose -f docker-compose-kafka-cluster.yml up -d 2、安装滴滴开源Kafka UI管理工具knowstreaminghttps://doc.knowstreaming.com/","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"},{"name":"kafka","slug":"kafka","permalink":"https://imalan6.github.io/hexo_blog/tags/kafka/"}]},{"title":"kafka数据可靠性","slug":"kafka/kafka发送数据可靠性","date":"2022-11-10T15:12:33.000Z","updated":"2024-02-14T12:12:32.241Z","comments":false,"path":"2022/11/10/kafka/kafka发送数据可靠性/","permalink":"https://imalan6.github.io/hexo_blog/2022/11/10/kafka/kafka%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7/","excerpt":"","text":"配置参数Kafka有两个很重要的配置参数：acks 与 min.insync.replicas 。其中，acks 是producer的配置参数，而 min.insync.replicas 是broker端的配置参数。这两个参数对于生产者发送数据的可靠性起了很大的作用。 kafka 分区副本kafka 的topic是可以分区的，并且可以为分区配置多个副本，改配置可以通过 replication.factor 参数实现。 Kafka中的分区副本包括两种类型：领导者副本（Leader Replica）和追随者副本（Follower Replica)，每个分区在创建时都要选举一个副本作为领导者副本，其余的副本自动变为追随者副本。 在Kafka中，追随者副本是不对外提供服务的，也就是说，追随者副本不能响应消费者和生产者的读写请求。所有的请求都必须由领导者副本来处理。换句话说，所有的读写请求都必须发往领导者副本所在的Broker，由该 Broker 负责处理。 追随者副本不处理客户端请求，它唯一的任务就是从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。 Kafka默认的副本因子是3，即每个分区只有1个leader副本和2个follower副本。具体如下图所示： 上面提到生产者客户端仅写入Leader broker，跟随者异步复制数据。由于Kafka是一个分布式系统，必然会存在与 Leader 不能实时同步的风险，所以需要一种方法来判断这些追随者是否跟上了领导者的步伐，即追随者是否同步了最新的数据。换句话说，Kafka 要明确地告诉我们，追随者副本到底在什么条件下才算与 Leader 同步？这就是下面所要说的ISR同步副本机制。 同步副本(In-sync replicas)In-sync replica (ISR) 称之为同步副本，ISR中的副本都是与Leader进行同步的副本，所以不在该列表的 follower 会被认为与 Leader 是不同步的。那么，ISR中存在是什么副本呢？首先可以明确的是：Leader副本总是存在于ISR中。而 follower 副本是否在ISR中，取决于该follower副本是否与Leader副本保持了“同步”。 对于”follower副本是否与Leader副本保持了同步”的理解如下：1）上面所说的同步不是指完全的同步，即并不是说一旦follower副本同步滞后与Leader副本，就会被踢出ISR列表。2）Kafka的broker端有一个参数replica.lag.time.max.ms, 该参数表示follower副本滞后与Leader副本的最长时间间隔，默认是10秒. 这就意味着，只要follower副本落后于leader副本的时间间隔不超过10秒，就可以认为该follower副本与leader副本是同步的，所以哪怕当前follower副本落后于Leader副本几条消息，只要在10秒之内赶上Leader副本，就不会被踢出出局。3）如果follower副本被踢出ISR列表，等到该副本追上了Leader副本的进度，该副本会被再次加入到ISR列表中，所以ISR是一个动态列表，并不是静态不变的。 如上图所示：Broker3 上的 partition1 副本超过了规定时间，未与 Leader 副本同步，所以被踢出ISR列表，此时的ISR为[1,3]。 acks确认机制acks 参数指定了必须要有多少个分区副本收到消息，生产者才认为该消息是写入成功的，这个参数对于消息是否丢失起着重要作用，该参数的配置具体如下： acks &#x3D; 0，表示生产者在成功写入消息之前不会等待任何来自服务器的响应。换句话说，一旦出现了问题导致服务器没有收到消息，那么生产者就无从得知，消息也就丢失了。该配置由于不需要等到服务器的响应，所以可以最大速度发送消息，达到很高的吞吐量。 acks &#x3D; 1，表示只要集群的leader分区副本接收到了消息，就会向生产者发送一个成功响应的ack，此时生产者接收到 ack 之后就可以认为该消息是写入成功的。如果消息无法写入 leader 分区副本（比如网络原因、leader 节点崩溃），生产者会收到一个错误响应。当生产者接收到该错误响应之后，为了避免数据丢失，会重新发送数据。注意：如果生产者收到了错误响应，即便是重新发消息，还是会有可能出现丢数据的现象。比如，如果一个没有收到消息的节点成为了新的Leader，消息就可能丢失。 acks &#x3D; all，表示只有所有参与复制的节点（ISR列表的副本）全部收到消息后，生产者才会接收到来自服务器的 ack 响应。这种模式是最高级别的，也是最安全的，可以确保不止一个Broker接收到了消息。但该模式的延迟很高。 最小同步副本上面提到，当acks &#x3D; all时，需要所有的副本都同步了才会发送成功响应到生产者。其实这里面存在一个问题：如果Leader副本是唯一的同步副本时，此时相当于acks &#x3D; 1，所以也是不安全的。 Kafka 的 Broker 端提供了一个参数 min.insync.replicas，该参数控制的是消息至少被写入到多少个副本才算是”真正写入”。该值默认值为1，生产环境设定为一个大于1的值可以提升消息数据可靠性。如果同步副本的数量低于该配置值，生产者会收到错误响应，可以确保消息不丢失。 场景 1如下图，当 min.insync.replicas &#x3D; 2 且 acks &#x3D; all 时，如果此时ISR列表只有[1,2],3被踢出ISR列表，只需要保证两个副本同步了，生产者就会收到成功响应. 场景 2如下图，当 min.insync.replicas &#x3D; 2，如果此时ISR列表只有 [1]，而 2 和 3 被踢出ISR列表：那么，当 acks &#x3D; all 时，则不能成功写入数据；当 acks &#x3D; 0 或者 acks &#x3D; 1 可以成功写入数据。 场景 3如果 acks &#x3D; all 且 min.insync.replicas &#x3D; 2，此时ISR列表为[1,2,3]，那么还是会等到所有的同步副本都同步了消息，才会向生产者发送成功响应的ack。因为 min.insync.replicas &#x3D; 2 只是一个最低限制，即同步副本少于该配置值，则会抛异常；而 acks &#x3D; all，是需要保证所有的ISR列表的副本都同步了才可以发送成功响应。这种情况是很容易引起误解的。如下图所示： 总结acks &#x3D; 0 时，生产者在成功写入消息之前不会等待任何来自服务器的响应。 acks &#x3D; 1 时，只要集群的leader分区副本接收到了消息，就会向生产者发送一个成功响应的ack。 acks &#x3D; all 时，只有所有参与复制的节点(ISR列表的副本)全部收到消息时，生产者才会接收到来自服务器的响应，此时如果ISR同步副本的个数小于min.insync.replicas的值，消息不会被写入。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://imalan6.github.io/hexo_blog/tags/kafka/"}]},{"title":"Nginx反向代理集群部署","slug":"nginx/Nginx反向代理集群部署","date":"2021-06-22T08:23:12.000Z","updated":"2024-02-14T12:06:55.817Z","comments":false,"path":"2021/06/22/nginx/Nginx反向代理集群部署/","permalink":"https://imalan6.github.io/hexo_blog/2021/06/22/nginx/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"","text":"Nginx反向代理集群部署概述NginxNginx是一款非常优秀的反向代理工具，支持请求分发，负载均衡，以及缓存等。在请求处理上，Nginx采用epoll模型，这是一种基于事件监听的模型，因而其具备非常高效的请求处理效率，单机并发能力能够达到百万。Nginx接收到的请求可以通过负载均衡策略分发到其下一级应用服务器。对于一些特大型的网站，单机的Nginx并发能力是有限的，而Nginx本身并不支持集群模式，因而对Nginx的横向扩展显得尤为重要。 KeepalivedKeepalived是一款服务器状态检测和故障切换的工具。在其配置文件中，可以配置主备服务器和该服务器的状态检测请求。Keepalived起初是专为LVS负载均衡软件设计的，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用的VRRP功能。因此，Keepalived除了能够管理LVS软件外，还可以用于解决其他服务的高可用解决方案。 Keepalived主要是通过VRRP协议实现高可用功能的。VRRP是Virtual Router Redundancy Protocol（虚拟路由冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由的单点故障问题，它能保证当个别节点宕机时，整个网络可以不间断地运行。所以，Keepalived一方面具有配置管理LVS的功能，同时还具有对LVS下面节点进行健康检查的功能，另一方面也可以实现系统网络服务的高可用功能。 Keepalived的高可用服务的故障切换转移功能，是通过VRRP来实现的。在Keepalived服务工作时，主Master节点会不断地向备节点发送（多播的方式）心跳消息，用来告诉备Backup节点自己还活着。当主节点发生故障时，就无法发送心跳的消息了，备节点也因此无法继续检测到来自主节点的心跳了。于是就会调用自身的接管程序，接管主节点的IP资源和服务。当主节点恢复时，备节点又会释放主节点故障时自身接管的IP资源和服务，恢复到原来的备用角色。 结构图 集群部署安装Keepalived+Nginx选择两台服务器，这里使用的是centos7，安装Keepalived和Nginx。 安装Keepalived： 1yum -y install keepalived 运行Keepalived： 1systemctl start keepalived 安装Nginx： 1yum -y install nginx 运行Nginx： 1systemctl start nginx 配置文件Master服务器配置文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243! Configuration File for Keepalivedglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr #vrrp_strict #此处不注释掉，无法ping通VIP vrrp_garp_interval 0 vrrp_gna_interval 0&#125;#监控Nginx进程状态的脚本vrrp_script check_nginx &#123; script &quot;/usr/local/server/check_nginx.sh&quot; interval 2 weight 2&#125;vrrp_instance VI_1 &#123; state MASTER #master为master，backup则为backup interface ens33 #修改为实际的网卡 virtual_router_id 51 #此处MASTER和BACKUP必须一致，但是和局域网中其他的keeplived集群不能相同 priority 100 #数字越大，优先级越高。master高于其他 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script &#123; #执行监控Nginx进程脚本 check_nginx &#125; virtual_ipaddress &#123; 192.168.0.8 #虚拟IP地址，可以配置多个 &#125;&#125; Backup服务器配置文件(仅列不同项)： 12state BACKUP #master为master，backup则为backup priority 80 #数字越大，优先级越高。master高于其他 Keepalived配置文件中加了注释符号#的配置项需要修改，其余的可以不变。主要修改项如下： router_id 是路由标识，在一个局域网里面应该是唯一的 vrrp_instance VI_1&#123;...&#125;是一个VRRP实例，里面定义了Keepalived的主备状态、接口、优先级、认证和IP信息 state 定义了VRRP的角色 interface定义使用的接口，这里的网卡都ens33，根据实际填写 virtual_router_id是虚拟路由ID标识，一组的Keepalived配置中主备都是一致的 priority是优先级，数字越大，优先级越高 auth_type是认证方式 auth_pass是认证的密码 virtual_ipaddress｛...｝定义虚拟IP地址，可以配置多个IP地址，这里定义为192.168.0.8 脚本文件注意，上面配置文件中的脚本配置 123456#监控Nginx进程状态的脚本vrrp_script check_nginx &#123; script &quot;/usr/local/server/check_nginx.sh&quot; interval 2 weight 2&#125; 其中的脚本文件”/usr/local/server/check_nginx.sh“，用于检查Nginx状态，内容如下： 1234567891011121314#!/bin/shnginxpid=$(ps -C nginx --no-header|wc -l)#判断Nginx是否存活，如果不存活则尝试启动Nginxif [ $nginxpid -eq 0 ];then systemctl start nginx sleep 2 #等待2秒后，再次查看Nginx是否启动 nginxpid=$(ps -C nginx --no-header|wc -l) #如果Nginx还是没启动，停止Keepalived，让地址漂移到其他Nginx if [ $nginxpid -eq 0 ];then systemctl stop keepalived fifi 作用是检查Nginx进程是否存活，如果不存活就启动Nginx，并且2秒后再次检查，如果还是不存活，说明启动Nginx失败，然后关闭Keepalived服务，把虚拟地址转移给其他Nginx服务(backup)。 但是需要注意：在使用时，发现有一台服务器的Nginx服务启动后有4个Nginx进程，而Nginx服务关闭后，仍然存在2个Nginx进程，另外一台是正常的，可能是安装是出现问题。 Nginx服务启动后： 12345[root@192 ~]# ps aux | grep nginxroot 22177 0.0 0.0 10648 3392 ? Ss 14:00 0:00 nginx: master process nginx -g daemon off;101 22230 0.0 0.0 11088 1484 ? S 14:00 0:00 nginx: worker processroot 22365 0.0 0.0 105496 1976 ? Ss 14:02 0:00 nginx: master process /usr/sbin/nginxNginx 22366 0.0 0.0 108048 3376 ? S 14:02 0:00 nginx: worker process Nginx服务关闭后： 123[root@192 ~]# ps aux | grep nginxroot 22177 0.0 0.0 10648 3392 ? Ss 14:00 0:00 nginx: master process nginx -g daemon off;101 22230 0.0 0.0 11088 1484 ? S 14:00 0:00 nginx: worker process 所以针对这台服务器，使用上面的Nginx状态检查脚本，就无法正常检测出Nginx是否存活。因为当关闭Nginx服务后，脚本中的 “ps -C Nginx --no-header|wc -l“ 语句仍然返回2，而不是0，也就不会执行后面启动Nginx的命令了。这时，就需要修改脚本，保证能正常检测Nginx是否存活。 测试修改Nginx服务器的html主页文件”/usr/share/Nginx/html/index.html“，在master和backup上分别加入区分描述，用于测试使用。 分别启动master和backup服务器上的Nginx和Keepalived服务，浏览器访问http://192.168.0.8，返回如下： 然后关闭master服务器上的Nginx和Keepalived服务，返回如下：","categories":[{"name":"开源组件","slug":"开源组件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://imalan6.github.io/hexo_blog/tags/nginx/"}]},{"title":"生产环境系统运行缓慢问题排查","slug":"jvm/生产环境系统运行缓慢问题排查","date":"2021-06-21T15:05:22.000Z","updated":"2024-02-14T11:20:05.185Z","comments":false,"path":"2021/06/21/jvm/生产环境系统运行缓慢问题排查/","permalink":"https://imalan6.github.io/hexo_blog/2021/06/21/jvm/%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E7%B3%BB%E7%BB%9F%E8%BF%90%E8%A1%8C%E7%BC%93%E6%85%A2%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","excerpt":"","text":"生产环境系统运行缓慢问题排查主要问题线上环境可能出现系统突然运行缓慢，甚至可能导致线上系统不可用。如果遇到这样的情况，首先需要导出jstack日志和内存信息，然后重启系统，保证系统的可用性。这种情况可能的原因有： 代码中某个位置读取数据量较大，导致系统内存耗尽，从而导致Full GC次数过多，系统缓慢； 代码中存在耗时计算，导致 CPU 占用过高，系统运行缓慢； 以上两种是出现频率最高的情况，可能直接导致系统不可用。另外几种情况也可能导致系统运行缓慢： 代码某个位置有阻塞性操作，导致该功能调用比较耗时，但这样情况比较随机； 某个线程由于某种原因进入WAITING状态，此时该功能整体不可用，但无法复现； 由于锁使用不当，使得多个线程进入死锁状态，导致系统整体运行比较缓慢。 对于这几种情况，通过查看 CPU 和系统内存是无法检查出具体问题的，因为可能 CPU 和系统内存使用情况都不高，但是系统却很慢。遇到这些情况，只有分析系统日志来排查。 Full GC次数过多相对来说，这种情况是最容易出现的，尤其是新功能上线时。对于Full GC较多的情况，其主要有如下两个特征： 线上多个线程 CPU 占用率都超过了 100%，通过jstack命令可以看到这些线程主要是垃圾回收线程； 通过jstat命令监控GC情况，可以看到Full GC次数非常多，且次数在不断增加。 首先，我们使用top命令查看系统 CPU 的占用情况，如下是系统 CPU 较高的一个情况： 123456top - 08:31:10 up 30 min, 0 users, load average: 0.73, 0.58, 0.34KiB Mem: 2046460 total, 1923864 used, 122596 free, 14388 buffersKiB Swap: 1048572 total, 0 used, 1048572 free. 1192352 cached MemPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND9 root 20 0 2557160 288976 15812 S 98.0 14.1 0:42.60 java 从结果可以看出，有一个进程为 9 的 java应用，它的 CPU 占用率达到了 98.8%，这是很不正常的情况。然后使用如下命令查看下该进程的各个线程运行情况： 1top -Hp 9 该进程下的各个线程运行情况如下： 可以看到进程为9的 Java 程序中各个线程的 CPU 占用情况，然后通过jstack命令查看线程 id 为 10 的线程为什么耗费 CPU 最高。需要注意的是，在jsatck命令展示的结果中，线程 id 都转换成了十六进制形式，可以用如下命令转换： 123printf &quot;%x\\n&quot; 10a 十六进制形式的线程 id 的为 0xa，然后在jstack命令输出结果中查找对应的线程信息： 找到nid=0xa的线程，这里nid的意思就是操作系统线程 id 的意思。可以看到线程名称是VM Thread，而VM Thread指的就是垃圾回收的线程。这里我们基本上可以确定，当前系统缓慢的原因主要是垃圾回收过于频繁，导致GC停顿时间较长。通过如下命令可以查看GC的情况： 可以看到，这里FGC指的是Full GC数量，高达6793，而且还在不断增长。从而进一步证实了是由于内存溢出导致的系统缓慢。那么确认了内存溢出，但是如何查看是哪些对象导致的内存溢出呢，可以dump出内存日志，然后通过eclipse的MAT工具进行查看，如下是其展示的一个对象树结构： 经过MAT工具分析，基本上能确定内存中主要是哪个对象比较消耗内存，然后找到该对象的创建位置，进行处理即可。这里主要是PrintStream最多，但是其内存消耗量也只有 12.2%，也就是说，其还不足以导致大量的Full GC，此时我们需要考虑另外一种情况，就是代码或者第三方依赖的包中有显示的System.gc()调用。这种情况我们查看dump内存得到的文件即可判断，因为其会打印GC原因： 12[Full GC (System.gc()) [Tenured: 262546K-&gt;262546K(349568K), 0.0014879 secs] 262546K-&gt;262546K(506816K), [Metaspace: 3109K-&gt;3109K(1056768K)], 0.0015151 secs] [Times: user=0.00 sys=0.00, real=0.01 secs][GC (Allocation Failure) [DefNew: 2795K-&gt;0K(157248K), 0.0001504 secs][Tenured: 262546K-&gt;402K(349568K), 0.0012949 secs] 265342K-&gt;402K(506816K), [Metaspace: 3109K-&gt;3109K(1056768K)], 0.0014699 secs] [Times: user=0.00 比如这里第一次GC是由于System.gc()的显示调用导致的，而第二次GC则是JVM主动发起的。总结来说，对于Full GC次数过多，主要有以下两种原因： 代码中一次获取了大量的对象，导致内存溢出，此时可以通过eclipse的MAT工具查看内存中有哪些对象比较多； 内存占用不高，但是Full GC次数比较多，此时可能存在显示调用System.gc()导致GC次数过多，可以通过添加-XX:+DisableExplicitGC参数来禁用JVM对显示GC的响应。 CPU占用过高CPU 过高可能是系统频繁地进行Full GC，导致系统缓慢。而我们平常也肯能遇到比较耗时的计算，导致 CPU 过高的情况，此时查看方式其实与上面的非常类似。首先我们通过top命令查看当前 CPU 消耗过高的进程是哪个，从而得到进程 id；然后通过top -Hp &lt;pid&gt;来查看该进程中有哪些线程 CPU 过高，一般超过 80%就是比较高的，80% 左右是合理情况。这样我们就能得到 CPU 消耗比较高的线程 id。接着通过该 线程 id 的十六进制表示在jstack日志中查看当前线程具体的堆栈信息。 在这里就可以区分导致 CPU 过高的原因具体是Full GC次数过多还是代码中有比较耗时的计算了。如果是Full GC次数过多，那么通过jstack得到的线程信息会是类似于VM Thread之类的线程，而如果是代码中有比较耗时的计算，那么我们得到的就是一个线程的具体堆栈信息。如下是一个代码中有比较耗时的计算，导致 CPU 过高的线程信息： 这里可以看到，在请求UserController的时候，由于该Controller进行了一个比较耗时的调用，导致该线程的 CPU 一直处于100%。我们可以根据堆栈信息，直接定位到UserController的34行，查看代码中具体是什么原因导致计算量如此之高。 接口耗时对于这种情况，比较典型的例子就是，访问接口返回很慢，而且由于这样的接口耗时是不定时出现的，这就导致了我们在通过jstack命令即使得到了线程访问的堆栈信息，我们也没法判断具体哪个线程是正在执行比较耗时操作的线程。 对于不定时出现的接口耗时严重问题，定位思路如下：首先找到该接口，通过压测工具不断加大访问力度，如果说该接口中有某个位置是比较耗时的，由于访问频率非常高，那么大多数线程都将阻塞在这里，这将导致多个线程具有相同的堆栈日志，然后分析日志就可以定位到该接口中比较耗时的代码的位置。如下是一个代码中有比较耗时的阻塞操作通过压测工具得到的线程堆栈日志： 1234567891011121314151617181920&quot;http-nio-8080-exec-2&quot; #29 daemon prio=5 os_prio=31 tid=0x00007fd08cb26000 nid=0x9603 waiting on condition [0x00007000031d5000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at com.aibaobei.user.controller.UserController.detail(UserController.java:18)&quot;http-nio-8080-exec-3&quot; #30 daemon prio=5 os_prio=31 tid=0x00007fd08cb27000 nid=0x6203 waiting on condition [0x00007000032d8000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at com.aibaobei.user.controller.UserController.detail(UserController.java:18)&quot;http-nio-8080-exec-4&quot; #31 daemon prio=5 os_prio=31 tid=0x00007fd08d0fa000 nid=0x6403 waiting on condition [0x00007000033db000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at com.aibaobei.user.controller.UserController.detail(UserController.java:18) 从上面的日志可以看出，有多个线程都阻塞在了UserController的第18行代码，说明这是一个阻塞点，也就是导致该接口比较缓慢的原因，然后分析代码即可。 线程WAITING状态线程处于 waiting 状态是比较罕见的一种情况，但是也是有可能出现的，而且由于其具有一定的“不可复现性”，在排查的时候是非常难以发现的。笔者曾经就遇到过类似的这种情况，具体的场景是，在使用CountDownLatch时，由于需要每一个并行的任务都执行完成之后才会唤醒主线程往下执行。而当时我们是通过CountDownLatch控制多个线程连接并导出用户的gmail邮箱数据，这其中有一个线程连接上了用户邮箱，但是连接被服务器挂起了，导致该线程一直在等待服务器的响应。最终导致我们的主线程和其余几个线程都处于 WAITING 状态。 对于这样的问题，查看过jstack日志的读者应该都知道，正常情况下，线上大多数线程都是处于TIMED_WAITING状态，而我们这里出问题的线程所处的状态与其是一模一样的，这就非常容易混淆我们的判断。解决这个问题的思路主要如下： 通过grep命令在jstack堆栈日志中找出所有的处于TIMED_WAITING状态的线程，将其导出到某个文件中，如a1.log，如下是一个导出的日志文件示例： 1234&quot;Attach Listener&quot; #13 daemon prio=9 os_prio=31 tid=0x00007fe690064000 nid=0xd07 waiting on condition [0x0000000000000000]&quot;DestroyJavaVM&quot; #12 prio=5 os_prio=31 tid=0x00007fe690066000 nid=0x2603 waiting on condition [0x0000000000000000]&quot;Thread-0&quot; #11 prio=5 os_prio=31 tid=0x00007fe690065000 nid=0x5a03 waiting on condition [0x0000700003ad4000]&quot;C1 CompilerThread3&quot; #9 daemon prio=9 os_prio=31 tid=0x00007fe68c00a000 nid=0xa903 waiting on condition [0x0000000000000000] 等待一段时间之后，比如10s，再次对jstack日志进行grep，将其导出到另一个文件，如a2.log，结果如下所示： 123&quot;DestroyJavaVM&quot; #12 prio=5 os_prio=31 tid=0x00007fe690066000 nid=0x2603 waiting on condition [0x0000000000000000]&quot;Thread-0&quot; #11 prio=5 os_prio=31 tid=0x00007fe690065000 nid=0x5a03 waiting on condition [0x0000700003ad4000]&quot;VM Periodic Task Thread&quot; os_prio=31tid=0x00007fe68d114000nid=0xa803waiting on condition 重复步骤2，待导出 34 个文件之后，我们对导出的文件进行对比，找出其中在这几个文件中一直都存在的用户线程，这个线程基本上就可以确认是包含了处于等待状态有问题的线程。因为正常的请求线程是不会在2030s之后还是处于等待状态的。 经过排查得到这些线程之后，我们可以继续对其堆栈信息进行排查，如果该线程本身就应该处于等待状态，比如用户创建的线程池中处于空闲状态的线程，那么这种线程的堆栈信息中是不会包含用户自定义的类的。这些都可以排除掉，而剩下的线程基本上就可以确认是我们要找的有问题的线程。通过其堆栈信息，我们就可以得出具体是在哪个位置的代码导致该线程处于等待状态了。 这里需要说明的是，我们在判断是否为用户线程时，可以通过线程最前面的线程名来判断，因为一般的框架的线程命名都是非常规范的，我们通过线程名就可以直接判断得出该线程是某些框架中的线程，这种线程基本上可以排除掉。而剩余的，比如上面的Thread-0，以及我们可以辨别的自定义线程名，这些都是我们需要排查的对象。 经过上面的方式进行排查之后，我们基本上就可以得出这里的Thread-0就是我们要找的线程，通过查看其堆栈信息，我们就可以得到具体是在哪个位置导致其处于等待状态了。如下示例中则是在SyncTask的第8行导致该线程进入等待了。 1234567&quot;Thread-0&quot; #11 prio=5 os_prio=31 tid=0x00007f9de08c7000 nid=0x5603 waiting on condition [0x0000700001f89000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304) at com.aibaobei.chapter2.eg4.SyncTask.lambda$main$0(SyncTask.java:8) at com.aibaobei.chapter2.eg4.SyncTask$$Lambda$1/1791741888.run(Unknown Source) at java.lang.Thread.run(Thread.java:748) 线程死锁对于死锁，这种情况基本上很容易发现，因为jstack堆栈信息可以很方便检查出死锁，并且在日志中打印具体的死锁线程信息。如下是一个产生死锁的一个jstack日志示例： 可以看到，在jstack堆栈日志的底部，其直接帮我们分析了日志中存在哪些死锁，以及每个死锁的线程堆栈信息。这里有两个用户线程分别在等待对方释放锁，而被阻塞的位置都是在ConnectTask的第5行，此时我们就可以直接定位到该位置，并且进行代码分析，从而找到产生死锁的原因。 小结本文主要讲解了线上可能出现的五种导致系统缓慢的情况，详细分析了每种情况产生时的现象。根据现象可以通过哪些方式定位得到是这种原因导致的系统缓慢。简要的说，可以分为如下步骤： 1）通过top命令查看 CPU 占用率高的进程，然后通过top -Hp &lt;pid&gt;命令查看当前进程的各个线程运行情况，找出CPU过高的线程之后，再将线程 id 转换为十六进制形式，最后在jstack日志中查看该线程主要的工作。这里又分为两种情况： 如果是用户线程，则通过查看该线程的堆栈信息定位具体是哪处代码运行比较消耗CPU； 如果该线程是VM Thread线程，则通过jstat -gcutil &lt;pid&gt; &lt;period&gt; &lt;times&gt;命令监控当前系统的GC状况，然后通过jmapdump:format=b,file=&lt;filepath&gt; &lt;pid&gt;导出系统当前的内存数据。并通过eclipse的MAT内存分析工具查看具体是什么对象比较消耗内存，最后再修改相关代码；详见 生产环境CPU 100%解决思路。 2）如果通过top命令看到CPU并不高，并且系统内存占用率也比较低。此时就可以考虑是否是由于另外三种情况导致的问题。具体的可以根据具体情况分析： 3）如果是接口调用比较耗时，并且是不定时出现，则可以通过压测的方式加大阻塞点出现的频率，并通过jstack查看堆栈信息，找到系统阻塞点； 4）如果是某个功能突然出现停滞状况，这种情况也无法复现，此时可以通过多次导出jstack日志的方式对比哪些用户线程是一直都处于等待状态，这些线程就是可能存在问题的线程； 5）如果通过jstack查看到死锁线程，则可以检查导致线程死锁的具体资源并处理相应的问题。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"}]},{"title":"SpringCloud系列之Sleuth和Zipkin","slug":"springcloud/SpringCloud系列之Sleuth和Zipkin","date":"2021-05-26T15:09:16.000Z","updated":"2024-02-14T12:08:50.227Z","comments":false,"path":"2021/05/26/springcloud/SpringCloud系列之Sleuth和Zipkin/","permalink":"https://imalan6.github.io/hexo_blog/2021/05/26/springcloud/SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BSleuth%E5%92%8CZipkin/","excerpt":"","text":"SpringCloud系列之Sleuth和Zipkin简介当采用微服务架构开发时，服务会按照不同的维度进行拆分，各业务之间通过接口相互调用。一个用户请求，可能需要很多微服务的相互调用才能完成。如果在业务调用链路上任何一个微服务出现问题或者网络超时，都可能导致功能失败。因此，我们需要一些可以帮助理解系统行为，并用于系统性能分析的工具，以便发生故障的时候，能够快速地定位和解决问题。随着业务越来越多，几乎每一个请求都会形成一个复杂的分布式服务调用链路，而对于微服务之间调用链路的分析会越来越复杂，类似下图所示： 谷歌在Dapper的论文中，提出了”链路追踪“的概念。链路追踪就是指一次任务的开始到结束，期间调用的所有系统及耗时（时间跨度）都可以完整记录下来。而Spring Cloud Sleuth就是Spring Cloud推出的分布式跟踪解决方案，并兼容支持了Zipkin（Twitter推出的分布式链路跟踪系统）和其他基于日志的追踪系统。通过Sleuth我们可以很清楚地掌握每一个请求经过了哪些服务，每个服务处理了多少时间，这让我们可以很方便地理清各个微服务间的调用关系。另外，Sleuth还提供如下功能： 耗时分析：通过Sleuth可以很清楚地了解到每个采样请求的耗时，从而分析出哪些服务调用比较耗时; 可视化错误：对于程序未捕捉的异常，可以通过集成Zipkin服务界面上看到; 链路优化：对于调用比较频繁的服务，可以针对这些服务实施一些优化措施。 为了实现平台无关、厂商无关的分布式服务跟踪，CNCF发布了布式服务跟踪标准Open Tracing。目前，业界使用最广泛的分布式链路跟踪系统是Twitter的Zipkin。而国内各大企业自己使用的，主要有淘宝的 “鹰眼”，京东的 “Hydra”，大众点评的 “CAT”以及新浪的 “Watchman”等。 Sleuth链路跟踪的跟踪单元是从用户发起请求(Request)到系统的边界开始，然后到系统返回响应(Response)为止的过程，整个过程称为一个Trace。 每个Trace中可能会调用多个服务，在每次调用服务时，添加一个调用记录，用来记录每次调用消耗的时间等信息，这个调用记录称为一个Span。 若干个有序的Span组成了一个Trace。在系统向外界提供服务时，会不断地有请求和响应发生，也就会不断地生成Trace，把这些带有Span的Trace统计出来，就构成了一幅完成的系统调用链路拓扑图。然后再附上Span中的响应时间，请求成功与否等信息，就可以在出现问题时，很方便地找到异常服务。 一个Trace是一次完整的调用链路，内部包含多个Span。Trace和Span是一对多的关系，而Span与Span之间存在父子关系，一系列的Span组成了树状结构。 比如：用户请求调用服务 C 、服务 D 、服务 E，其中服务 C 就是一个 Span，如果在服务 C 中另起一个线程调用了服务 D，那么服务 D 就是服务 C 的子 Span，如果在服务 D 中又另起一个线程调用了服务 E，那么服务 E 就是服务 D 的子 Span，而这个 C -&gt; D -&gt; E 构成的调用链路就是一条Trace。将链路调用数据汇总，类似如下图所示： ZipkinZipkin是Twitter的一个开源项目，它基于Google Dapper实现，它致力于收集服务的定时数据，包括数据的收集、存储、查找和显示。可以使用它来收集各个服务器上请求链路的跟踪数据，并通过它提供的REST API接口查询跟踪数据以实现对分布式系统的监控程序，从而及时地解决微服务系统中的性能问题，Zipkin还提供了可视化的UI组件帮助我们直观地搜索跟踪信息和分析请求链路细节。 Zipkin主要包括 4 个核心组件： Collector：收集器，主要用于处理从外部系统发送过来的跟踪信息，将这些信息转换为Zipkin内部处理的Span格式，以支持存储、分析、展示等功能。 Storage：存储组件，主要对处理收集器接收到的跟踪信息进行存储，默认存储在内存中。可以修改此存储策略，使用其他存储，比如Mysql。 RESTful API：API接口，用来提供外部访问接口。比如给客户端展示跟踪信息，或是外接系统访问监控数据等。 Web UI：UI组件，基于API组件实现的上层UI显示，可以很方便地查询和分析跟踪信息。 Zipkin分为服务端和客户端两部分。客户端直接部署在微服务上，一旦发生服务间的调用，会被Sleuth监听到，然后生成Trace和Span信息并发送到Zipkin服务端。发送的方式有两种：一种是采用Http报文的方式，另一种是采用消息队列发送，比如RabbitMQ。 部署1.服务端在使用Spring Boot 2.x版本后，官方就不推荐自行定制编译Zipkin，而是直接提供了编译好的jar包供使用。使用如下命令安装运行： 12curl -sSL https://zipkin.io/quickstart.sh | bash -sjava -jar zipkin.jar 如果使用Docker的话，命令如下： 12#docker pull openzipkin/zipkin#docker run -d -p 9411:9411 openzipkin/zipkin 启动Zipkin服务端后，访问 http://localhost:9411/zipkin/ ，界面显示如下： 2.客户端1）添加依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置 1234567891011spring: sleuth: web: client: enabled: true sampler: probability: 1.0 #将采样比例设置为1.0，也就是全部都需要。默认是0.1 sender: type: web #数据传输方式，web 表示以 HTTP 报文的形式向服务端发送数据 zipkin: base-url: http://192.168.0.6:9411/ #zipkin服务器的地址 Spring Cloud Sleuth有一个Sampler策略，用来控制数据采样算法。采样器不会阻碍span相关id的产生，但是会对导出以及附加事件标签的相关操作产生影响。 Sleuth默认采样算法是Reservoir sampling，默认的采样比例为 0.1(即 10%)。可以通过spring.sleuth.sampler.percentage设置，值介于0.0到1.0之间，1.0表示全部采集。 3.测试模拟用户发起服务请求，然后查看打开Zipkin UI界面，显示链路请求数据如下：","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"},{"name":"链路追踪","slug":"链路追踪","permalink":"https://imalan6.github.io/hexo_blog/tags/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"}]},{"title":"对象引用关系总结","slug":"jvm/对象引用关系总结","date":"2021-05-12T07:59:59.000Z","updated":"2024-02-13T06:00:28.158Z","comments":false,"path":"2021/05/12/jvm/对象引用关系总结/","permalink":"https://imalan6.github.io/hexo_blog/2021/05/12/jvm/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E5%85%B3%E7%B3%BB%E6%80%BB%E7%BB%93/","excerpt":"","text":"对象引用关系总结概述Java 执行GC时判断对象是否存活有两种方式，其中一种是引用计数。 引用计数：Java堆中每一个对象都有一个引用计数属性，引用每新增1次计数加1，引用每释放1次计数减1。 在JDK 1.2以前的版本中，若一个对象不被任何变量引用，那么程序就无法再使用这个对象。也就是说，只有对象处于可达状态（reachable），程序才能使用它。从JDK 1.2版本开始，对象的引用被划分为4种级别，使程序能更加灵活地控制对象的生命周期。这4种级别由高到低依次为：强引用、软引用、弱引用和虚引用。 强引用强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。如下： 1Object strongReference = new Object(); 当内存空间不足时，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 如果强引用对象不使用时，需要弱化从而使GC能够回收，如下： 1strongReference = null; 显式地设置strongReference对象为null，或让其超出对象的生命周期范围，则gc认为该对象不存在引用，这时就可以回收这个对象。具体什么时候收集这要取决于GC算法。 123public void test() &#123; Object strongReference = new Object();&#125; 在一个方法的内部有一个强引用，这个引用保存在 Java 栈中，而真正的引用内容Object保存在 Java 堆中。 当这个方法运行完成后，就会退出方法栈，则引用对象的引用数为0，这个对象会被回收。 但是如果这个strongReference是全局变量时，就需要在不用这个对象时赋值为null，因为强引用不会被垃圾回收。 比如，ArrayList的Clear方法： 123456789public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0;&#125; 在ArrayList类中定义了一个elementData数组，在调用clear方法清空数组时，每个数组元素被赋值为null。 不同于elementData = null，强引用仍然存在，避免在后续调用add()等方法添加元素时进行内存的重新分配。 使用如clear()方法内存数组中存放的引用类型进行内存释放特别适用，这样就可以及时释放内存。 软引用如果一个对象只具有软引用，则内存空间充足时，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。 软引用可用来实现内存敏感的高速缓存。 1234567// 强引用String strongReference = new String(&quot;abc&quot;);// 软引用String str = new String(&quot;abc&quot;);SoftReference&lt;String&gt; softReference = new SoftReference&lt;String&gt;(str); 软引用可以和一个引用队列 (ReferenceQueue) 联合使用。如果软引用所引用对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。 12345678910111213ReferenceQueue&lt;String&gt; referenceQueue = new ReferenceQueue&lt;&gt;();String str = new String(&quot;abc&quot;);SoftReference&lt;String&gt; softReference = new SoftReference&lt;&gt;(str, referenceQueue);str = null;// Notify GCSystem.gc();System.out.println(softReference.get()); // abcReference&lt;? extends String&gt; reference = referenceQueue.poll();System.out.println(reference); //null 注意：软引用对象是在 JVM 内存不够的时候才会被回收，我们调用System.gc()方法只是起通知作用，JVM 什么时候扫描回收对象是 JVM 自己的状态决定的。就算扫描到软引用对象也不一定会回收它，只有内存不够的时候才会回收。 当内存不足时，JVM首先将软引用中的对象引用置为null，然后通知垃圾回收器进行回收： 123456if(JVM内存不足) &#123; // 将软引用中的对象引用置为null str = null; // 通知垃圾回收器进行回收 System.gc();&#125; 也就是说，垃圾收集线程会在虚拟机抛出OutOfMemoryError之前回收软引用对象，而且虚拟机会尽可能优先回收长时间闲置不用的软引用对象。对那些刚构建的或刚使用过的”较新的”软对象会被虚拟机尽可能保留，这就是引入引用队列ReferenceQueue的原因。 应用场景 浏览器的后退按钮。按后退时，这个后退时显示的网页内容是重新进行请求还是从缓存中取出呢？这就要看具体的实现策略了。 1）如果一个网页在浏览结束时就进行内容的回收，则按后退查看前面浏览过的页面时，需要重新构建； 2）如果将浏览过的网页存储到内存中会造成内存的大量浪费，甚至会造成内存溢出。 这时候就可以使用软引用，很好的解决了实际的问题： 1234567891011121314151617181920// 获取浏览器对象进行浏览Browser browser = new Browser();// 从后台程序加载浏览页面BrowserPage page = browser.getPage();// 将浏览完毕的页面置为软引用SoftReference softReference = new SoftReference(page);// 回退或者再次浏览此页面时if(softReference.get() != null) &#123; // 内存充足，还没有被回收器回收，直接获取缓存 page = softReference.get();&#125; else &#123; // 内存不足，软引用的对象已经回收 page = browser.getPage(); // 重新构建软引用 softReference = new SoftReference(page);&#125; 弱引用弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。 123String str = new String(&quot;abc&quot;);WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);str = null; JVM首先将软引用中的对象引用置为null，然后通知垃圾回收器进行回收： 12str = null;System.gc(); 注意：如果一个对象是偶尔使用，并且希望在使用时随时就能获取到，但又不想影响此对象的垃圾收集，那么你应该用 Weak Reference 来记住此对象。 下面的代码会让一个弱引用再次变为一个强引用： 1234String str = new String(&quot;abc&quot;);WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);// 弱引用转强引用String strongReference = weakReference.get(); 同样，弱引用可以和一个引用队列(ReferenceQueue)联合使用，如果弱引用所引用的对象被垃圾回收，JVM 就会把这个弱引用加入到与之关联的引用队列中。 测试实例 GCTarget.java 12345678910111213141516public class GCTarget &#123; // 对象的ID public String id; // 占用内存空间 byte[] buffer = new byte[1024]; public GCTarget(String id) &#123; this.id = id; &#125; protected void finalize() throws Throwable &#123; // 执行垃圾回收时打印显示对象ID System.out.println(&quot;Finalizing GCTarget, id is : &quot; + id); &#125;&#125; GCTargetWeakReference.java 1234567891011121314public class GCTargetWeakReference extends WeakReference&lt;GCTarget&gt; &#123; // 弱引用的ID public String id; public GCTargetWeakReference(GCTarget gcTarget, ReferenceQueue&lt;? super GCTarget&gt; queue) &#123; super(gcTarget, queue); this.id = gcTarget.id; &#125; protected void finalize() &#123; System.out.println(&quot;Finalizing GCTargetWeakReference &quot; + id); &#125;&#125; WeakReferenceTest.java 1234567891011121314151617181920212223242526272829303132333435363738public class WeakReferenceTest &#123; // 弱引用队列 private final static ReferenceQueue&lt;GCTarget&gt; REFERENCE_QUEUE = new ReferenceQueue&lt;&gt;(); public static void main(String[] args) &#123; LinkedList&lt;GCTargetWeakReference&gt; gcTargetList = new LinkedList&lt;&gt;(); // 创建弱引用的对象，依次加入链表中 for (int i = 0; i &lt; 5; i++) &#123; GCTarget gcTarget = new GCTarget(String.valueOf(i)); GCTargetWeakReference weakReference = new GCTargetWeakReference(gcTarget, REFERENCE_QUEUE); gcTargetList.add(weakReference); System.out.println(&quot;Just created GCTargetWeakReference obj: &quot; + gcTargetList.getLast()); &#125; // 通知GC进行垃圾回收 System.gc(); try &#123; // 休息几分钟，等待上面的垃圾回收线程运行完成 Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 检查关联的引用队列是否为空 Reference&lt;? extends GCTarget&gt; reference; while((reference = REFERENCE_QUEUE.poll()) != null) &#123; if(reference instanceof GCTargetWeakReference) &#123; System.out.println(&quot;In queue, id is: &quot; + ((GCTargetWeakReference) (reference)).id); &#125; &#125; &#125;&#125; 运行WeakReferenceTest.java，运行结果如下： 可见WeakReference对象的生命周期基本由垃圾回收器决定，一旦垃圾回收线程发现了弱引用对象，在下一次GC过程中就会对其进行回收。 虚引用虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 应用场景 虚引用主要用来跟踪对象被垃圾回收器回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列 (ReferenceQueue) 联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 1234String str = new String(&quot;abc&quot;);ReferenceQueue queue = new ReferenceQueue();// 创建虚引用，要求必须与一个引用队列关联PhantomReference pr = new PhantomReference(str, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要进行垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 总结 Java中4种引用的级别和强度由高到低依次为：强引用 -&gt; 软引用 -&gt; 弱引用 -&gt; 虚引用 当垃圾回收器回收时，某些对象会被回收，某些不会被回收。垃圾回收器会从根对象 GC ROOT 来标记存活的对象，然后将某些不可达的对象和一些引用的对象进行回收。 引用类型 被垃圾回收时间 用途 生存时间 强引用 从来不会 对象的一般状态 JVM 停止运行时终止 软引用 当内存不足时 对象缓存 内存不足时终止 弱引用 正常垃圾回收时 对象缓存 垃圾回收后终止 虚引用 正常垃圾回收时 跟踪对象的垃圾回收 垃圾回收后终止","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"}]},{"title":"SpringCloud系列之Ribbon","slug":"springcloud/SpringCloud系列之Ribbon","date":"2021-04-21T14:16:14.000Z","updated":"2024-02-14T11:32:17.995Z","comments":false,"path":"2021/04/21/springcloud/SpringCloud系列之Ribbon/","permalink":"https://imalan6.github.io/hexo_blog/2021/04/21/springcloud/SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BRibbon/","excerpt":"","text":"SpringCloud系列之Ribbon简介Ribbon是一个由Netflix发布的开源的客户端负载均衡器，它可以控制HTTP和TCP客户端的行为，是SpringCloud-Netflix中重要的一环。通过Ribbon可以将Netflix的中间层服务连接在一起。使用时只需为Ribbon配置服务提供者地址列表，Ribbon就可基于负载均衡算法计算出要请求的目标服务地址。 Ribbon客户端组件提供了一系列完善的配置项，如连接超时、重试等。在配置文件中列出Load Balancer后面所有的服务，Ribbon会自动的基于某种规则（如简单轮询，随机连接，响应时间加权等）去连接这些服务，也很容易实现自定义的负载均衡算法，只需实现IRule接口即可。 Ribbon是在客户端来实现负载均衡的访问服务，主要的功能点： 服务发现，发现依赖服务的列表 服务选择规则，在多个服务中如何选择一个有效服务 服务监听，检测失效的服务，剔除失效服务 使用方法1）配置 添加依赖： 由于spring-cloud-starter-netflix-eureka-client已经包含spring-cloud-starter-netfilx-ribbon，所以无需额外添加依赖。 启动类配置： 123456789101112131415161718@SpringBootApplication@EnableEurekaClient@EnableFeignClients(basePackages = &#123;&quot;com.landcode.land.service.consumer.service&quot;&#125;) // 使用feign调用微服务，如果不使用feign可以不加@RibbonClient(name = &quot;service-hi&quot;, configuration = RibbonConfig.class) // 使用自定义配置public class UserApplication &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub SpringApplication.run(UserApplication.class, args); &#125; // 开启负载均衡 @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 如代码所示，只需在RestTemplate上添加LoadBalanced 注解，即可让整合Ribbon。 2）RestTemplate + Ribbon使用RestTemplate是Spring Resources中一个访问第三方RESTful API接口的网络请求框架，用来消费REST服务的。所以RestTemplate的主要方法都与REST的Http协议的一些方法紧密相连，例如HEAD、GET、POST、PUT、DELETE和OPTIONS等方法，这些方法在RestTemplate类对应的方法为headForHeaders()、getForObject()、postForObject()、put()和delete()等。 12345678910111213@RestController@RequestMapping(&quot;/user&quot;)public class TestHiController &#123;@Autowiredprivate RestTemplate restTemplate;@RequestMapping(&quot;/hi&quot;)public String hi () &#123; // 使用LoadBalancerClient通过service id获取指定服务 ServiceInstance serviceInstance = loadBalancerClient.choose(&quot;service-hi&quot;); return restTemplate.getForObject(serviceInstance.getUri().toString() + &quot;/hi&quot;, String.class);&#125; 代码中LoadBalancerClient为Ribbon默认的负载均衡API，使用的轮询策略；loadBalancerClient.choose(&quot;consul-provider&quot;)用于获取注册中心服务名称为service-hi的服务，再通过getUri()获取服务的地址；最后通过restTemplate.getForObject调用服务。 3）Feign + Ribbon使用Feign是一个声明式的Web Service客户端。它的出现使开发Web Service客户端变得很简单。在Spring Cloud中使用Feign，可以做到使用HTTP请求访问远程服务，就像调用本地方法一样的。详见 SpringCloud系列之Feign。 123456@FeignClient(value = &quot;service-hi&quot;)public interface ITestHi &#123; @RequestMapping(&quot;/hi&quot;) public String testHi();&#125; Feign是整合了Ribbon，使用方式一样。在controller里调用代码如下： 123456789101112@RestController@RequestMapping(&quot;/user&quot;)public class TestHiController &#123; @Autowired private ITestHi testHi; @RequestMapping(&quot;/hi&quot;) public String testHi() &#123; return testHi.testHi(); &#125;&#125; 负载均衡策略1）负载均衡当集群里的1台或者多台服务器出现故障时，剩余没有出现故障的服务器可以保证服务正常使用。而对于客户端如何选择调用哪个服务，则需要负载均衡技术。负载均衡有好几种实现策略，常见的有： 随机 (Random) 轮询 (RoundRobin) 一致性哈希 (ConsistentHash) 哈希 (Hash) 加权（Weighted） 2）Ribbon负载均衡策略Ribbon自带多种负载均衡策略，默认的是轮询策略。分别如下： 配置文件配置策略 1234# 通过配置文件指定服务的ribbon负载均衡策略为RandomRuleservice-hi: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 代码配置策略 为某个服务配置代码： 1234@Configuration@RibbonClient(name=&quot;service-hi&quot;,configuration = RibbonConfig.class)public class ServiceHiRibbonConfiguration &#123;&#125; RibbonConfig类代码： 123456789@Configurationpublic class RibbonConfig &#123; //Ribbon提供的负载均衡策略 @Bean public IRule ribbonRule()&#123; return new RandomRule(); &#125;&#125; 新建RibbonConfig类，@RibbonClient注解指定某个服务，针对该服务的配置有效。configuration参数指定为Ribbon的负载均衡策略配置类。如果全局配置，则不指定服务名称，使用@RibbonClients(defaultConfiguration = RibbonConfig.class)； 当然，也可以不单独创建配置类，像开头那样直接放入启动类中也是可以的。 自定义策略 如果Ribbon提供的负载均衡策略不满足业务需求，想要自己实现的话也是可以的。Ribbon支持自定义负载均衡策略，需要继承AbstractLoadBalancerRule类，或者实现IRule接口，实现choose方法即可。 123456789101112public class TestRule extends AbstractLoadBalancerRule &#123; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) &#123; &#125; @Override public Server choose(Object o) &#123; log.info(&quot;key:&quot; + o); List&lt;Server&gt; allServers = getLoadBalancer().getAllServers(); // 获取所有服务实例 return allServers.get(0); //使用列表中第一个服务实例 &#125;&#125; 如上，实现了一个简单的测试策略，即调用服务列表中的第一个服务实例。在真实应用环境中，替换成自己实现的负载均衡算法即可。使用该策略的话，直接将配置类return自定义的策略就可以了。 12345678@Configurationpublic class RibbonConfig &#123; @Bean public IRule ribbonRule()&#123; return new TestRule(); // 返回自定义的策略 &#125;&#125;","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"}]},{"title":"SpringCloud系列之Hystrix","slug":"springcloud/SpringCloud系列之Hystrix","date":"2021-04-10T15:05:15.000Z","updated":"2024-02-14T11:32:17.978Z","comments":false,"path":"2021/04/10/springcloud/SpringCloud系列之Hystrix/","permalink":"https://imalan6.github.io/hexo_blog/2021/04/10/springcloud/SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BHystrix/","excerpt":"","text":"SpringCloud系列之Hystrix服务雪崩在一个高度服务化的微服务系统中，一个业务逻辑处理通常会依赖多个服务。 如果其中的某一个服务不可用，就会出现线程池里所有线程都因等待响应而被阻塞，从而造成服务雪崩。这种因服务提供者不可用而导致服务调用者不可用，并将不可用逐渐放大传播的过程，就叫服务雪崩效应。比如程序bug、大流量请求、硬件故障、缓存雪崩击穿等。如下是一个分布式系统中服务调用的常见模型： 在服务提供者不可用时，服务调用者可能会出现大量重试情况，比如用户手动重试操作、代码逻辑重试操作等，这些重试操作最终导致请求量进一步加大。当服务调用者使用的同步调用时，大量等待线程占用了大量系统资源。一旦线程资源被耗尽，服务调用者提供的服务也将处于不可用状态，于是服务雪崩效应就产生了。所以，导致雪崩效应的根本原因就是大量请求线程同步等待造成的资源耗尽。 产生原因导致服务不可用的原因有很多，除了服务提供者不可用之外还有其他因素也可能产生雪崩效应： 服务调用者请求量激增，导致系统负载升高。比如异常流量、用户重试、代码逻辑重复等。 缓存击穿，缓存雪崩等，导致请求都直接转向数据库。 重试机制，比如RPC框架的Retry次数，每次重试都可能会进一步恶化服务提供者。 硬件故障，比如设备出问题，机房断电等情况。 解决方案针对服务调用者自身请求量激增问题，可以采取自动扩容方式应对突发流量，或在负载均衡器上实现限流功能。 针对重试问题，可以减少或关闭重试机制。 针对硬件故障，可以采取多机备份，异地多活等方案。 针对服务不可用而导致的系统雪崩问题，主要有以下解决方案： 超时机制 在不做任何处理的情况下，服务提供者不可用会导致消费者请求线程强制等待，而造成系统资源耗尽。加入超时机制，一旦超时，就释放资源。由于释放资源速度较快，一定程度上可以抑制资源耗尽的问题。 服务隔离 限制请求核心服务提供者的流量，把流量拦截在核心服务之外，这样可以更好地保证核心服务提供者不出问题。对于一些出问题的服务可以限制流量访问，只分配固定线程资源访问，这样能使整体的资源不至于被出问题的服务耗尽。可以通过线程池+队列的方式，通过信号量的方式进行处理。 服务熔断 当远程服务不稳定或网络抖动严重时暂时关闭。实时监测应用，一旦发现一定时间内服务调用的失败次数&#x2F;失败率达到一定阈值时，服务调用就断开(断路器)。此时，服务请求直接返回，不继续执行原本调用逻辑。断开一段时间后（比如10秒），断路器进入半开状态，此时允许调用一次该服务。如果调用成功，则断路器关闭，服务进入正常调用；如果调用仍然失败，断路器继续回到打开状态。经过一段时间（比如10秒）再进入半开状态，尝试调用服务。通过这种断路器打开—半开—关闭的方式， 可以控制服务调用者是否执行服务调用，从而避免频繁调用失败，浪费系统资源。 服务降级 所谓服务降级，就是调用者提前实现一个fallback熔断回调，当某个服务熔断无法被调用时，服务调用者就会调用fallback直接返回一个缺省值。比如，备用接口&#x2F;缓存&#x2F;mock数据等。这样业务处理方式更友好。 Hystrix使用Hystrix是由Netflix开源的一个延迟和容错库，提供超时机制、限流、熔断、降级全面的功能实现，主要用于隔离访问远程系统、服务或者第三方库，防止级联失败，从而提升系统的可用性与容错性。 服务隔离Hystrix采用了舱壁隔离技术，来将外部依赖进行资源隔离，进而避免任何外部依赖的故障导致本服务崩溃。舱壁隔离，是说将船体内部空间区隔划分成若干个隔舱，一旦某几个隔舱发生破损进水，水流不会在其间相互流动，如此一来船舶在受损时，依然能具有足够的浮力和稳定性，进而减低立即沉船的危险。Hystrix的资源隔离策略有两种，分别为：线程池和信号量。 线程池 在Hystrix中，如果不使用线程池隔离策略，而是共用一个线程池的话，服务的调用方式如下图： 这种方法共用一个线程池的方式很容易出现问题，比如：如果方法A请求量很大，调用的服务处理又很慢，那方法A很容易把线程池的线程用完，那方法B和方法C就没有线程可以使用了，只能等待，结果就是超时被熔断。导致这种情况出现，并不是被调用的服务不可用，而是服务调用者根本没有线程去处理这些请求。 为了避免上面这种情况，如果Hystrix对每个外部调用都单独配一个线程池，这样即使某个外部调用延迟很严重处理不过来，也只是耗尽自己的那个线程池而已，不会影响其他方法的线程池。这样就使得方法间的调用相互隔离开了，互不影响。如下图： Hystrix是通过命令模式，将每个类型的业务请求封装成对应的命令请求，比如A方法-&gt;服务1Command，B方法-&gt;服务1Command，C方法-&gt;服务2Command。每个类型的Command对应一个线程池。创建好的线程池放入到ConcurrentHashMap中，比如： 12final static ConcurrentHashMap&lt;String, HystrixThreadPool&gt; threadPools = new ConcurrentHashMap&lt;String, HystrixThreadPool&gt;();threadPools.put(“hystrix-order”, new HystrixThreadPoolDefault(threadPoolKey, propertiesBuilder)); 信号量 用于隔离本地代码，利用信号量限制同时运行的线程数量。使用一个原子计数器（或信号量）来记录当前有多少个线程在运行，当请求进来时先判断计数器的数值，若超过设置的最大线程个数则拒绝该请求，若不超过则通行，这时候计数器+1，请求返回成功后计数器-1。 区别 执行线程区别：线程池隔离方式执行依赖代码的线程不是原来的线程；而信号量方式依然是原来的请求线程。 应用场景区别：线程池隔离适合并发量比较大的第三方应用或者接口；而信号量隔离适合并发量不大的内部应用或中间件。 执行效率区别：线程池增加了cpu的开销；而信号量不会创建副线程，开销较小。 注意 使用线程池隔离时，在某些业务场景下通过ThreadLocal来传递数据会出现问题。因为线程池隔离方式下，Hystrix会将请求放入方法的线程池去执行，这时请求线程就由A线程变成B线程了，ThreadLocal也就消失了。用信号量没问题的，因为还是原来那个线程在处理。 使用方法1）命令方式hystrix采用了命令模式，客户端需要继承抽象类HystrixCommand并实现其run方法。 12345678910111213// HelloHystrixCommand要使用Hystrix功能 public class HelloHystrixCommand extends HystrixCommand &#123; private final String name; public HelloHystrixCommand(String name) &#123; super(HystrixCommandGroupKey.Factory.asKey(&quot;ExampleGroup&quot;)); this.name = name; &#125; // 如果继承的是HystrixObservableCommand，要重写Observable construct() @Override protected String run() &#123; return &quot;Hello &quot; + name; &#125; &#125; 2）注解方式12345678910@HystrixCommand(commandKey = &quot;getCompanyInfoById&quot;, groupKey = &quot;company-info&quot;, threadPoolKey = &quot;company-info&quot;, fallbackMethod = &quot;fallbackMethod&quot;, threadPoolProperties = &#123; @HystrixProperty(name = &quot;coreSize&quot;, value = &quot;30&quot;), @HystrixProperty(name = &quot;maxQueueSize&quot;, value = &quot;101&quot;), @HystrixProperty(name = &quot;keepAliveTimeMinutes&quot;, value = &quot;2&quot;), @HystrixProperty(name = &quot;queueSizeRejectionThreshold&quot;, value = &quot;15&quot;), &#125;) commandKey：代表一个接口, 如果不配置，默认是@HystrixCommand注解修饰的函数的函数名。 groupKey：代表一个服务，一个服务可能会暴露多个接口。Hystrix命令默认的线程划分也是根据命令组来实现。默认情况下，Hystrix会让相同组名的命令使用同一个线程池，所以我们需要在创建Hystrix命令时为其指定命令组来实现默认的线程池划分。 threadPoolKey：对线程池进行更细粒度的配置，默认等于groupKey的值。如果依赖服务中的某个接口耗时较长，需要单独特殊处理，最好单独用一个线程池，这时候就可以配置threadpool key。 fallbackMethod：@HystrixCommand注解修饰的函数的回调函数，@HystrixCommand修饰的函数必须和这个回调函数定义在同一个类中，因为定义在了同一个类中，所以fackback method可以是public/private均可。 线程池配置：coreSize表示核心线程数，hystrix默认是10；maxQueueSize表示线程池的最大队列大小；keepAliveTimeMinutes表示非核心线程空闲时最大存活时间；queueSizeRejectionThreshold：该参数用来为队列设置拒绝阈值。通过该参数，即使队列没有达到最大值也能拒绝请求。 使用实例： 1234567891011121314151617181920212223@RestController@RequestMapping(&quot;/user/hello&quot;)public class TestHelloController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(&quot;/hello&quot;) @HystrixCommand( fallbackMethod = &quot;HelloFallback&quot;,// 服务降级方法 // 使用commandProperties 可以配置熔断的一些细节信息 commandProperties = &#123; //熔断超时时间2s，类似kv形式 @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;,value = &quot;2000&quot;) &#125; ) public int getHi()&#123; String url =&quot;http://.....&quot;; return restTemplate.getForObject(url, Integer.class); &#125; // 服务降级方法，服务降级后调用该方法返回，返回值类型需要和原方法一致 public int HelloFallback()&#123; return -1; &#125;&#125; 3）与Feign配合使用通过配置@FeignClient注解的fallback属性指定一个自定义的fallback处理类。 123456@FeignClient(value = &quot;service-hi&quot;, fallback = HiFallback.class)public interface ITestHi &#123; @RequestMapping(&quot;/hi&quot;) public String testHi();&#125; HiFallback需要实现ITestHi接口，并且在Spring容器中注册bean。可以有两种方式：一种直接实现ITestHi接口，如下： 1234567@Componentclass HiFallback implements ITestHi&#123; @Override public String testHi()&#123; return &quot;error&quot;; &#125;&#125; 另一种实现FallbackFactory&lt;ITestHi&gt;接口，如下： 12345678@Componentclass HiFallback implements FallbackFactory&lt;ITestHi&gt;&#123; @Override public ITestHi create(Throwable cause) &#123; &#125;&#125; Hystrix监控 单服务监控 1）添加依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 2）启动类添加注解@EnableHystrixDashboard 12345678910111213141516171819@SpringBootApplication@EnableEurekaClient@EnableFeignClients(basePackages = &#123;&quot;com.landcode.land.service.consumer.service&quot;&#125;)@RibbonClient(name = &quot;service-hi&quot;, configuration = RibbonConfig.class)@EnableCircuitBreaker@EnableHystrixDashboard // 打开HystrixDashboardpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub SpringApplication.run(ConsumerApplication.class, args); &#125; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 3）测试 启动hystrix-dashboard后，输入http://localhost:8081/hystrix，出现如下页面： 在第一个文本框输入要监控的服务，采用ip + 端口 + hystrix.stream格式，比如http://localhost:8801/actuator/hystrix.stream，则会跳转到监控页面。如果点击后出现 “Unable to connect to Command Metric Stream.” 错误。则按如下方式解决： 在监控服务添加： 123hystrix: dashboard: proxy-stream-allow-list: &quot;*&quot; 在被监控服务添加配置类： 123456789101112@Configurationpublic class HystrixDashboardConfig &#123; @Bean public ServletRegistrationBean getServlet() &#123; HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(&quot;/actuator/hystrix.stream&quot;); //访问路径 registrationBean.setName(&quot;hystrix.stream&quot;); return registrationBean; &#125;&#125; Turbine聚合监控数据 1）创建一个监控服务项目，引入如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine&lt;/artifactId&gt;&lt;/dependency&gt; 2）启动类上配置@EnableTurbine注解： 1234567891011121314151617181920@SpringBootApplication@EnableEurekaClient@EnableFeignClients(basePackages = &#123;&quot;com.landcode.land.service.consumer.service&quot;&#125;)@RibbonClient(name = &quot;service-hi&quot;, configuration = RibbonConfig.class)@EnableCircuitBreaker@EnableHystrixDashboard @EnableTurbine // 打开Turbinepublic class ConsumerApplication &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub SpringApplication.run(ConsumerApplication.class, args); &#125; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 3）添加如下配置，指明从哪些微服务收集监控数据 123turbine: app-config: hi,test cluster-name-expression: &quot;&#x27;default&#x27;&quot; 注意turbine的配置，这里收集hi和test服务的日志 4）启动监控项目后，在hystrix-dashboard中输入http://localhost:8088/turbine.stream,则展示如下聚合结果： 以上Turbine聚合微服务的监控数据，然后在hystrix-dashboard展示多个微服务的实时监控数据。但是Turbine有它的局限性，比如如果微服务之间无法通信，或者服务没在Eureka上注册，则Turbine无法收集到微服务的日志。这种情况下，需要借助消息中间件来解决。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"},{"name":"熔断","slug":"熔断","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%86%94%E6%96%AD/"}]},{"title":"SpringCloud系列之Feign","slug":"springcloud/SpringCloud系列之Feign","date":"2021-03-29T15:11:45.000Z","updated":"2024-02-14T11:32:17.961Z","comments":false,"path":"2021/03/29/springcloud/SpringCloud系列之Feign/","permalink":"https://imalan6.github.io/hexo_blog/2021/03/29/springcloud/SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BFeign/","excerpt":"","text":"SpringCloud系列之Feign简介Feign是一个声明式、模板化的HTTP客户端，简化了系统发起HTTP请求。创建它时，只需要创建一个接口，然后加上@FeignClient注解就行了。使用它调用其他服务时，就像调用本地方法一样，完全感知不到这是在调用远程的方法，也感知不到背后发起的HTTP请求。Feign默认集成了Ribbon，并和Eureka结合，实现了负载均衡的效果。Feign功能如下： Feign采用的是基于接口的注解； 支持HTTP请求和响应的压缩； Feign整合了Ribbon，具有负载均衡的能力； 整合了Hystrix，具有熔断的能力。 使用方法1）pom.xml文件添加依赖： 12345 &lt;!--添加Feign依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 2）配置启动类，添加@EnableFeignClient注解： 12345678910@SpringBootApplication@EnableEurekaClient@EnableFeignClients(basePackages = &#123;&quot;com.landcode.land.service.user.service&quot;&#125;)public class UserApplication &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub SpringApplication.run(ConsumerApplication.class, args); &#125;&#125; 3）定义一个Feign接口，通过@FeignClient（“服务名”）来指定调用哪个服务。 12345@FeignClient(value = &quot;land-hi&quot;)public interface ITestHi &#123; @RequestMapping(&quot;/hi&quot;) public String hi();&#125; 上述ITestHi接口调用land-hi服务，hi方法调用land-hi服务的/hi接口。 自定义Feign配置类Feign也支持自定义配置，如下配置自定义重试机制，错误处理，拦截器demo。 代码配置方式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Configurationclass FeignConfig &#123; //自定义重试机制 @Bean public Retryer feignRetryer() &#123; //fegin提供的默认实现，最大请求次数为5，初始间隔时间为100ms，下次间隔时间1.5倍递增，重试间最大间隔时间为1s， return new Retryer.Default(); &#125; //错误处理 @Bean public ErrorDecoder feignError() &#123; return (key, response) -&gt; &#123; if (response.status() == 400) &#123; log.error(&quot;请求服务400参数错误,返回:&#123;&#125;&quot;, response.body()); &#125; if (response.status() == 404) &#123; log.error(&quot;请求服务404异常,返回:&#123;&#125;&quot;, response.body()); &#125; // 其他异常交给Default去解码处理 return new ErrorDecoder.Default().decode(key, response); &#125;; &#125; /** * fegin 拦截器 * @return */ @Bean public RequestInterceptor cameraSign() &#123; return template -&gt; &#123; // 如果是get请求 if (template.method().equals(Request.HttpMethod.GET.name())) &#123; //获取到get请求的参数 Map&lt;String, Collection&lt;String&gt;&gt; queries = template.queries(); &#125; //如果是Post请求 else if (template.method().equals(Request.HttpMethod.POST.name())) &#123; //获得请求body String body = template.requestBody().asString(); JSONPObject request = JSON.parseObject(body, JSONPObject.class); &#125; //根据请求参数生成的签名 String sign = &quot;*******&quot;; //放入url之后 template.query(&quot;sign&quot;, sign); //放入请求body中 String newBody = body + sign; template.body(Request.Body.encoded(newBody.getBytes(StandardCharsets.UTF_8), StandardCharsets.UTF_8)); &#125;; &#125;&#125; 当然，FeignConfig也可以无须定义在Spring容器中，直接在@FeignClient注解上使用也可以生效。 1@FeignClient(value = &quot;hi&quot;, configuration = FeignConfig.class) 属性配置方式 从Spring Cloud Edgware开始，Feign支持使用属性自定义配置。对于一个指定名称的FeignClient（例如该FeignClient的名称为feignName ），Feign支持如下配置项： 1234567891011121314151617feign: client: config: feignName: connectTimeout: 5000 # 相当于Request.Options readTimeout: 5000 # 相当于Request.Options # 配置Feign的日志级别，相当于代码配置方式中的Logger loggerLevel: full # Feign的错误解码器，相当于代码配置方式中的ErrorDecoder errorDecoder: com.example.SimpleErrorDecoder # 配置重试，相当于代码配置方式中的Retryer retryer: com.example.SimpleRetryer # 配置拦截器，相当于代码配置方式中的RequestInterceptor requestInterceptors: - com.alanotes.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false 当然不建议配置retryer重试机制，Spring Cloud Camden以及之后的版本中，Spring Cloud关闭了Feign的重试，而是使用Ribbon的重试。如果自己再定义Feign的重试，可能会造成混乱。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"}]},{"title":"SpringCloud系列之Zuul","slug":"springcloud/SpringCloud系列之Zuul","date":"2021-03-26T13:11:21.000Z","updated":"2024-02-14T12:08:39.513Z","comments":false,"path":"2021/03/26/springcloud/SpringCloud系列之Zuul/","permalink":"https://imalan6.github.io/hexo_blog/2021/03/26/springcloud/SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BZuul/","excerpt":"","text":"SpringCloud系列之Zuul服务网关服务网关是统一管理API的一个网络关口、通道，是整个微服务平台所有请求的唯一入口，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。 路由转发：接收所有外界请求，转发给微服务处理； 过滤处理：对请求进行处理，比如权限校验、限流以及监控等。 Zuul是Netflix OSS中的一员，是一个基于JVM路由和服务端的负载均衡器。提供路由、监控、弹性、安全等方面的服务框架。Zuul能够与Eureka、Ribbon、Hystrix等组件配合使用。Zuul的核心是过滤器，通过这些过滤器可以扩展出很多功能，比如： 动态路由 动态地将客户端的请求转发到后端具体的服务，完成业务逻辑处理。 认证鉴权 对所有用户请求做身份认证，拒绝非法请求，提高整个系统安全性。 预警监控 可以对所有用户请求进行监控，记录详细的请求响应日志，实时统计当前系统访问量、状态。 负载均衡 为每种类型的请求分配容量并丢弃超过限额的请求。 静态资源处理 直接在Zuul处理静态资源并响应，而并非转发这些请求到内部集群中。 部署 配置 1）pom文件添加依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 2）启动类加注解 12345678@SpringBootApplication@EnableDiscoveryClient@EnableZuulProxypublic class ZuulApplication &#123; public static void main(String[] args)&#123; SpringApplication.run(ZuulApplication.class, args); &#125;&#125; 3）配置文件 123456789101112131415161718192021222324252627server: port: 9000 spring: application: name: land-zuulzuul: routes: land-user: path: /user/** service-id: land-user stripPrefix: false #前缀方式映射-去掉前缀,不然访问需要/user前缀，比如访问/user/hello需要写成/user/user/hello.management: endpoints: web: exposure: include: &quot;*&quot; #实现智能端点，查看路由信息，filters，路径：/actuator/routes，需要使用actuator，zuul已默认集成starter-actuatoreureka: instance: prefer-ip-address: true #开启显示IP地址 instance-id: $&#123;spring.cloud.client.ip-address&#125;:$&#123;server.port&#125; #eureka页面显示IP地址：端口号 client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 测试 启动zuul和user服务，访问：http://127.0.0.1:9000/user/hello ，正常访问。 需要注意：如果使用springboot部署zuul，并且添加了starter-security依赖，需要注销掉，不然会跳转到默认的登录页面。 1234&lt;!-- &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;--&gt; 这是因为在SpringBoot中，默认的Spring Security生效了，此时所有接口的访问都是被保护的。需要通过验证才能正常访问。Spring Security提供了一个默认的用户，用户名是user，而密码则是启动项目的时候自动生成的。如果不想注销依赖，可以有如下方法解决： SpringBoot1.x以前，修改配置文件如下： 123security: basic: enabled: false SpringBoot2.x及以后，添加配置类如下： 12345678910@Configuration@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; //配置不需要登陆验证 http.authorizeRequests().anyRequest().permitAll().and().logout().permitAll(); &#125;&#125; 常用基本配置 配置path 上文中,我们配置的一个路由规则是这样的： 12345zuul: routes: land-user: path: /user/** service-id: land-user 这里指定了path和service-id，可以简化一下，方式如下： 123zuul: routes: service-id: /user/** zuul.routes后面是服务名，值是路径，上面这两种配置的方式都是可以的，下面这样更简洁。 配置url 同时指定path和url，例如： 12345zuul: routes: user-route: # 该配置方式中，user-route 只是给路由一个名称，可以任意起名。 url: http://localhost:8001/ # 指定的 url path: /user/** # url 对应的路径 这样就可以将 /user/** 映射到 http://localhost:8001/**。 需要注意的是，使用这种方式配置的路由不会作为HystrixCommand执行，也不能使用Ribbon来负载均衡多个url。 同时指定path和url，并且不破坏Zuul的Hystrix、Ribbon特性。配置如下： 123456789101112zuul: routes: land-user: url: http://localhost:8001/ path: /user/** service-id: land-userribbon: eureka: enabled: false # 为 Ribbon 禁用 Eurekaland-user: ribbon: listOfServices: localhost:8001,localhost:8002 路由前缀 为所有路由规则增加前缀，配置如下： 12zuul: prefix: /api 比如之前访问路径是 http://localhost:9000/user/hello ，配置了前缀之后，访问路径就变成了 http://localhost:9000/api/user/hello 。 忽略指定服务 忽略服务可以使用zuul.ignored-services配置需要忽略的服务，多个用逗号分隔。例如： 12zuul: ignored-services: land-test, land-hi 这样Zuul就忽略掉了land-test和land-hi微服务，只代理其他微服务。 如果要忽略所有微服务，只路由指定微服务，可以将zuul.ignored-services设为*。 1234zuul: ignored-services: &#x27;*&#x27; # 使用 &#x27;*&#x27; 可忽略所有微服务 routes: land-user: /user/** 通配符 不论是使用传统配置方式还是服务路由的配置方式，都需要使用通配符方式为每个路由定义匹配表达式。 通配符 说明 ? 匹配任意单个字符 * 匹配任意数量的字符 ** 匹配任意数量的自负，支持多级目录 url路径 说明 &#x2F;user&#x2F;? 可以匹配&#x2F;user&#x2F;之后的一个字符的路径，比如&#x2F;user&#x2F;a，&#x2F;user&#x2F;b &#x2F;user&#x2F;* 可以匹配&#x2F;user&#x2F;之后任意字符的路径，比如&#x2F;user&#x2F;a，&#x2F;user&#x2F;aaa等 &#x2F;user&#x2F;** 可以匹配&#x2F;user&#x2F;*包含的内容之外，还可以匹配&#x2F;user&#x2F;a&#x2F;b等多级目录形式 正则表达式路由映射 有时为了兼容不同版本的客户端程序，后端系统需要创建不同版本的微服务来应对，比如：user-v1，user-v2等。默认情况下，Zuul自动为服务创建的路由表达式会采用服务名作为前缀，比如针对上面的user-v1和user-v2会产生/user-v1和/user-v2两个路径表达式来映射，这样生成出来的表示式规则单一，不利于管理。通常的做法是以版本号作为路由前缀，比如/v1/userservice/。这种使用版本号为前缀的url路径，可以很方便地对服务进行版本归类和管理。 我们可以使用Zuul来自定义服务与路由映射关系，创建类似于/v1/userserivce/**的路由规则。代码如下： 1234567@Beanpublic PatternServiceRouteMapper serviceRouteMapper()&#123; // 调用构造函数PatternServiceRouteMapper(String servicePattern, String routePattern) // servicePattern 指定微服务的正则 // routePattern 指定路由正则 return new PatternServiceRouteMapper(&quot;(?&lt;name&gt;^.+)-(?&lt;version&gt;v.+$)&quot;,&quot;$&#123;version&#125;/$&#123;name&#125;&quot;);&#125; PatternServiceRouteMapper对象可以让开发者通过正则表达式自定义服务与路由映射的关系。构造函数第一个参数用来匹配服务名称的正则表达式，第二个参数根据服务名内容转换出的表达式规则。当定义了PatternServiceRouteMapper之后，只要符合第一个参数定义规则的服务名，就会优先使用该实现构建表达式，如果没有匹配上还是会使用默认的路由映射规则，即采用完整服务名作为前缀的路径表达式。 Zuul + Ribbon + Hystrix 超时熔断 Ribbon配置： 1）当使用了Eureka注册中心，zuul.routes配置使用service-id的时候，通过ribbon.ReadTimeout和ribbon.SocketTimeout配置； 2）当zuul.routes配置使用url的时候,通过zuul.host.connect-timeout-millis和zuul.host.socket-timeout-millis配置； 如果需要对指定服务进行特殊配置，方式如下： 1&lt;serviceName&gt;.ribbon.ReadTimeout #serviceName为服务名 Hystrix配置： 如果Zuul配置了熔断Fallback的话，熔断超时也需要配置，方式如下： 1hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=30000 default代表默认，如果需要为某个指定服务特殊配置熔断超时策略，方式如下： 1hystrix.command.&lt;serviceName&gt;.execution.isolation.thread.timeoutInMilliseconds=30000 如果想关闭Hystrix的重试机制可以通过下面的配置： 关闭全局重试机制： 12zuul: retryable: false 关闭某个服务的重试机制： 1234zuul: routes: land-user: retryable: false Header设置 1）敏感Header设置 同一个系统中各个服务之间通过Headers来共享信息是没啥问题的，但是如果不想Headers中的一些敏感信息随着HTTP转发泄露出去话，需要在路由配置中指定一个忽略Header的清单。默认情况下，Zuul在请求路由时，会过滤HTTP请求头信息中的一些敏感信息，默认的敏感头信息通过zuul.sensitiveHeaders定义，包括Cookie、Set-Cookie、Authorization。配置的sensitiveHeaders可以用逗号分割。对指定路由的可以用下面进行配置: 123# 对指定路由开启自定义敏感头zuul.routes.[route].customSensitiveHeaders=true zuul.routes.[route].sensitiveHeaders=[这里设置要过滤的敏感头] 设置全局: 1zuul.sensitiveHeaders=[设置要过滤的敏感头] 2）忽略Header设置 如果每一个路由都需要配置一些额外的敏感Header时，可以通过zuul.ignoredHeaders来统一设置需要忽略的Header。如: 1zuul.ignoredHeaders=[这里设置要忽略的Header] 在默认情况下是没有这个配置的，如果项目中引入了Spring Security，那么Spring Security会自动加上这个配置，默认值为: Pragma, Cache-Control, X-Frame-Options, X-Content-Type-Options, X-XSS-Protection, Expries。 此时，如果还需要使用下游微服务的Spring Security的Header时，可以增加下面的设置: 1zuul.ignoreSecurityHeaders=false 熔断处理fallback 当Zuul进行路由分发时，如果微服务没有启动，或者调用超时，Zuul可以使用一种降级功能，而不是将异常直接暴露出来。默认情况下，经过Zuul的请求都会使用Hystrix进行包裹，所以Zuul本身就具有断路器的功能Zuul，需要实现ZuulFallbackProvider接口。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Componentpublic class HystrixFallbackConfig implements FallbackProvider &#123; @Override public String getRoute() &#123; //微服务配了路由的话，就用配置的名称 //return &quot;land-user&quot;; //*表示为所有微服务提供回退 return &quot;*&quot;; &#125; @Override public ClientHttpResponse fallbackResponse(String route, Throwable cause) &#123; if (cause instanceof HystrixTimeoutException) &#123; return response(HttpStatus.GATEWAY_TIMEOUT); &#125; else &#123; return this.fallbackResponse(); &#125; &#125; public ClientHttpResponse fallbackResponse() &#123; return this.response(HttpStatus.INTERNAL_SERVER_ERROR); &#125; private ClientHttpResponse response(final HttpStatus status) &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return status; &#125; @Override public int getRawStatusCode() throws IOException &#123; return status.value(); &#125; @Override public String getStatusText() throws IOException &#123; return status.getReasonPhrase(); &#125; @Override public void close() &#123; &#125; @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream(&quot;服务不可用，请稍后再试。&quot;.getBytes()); &#125; @Override public HttpHeaders getHeaders() &#123; // headers设定 HttpHeaders headers = new HttpHeaders(); // MediaType mt = new MediaType(&quot;application&quot;, &quot;json&quot;, Charset.forName(&quot;UTF-8&quot;)); // headers.setContentType(mt); headers.setContentType(MediaType.APPLICATION_JSON); return headers; &#125; &#125;; &#125;&#125; 当user服务不可用时，访问返回结果如下： 请求过滤如果需要通过网关实现一些诸如过滤，权限验证等功能，就需要用到Zuul的请求过滤的功能。ZuulFilter类似于一个拦截器，会把请求拦截下来，然后做相应处理，最后决定是否放行。 Zuul大部分功能都是通过过滤器来实现的。Zuul中定义了四种标准过滤器类型，这些过滤器类型对应于请求的典型生命周期： PRE：这种过滤器在请求被路由之前调用。可以利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 ROUTING：这种过滤器将请求路由到微服务。用于构建发送给微服务的请求，并使用Apache HttpClient或Netflix Ribbon构建和发送原始HTTP请求的位置。 POST：请求在路由到微服务之后执行。示例包括向响应添加标准Http标头、收集统计信息和指标、以及将响应从源传输到客户端。 ERROR：过滤器在其中一个阶段发生错误时执行。 除了默认的过滤器类型，Zuul还允许我们创建自定义过滤器类型。例如，自定义一个Static类型的过滤器，它直接在Zuul中生成响应，而不是将请求转发到后端的微服务。Zuul请求的生命周期如下图所示，详细描述了各种类型的过滤器执行顺序。 现在使用Zuul过滤器模拟一个对请求进行权限认证的功能，首先自定义一个过滤器并继承ZuulFilter，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940@Configurationpublic class ZuulFilterConfig extends ZuulFilter &#123; // 过滤器类型，pre表示在请求路由之前进行拦截 @Override public String filterType() &#123; return &quot;pre&quot;; &#125; // 过滤器的执行顺序。当请求在一个阶段的时候存在多个过滤器时，需要根据该方法的返回值依次执行 @Override public int filterOrder() &#123; // 值越小执行顺行越靠前 return 0; &#125; // 确定过滤器是否生效 @Override public boolean shouldFilter() &#123; // 默认此类过滤器时false，不开启的，需要改为true return true; &#125; @Override public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String token = request.getParameter(&quot;access-token&quot;); if (token == null || &quot;&quot;.equals(token.trim()) &#123; ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); ctx.addZuulResponseHeader((&quot;content-type&quot;), &quot;text/html;charset=utf-8&quot;); ctx.setResponseBody(&quot;拒绝访问&quot;); return null; &#125; // 否则正常执行业务逻辑..... return null; &#125;&#125; 运行Zuul，不提供access-token参数访问服务，结果如下： 方法说明： filterType()：返回值为过滤器的类型，过滤器的类型决定了过滤器在哪个生命周期执行，上面代码中返回的是pre，表示是在路由之前执行过滤，其他可选值还有post，error，route和static，也可以自定义。 filterOrder()：返回过滤器的执行顺序，当有多个过滤器时，这个方法定义执行顺序。 shouldFilter()：这个方法用来判断这个过滤器是否执行，true就是执行，在实际使用中可以根据当前请求地址来决定要不要执行这个过滤器，这里为了测试，直接返回true了。 run()：过滤器的具体业务逻辑，上面例子中，有access-token参数的请求放行，否则拦截下来。首先需要设置ctx.setSendZuulResponse(false);表示这个请求就不进行路由了，然后再设置http状态码和具体返回的body内容。在实际项目中，在run方法中可能是先获取用户对象，然后做权限判断等，并根据具体的业务具体实现。run方法的返回值在目前的版本中没有任何意义，可随意处理。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"},{"name":"网关","slug":"网关","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BD%91%E5%85%B3/"}]},{"title":"SpringCloud系列之Eureka","slug":"springcloud/SpringCloud系列之Eureka","date":"2021-03-23T15:21:44.000Z","updated":"2024-02-14T11:32:17.938Z","comments":false,"path":"2021/03/23/springcloud/SpringCloud系列之Eureka/","permalink":"https://imalan6.github.io/hexo_blog/2021/03/23/springcloud/SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BEureka/","excerpt":"","text":"SpringCloud系列之Eureka简介 服务治理 服务治理是微服务架构中最为核心和基础的模块，它主要用来实现各个微服务实例的自动化注册和发现。 1）服务注册 在服务治理框架中，通常都会构建一个注册中心，每个服务单元向注册中心登记自己提供的服务，包括服务的主机与端口号、服务版本号、通讯协议等一些附加信息。注册中心按照服务名分类组织服务清单，同时还需要以心跳检测的方式去监测清单中的服务是否可用，若不可用需要从服务清单中剔除，以达到排除故障服务的效果。 2）服务发现 在服务治理框架下，服务间的调用不再通过指定具体的实例地址来实现，而是通过服务名发起请求调用实现。服务调用方通过服务名从服务注册中心的服务清单中获取服务实例的列表清单，通过指定的负载均衡策略取出一个服务实例位置来进行服务调用。 Eureka介绍 Spring Cloud Eureka是Spring Cloud Netflix微服务套件中的一部分，它基于Netflix Eureka做了二次封装。主要负责完成微服务架构中的服务治理功能。 Spirng Cloud Eureka使用Netflix Eureka来实现服务注册与发现。它既包含了服务端组件，也包含了客户端组件，并且服务端与客户端均采用java编写，所以Eureka主要适用于通过java实现的分布式系统，或是JVM兼容语言构建的系统。Eureka的服务端提供了较为完善的REST API，所以Eureka也支持将非java语言实现的服务纳入到Eureka服务治理体系中来，只需要其他语言平台自己实现Eureka的客户端程序。 1）Eureka服务端 Eureka服务端，即服务注册中心。它同其他服务注册中心一样，支持高可用配置。依托于强一致性提供良好的服务实例可用性，可以应对多种不同的故障场景。 Eureka服务端支持集群模式部署，当集群中有分片发生故障的时候，Eureka会自动转入自我保护模式。它允许在分片发生故障的时候继续提供服务的发现和注册，当故障分配恢复时，集群中的其他分片会把他们的状态再次同步回来。集群中的的不同服务注册中心通过异步模式互相复制各自的状态，这也意味着在给定的时间点每个实例关于所有服务的状态可能存在不一致的现象。 2）Eureka客户端 Eureka客户端，主要处理服务的注册和发现。客户端服务通过注册和参数配置的方式，嵌入在客户端应用程序的代码中。在应用程序启动时，Eureka客户端向服务注册中心注册自身提供的服务，并周期性的发送心跳来更新它的服务租约。同时，他也能从服务端查询当前注册的服务信息并把它们缓存到本地并周期性地刷新服务状态。 部署单机部署 服务器端 1）pom文件添加依赖 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2）启动类加注解 1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); &#125;&#125; 3）application.xml配置 12345678910111213spring: application: name: land-eurekaserver: port: 8761eureka: client: # 是否要注册到其他Eureka Server实例 register-with-eureka: false # 是否要从其他Eureka Server实例获取数据 fetch-registry: false service-url: defaultZone: http://localhost:8761/eureka/ 客户端 1）添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 2）加注解 123456@SpringBootApplicationpublic class ProviderUserApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProviderUserApplication.class, args); &#125;&#125; 注意：早期的版本（Dalston及更早版本）还需在启动类上添加注解@EnableDiscoveryClient 或@EnableEurekaClient ，从Edgware开始，该注解可省略。 3）添加配置 123456789101112131415server: port: 8001spring: application: # 指定注册到eureka server上的服务名称 name: land-usereureka: client: service-url: # 指定eureka server地址 defaultZone: http://localhost:8761/eureka/ instance: # 是否注册IP到eureka server。如不指定或设为false，会注册主机名到eureka server prefer-ip-address: true 测试 启动Eureka服务端，启动land-user服务，使用浏览器打开 http://localhost:8761/ 访问eureka管理页面，即可查看服务信息。 集群部署在生产环境中，通常需要配置3台及以上的服务注册中心来提高可用性，配置原理都一样，将注册中心分别指向其它的注册中心。这里介绍三台集群的配置情况，其实和双节点的注册中心类似，每台注册中心分别又指向其它两个节点即可，使用application.yml来配置。 三个配置文件，分别如下： application-sever1.yml 123456789101112spring: application: name: land-eureka profiles: sever1server: port: 8761eureka: instance: hostname: sever1 client: serviceUrl: defaultZone: http://sever2:8762/eureka/,http://sever3:8763/eureka/ application-sever2.yml 123456789101112spring: application: name: land-eureka2 #不能重复 profiles: sever2server: port: 8762eureka: instance: hostname: sever2 client: serviceUrl: defaultZone: http://sever1:8761/eureka/,http://sever3:8763/eureka/ application-sever3.yml 123456789101112spring: application: name: land-eureka3 #不能重复 profiles: sever3server: port: 8763eureka: instance: hostname: sever3 client: serviceUrl: defaultZone: http://sever1:8761/eureka/,http://sever2:8762/eureka/ 修改本机hosts文件，添加sever1，sever2，sever3解析 123127.0.0.1 sever1127.0.0.1 sever2127.0.0.1 sever3 然后在配置文件application.yml中profiles，active配置项分别指定application-sever1.yml，application-sever2.yml，application-sever3.yml启动服务即可。 123#使用的配置文件名profiles: active: sever1 #分别指定sever1,sever2,sever3 原理 如图是Eureka集群的工作原理，包括： 1）Application Service，服务提供者； 2）Application Client，服务消费者； 3）Make Remote Call调用RESTful API； 4）us-east-1c、us-east-1d等都是Availability Zone，它们都属于us-east-1这个region。 由图可知，Eureka包含两个组件：Eureka Server和Eureka Client，它们的作用如下： 1）Eureka Server提供服务发现的能力，各个微服务启动时，会向Eureka Server注册自己的信息（例如IP、端口、微服务名称等），Eureka Server会存储这些信息； 2）Eureka Client是一个Java客户端，用于简化与Eureka Server的交互； 3）微服务启动后，会周期性（默认30秒）地向Eureka Server发送心跳以续约自己的“租期”； 4）如果Eureka Server在一定时间内没有接收到某个微服务实例的心跳，Eureka Server将会注销该服务实例（默认90秒）； 5）默认情况下，Eureka Server同时也是Eureka Client。多个Eureka Server实例，互相之间通过增量复制的方式，来实现服务注册表中数据的同步。Eureka Server默认保证在90秒内，Eureka Server集群内的所有实例中的数据达到一致； 6）Eureka Client会缓存服务注册表中的信息。这样，微服务无需每次请求都查询Eureka Server，从而降低了Eureka Server的压力；另外，即使Eureka Server所有节点都宕掉，服务消费者依然可以使用缓存中的信息找到服务提供者并完成调用。 Eureka通过心跳检查、客户端缓存等机制，提高了系统的可用性、灵活性以及可伸缩性。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"},{"name":"服务注册","slug":"服务注册","permalink":"https://imalan6.github.io/hexo_blog/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C/"}]},{"title":"SpringCloud系列之Admin","slug":"springcloud/SpringCloud系列之Admin","date":"2021-03-18T15:11:34.000Z","updated":"2024-02-14T11:32:17.920Z","comments":false,"path":"2021/03/18/springcloud/SpringCloud系列之Admin/","permalink":"https://imalan6.github.io/hexo_blog/2021/03/18/springcloud/SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BAdmin/","excerpt":"","text":"SpringCloud系列之Admin简介Spring Boot Admin主要用于管理和监控SpringBoot应用程序。被监控的应用程序被看作是一个客户端点，以http方式或者使用注册中心直接注册到Spring Boot Admin Server上。注册成功后，可以通过Spring Boot Admin提供的UI界面，可以轻松监控查看Actuator端点的监控信息。监控信息挺多，列举部分常见功能如下： 显示健康状况 显示详细信息，例如 JVM和内存指标 micrometer.io指标 数据源指标 缓存指标 查看JVM系统和环境属性 查看Spring Boot配置属性 轻松的日志级管理 与JMX-beans交互 查看线程转储 查看http跟踪 下载heapdump 单服务监控 Server端配置 1）添加pom依赖 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2）启动类添加注解@EnableAdminServer 123456789@SpringBootApplication@EnableAdminServerpublic class LandAdminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LandAdminApplication.class, args); &#125;&#125; 客户端配置 1）添加pom依赖 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2）添加配置 123456789101112spring: boot: admin: client: url: http://localhost:8000 #Admin Server地址 #actuator启用监控management: endpoints: web: exposure: include: &quot;*&quot; #开放所有端点health，info，metrics，通过actuator/端点名，就可以获取对应的信息。如果不配置，默认只打开health和info端点 需要配置admin server的地址，还需要打开actuator端点。 测试 启动Admin服务和需要监控的微服务，访问 http://127.0.0.1:8000/ ，显示如下： 点击查看服务详细信息如下： Spring Boot Admin以图形化方式展示了被监控服务的各项信息，这些信息大多都来自于Spring Boot Actuator提供的接口。 微服务监控如果只是单个或少量的Spring Boot应用，采用上面直接在端点完成配置的方式就可以了。但如果是微服务系统，且后端有很多微服务的话，采用上面的配置方式就显得过于复杂和笨拙。这时可以借助注册中心Eureka来完成，让Spring Boot Admin自动从注册中心抓取应用的相关信息。 如果使用Spring Cloud的服务发现功能完成监控抓取，服务端点就不需要再单独添加Admin Client依赖，只需要Admin Server就可以了，其它内容会自动进行配置。 1）客户端和Admin服务端都完成Eureka配置，详见 SpringCloud系列之Eureka 。 2）启动各个服务，访问 http://127.0.0.1:8000/ ，显示如下：","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"},{"name":"监控","slug":"监控","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"SpringCloud系列之Actuator","slug":"springcloud/SpringCloud系列之Actuator","date":"2021-03-12T08:12:24.000Z","updated":"2024-02-14T11:32:17.900Z","comments":false,"path":"2021/03/12/springcloud/SpringCloud系列之Actuator/","permalink":"https://imalan6.github.io/hexo_blog/2021/03/12/springcloud/SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BActuator/","excerpt":"","text":"SpringCloud系列之Actuator简介微服务系统通常是分布式部署的，大部分服务都运行在不同的机器上，彼此通过服务接口交互调用，业务会经过多个微服务的处理和传递，如果期间出现了异常需要快速定位，就需要对微服务的状态进行实时监控。 spring-boot-starter-actuator，这个模块可以自动为Spring Boot创建的应用构建一系列的用于监控的端点。Actuator是Spring Boot提供的对应用系统的自省和监控的集成功能，可以查看应用配置的详细信息，例如自动化配置信息、创建的Spring beans以及一些环境属性等。使用Actuator可以很方便地对微服务状况进行监控。 监控端点Actuator监控端点分为原生端点和用户自定义端点。自定义端点可以让用户自定义一些比较关心的指标，在运行期进行监控。而原生端点是由actuator提供的web接口，用来了解服务运行时的内部状况。原生端点可以分成三类： 应用配置类：用于查看服务在运行时的静态信息，比如自动配置信息，Spring Bean信息、配置文件信息、环境信息、请求映射等； 度量指标类：主要是服务运行时的动态信息，比如堆栈、请求链、健康指标、metrics信息等； 操作控制类：主要是指shutdown，用户可以发送请求关闭应用的监控功能。 Actuator提供了13个接口，如下表所示： HTTP方法 路径 描述 鉴权 GET &#x2F;autoconfig 查看自动配置的使用情况 true GET &#x2F;configprops 查看配置属性，包括默认配置 true GET &#x2F;beans 查看bean及其关系列表 true GET &#x2F;dump 打印线程栈 true GET &#x2F;env 查看所有环境变量 true GET &#x2F;env&#x2F;{name} 查看具体变量值 true GET &#x2F;health 查看应用健康指标 false GET &#x2F;info 查看应用信息 false GET &#x2F;mappings 查看所有url映射 true GET &#x2F;metrics 查看应用基本指标 true GET &#x2F;metrics&#x2F;{name} 查看具体指标 true POST &#x2F;shutdown 关闭应用 true GET &#x2F;trace 查看基本追踪信息 true 部署1）加入pom依赖 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2）配置文件 123456789#启用监控management: endpoints: web: exposure: include: &quot;*&quot; #开放所有端点health，info，metrics，通过actuator/端点名，就可以获取对应的信息。如果不配置，默认只打开health和info端点 endpoint: health: show-details: always #未开启actuator/health时，我们获取到的信息是&#123;&quot;status&quot;:&quot;UP&quot;&#125;，status的值还有可能是 DOWN。开启后打印详细信息 3）启动服务，输入 http://localhost:8081/actuator ，查看端点信息如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116&#123; &quot;_links&quot;:&#123; &quot;self&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator&quot;, &quot;templated&quot;:false &#125;, &quot;archaius&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/archaius&quot;, &quot;templated&quot;:false &#125;, &quot;auditevents&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/auditevents&quot;, &quot;templated&quot;:false &#125;, &quot;beans&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/beans&quot;, &quot;templated&quot;:false &#125;, &quot;caches-cache&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/caches/&#123;cache&#125;&quot;, &quot;templated&quot;:true &#125;, &quot;caches&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/caches&quot;, &quot;templated&quot;:false &#125;, &quot;health&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/health&quot;, &quot;templated&quot;:false &#125;, &quot;health-component-instance&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/health/&#123;component&#125;/&#123;instance&#125;&quot;, &quot;templated&quot;:true &#125;, &quot;health-component&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/health/&#123;component&#125;&quot;, &quot;templated&quot;:true &#125;, &quot;conditions&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/conditions&quot;, &quot;templated&quot;:false &#125;, &quot;configprops&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/configprops&quot;, &quot;templated&quot;:false &#125;, &quot;env&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/env&quot;, &quot;templated&quot;:false &#125;, &quot;env-toMatch&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/env/&#123;toMatch&#125;&quot;, &quot;templated&quot;:true &#125;, &quot;info&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/info&quot;, &quot;templated&quot;:false &#125;, &quot;loggers&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/loggers&quot;, &quot;templated&quot;:false &#125;, &quot;loggers-name&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/loggers/&#123;name&#125;&quot;, &quot;templated&quot;:true &#125;, &quot;heapdump&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/heapdump&quot;, &quot;templated&quot;:false &#125;, &quot;threaddump&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/threaddump&quot;, &quot;templated&quot;:false &#125;, &quot;metrics-requiredMetricName&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/metrics/&#123;requiredMetricName&#125;&quot;, &quot;templated&quot;:true &#125;, &quot;metrics&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/metrics&quot;, &quot;templated&quot;:false &#125;, &quot;scheduledtasks&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/scheduledtasks&quot;, &quot;templated&quot;:false &#125;, &quot;httptrace&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/httptrace&quot;, &quot;templated&quot;:false &#125;, &quot;mappings&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/mappings&quot;, &quot;templated&quot;:false &#125;, &quot;refresh&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/refresh&quot;, &quot;templated&quot;:false &#125;, &quot;features&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/features&quot;, &quot;templated&quot;:false &#125;, &quot;service-registry&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/service-registry&quot;, &quot;templated&quot;:false &#125;, &quot;jolokia&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/jolokia&quot;, &quot;templated&quot;:false &#125;, &quot;hystrix.stream&quot;:&#123; &quot;href&quot;:&quot;http://127.0.0.1:8801/actuator/hystrix.stream&quot;, &quot;templated&quot;:false &#125; &#125;&#125; 4）输入http://127.0.0.1:8801/actuator/health，查看`health`端点信息如下： 1234567891011121314151617181920212223242526272829303132333435363738394041&#123; &quot;status&quot;:&quot;UP&quot;, &quot;details&quot;:&#123; &quot;diskSpace&quot;:&#123; &quot;status&quot;:&quot;UP&quot;, &quot;details&quot;:&#123; &quot;total&quot;:124945166336, &quot;free&quot;:738893824, &quot;threshold&quot;:10485760 &#125; &#125;, &quot;refreshScope&quot;:&#123; &quot;status&quot;:&quot;UP&quot; &#125;, &quot;discoveryComposite&quot;:&#123; &quot;status&quot;:&quot;UP&quot;, &quot;details&quot;:&#123; &quot;discoveryClient&quot;:&#123; &quot;status&quot;:&quot;UP&quot;, &quot;details&quot;:&#123; &quot;services&quot;:[ ] &#125; &#125;, &quot;eureka&quot;:&#123; &quot;description&quot;:&quot;Eureka discovery client has not yet successfully connected to a Eureka server&quot;, &quot;status&quot;:&quot;UP&quot;, &quot;details&quot;:&#123; &quot;applications&quot;:&#123; &#125; &#125; &#125; &#125; &#125;, &quot;hystrix&quot;:&#123; &quot;status&quot;:&quot;UP&quot; &#125; &#125;&#125;","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"},{"name":"监控","slug":"监控","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Thread Dump日志分析案例","slug":"jvm/ThreadDump日志分析案例","date":"2021-02-12T10:32:11.000Z","updated":"2024-02-14T12:06:21.578Z","comments":false,"path":"2021/02/12/jvm/ThreadDump日志分析案例/","permalink":"https://imalan6.github.io/hexo_blog/2021/02/12/jvm/ThreadDump%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/","excerpt":"","text":"Thread Dump日志分析案例线程状态Thread Dump 文件里，值得关注的线程状态有： 1）死锁，Deadlock（重点关注） 2）执行中，Runnable 3）等待资源，Waiting on condition（重点关注） 4）等待获取监视器，Waiting on monitor entry（重点关注） 5）暂停，Suspended 6）对象等待中，Object.wait() 或 TIMED_WAITING 7）阻塞，Blocked（重点关注） 8）停止，Parked 案例分析日志组成要素123456789101112131415&quot;resin-22129&quot; daemon prio=10 tid=0x00007fbe5c34e000 nid=0x4cb1 waiting on condition [0x00007fbe4ff7c000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:315) at com.caucho.env.thread2.ResinThread2.park(ResinThread2.java:196) at com.caucho.env.thread2.ResinThread2.runTasks(ResinThread2.java:147) at com.caucho.env.thread2.ResinThread2.run(ResinThread2.java:118)&quot;Timer-20&quot; daemon prio=10 tid=0x00007fe3a4bfb800 nid=0x1a31 in Object.wait() [0x00007fe3a077a000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000006f0620ff0&gt; (a java.util.TaskQueue) at java.util.TimerThread.mainLoop(Timer.java:552) - locked &lt;0x00000006f0620ff0&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505) 以上依次是： 1）&quot;resin-22129&quot;线程名称：如果使用java.lang.Thread类生成一个线程的时候，线程名称为 Thread-(数字) 的形式，这里是resin生成的线程； 2）daemon线程类型：线程分为守护线程 (daemon) 和非守护线程 (non-daemon) 两种，通常都是守护线程； 3）prio=10线程优先级：默认为5，数字越大优先级越高； 4）tid=0x00007fbe5c34e000JVM线程的id：JVM 内部线程的唯一标识，通过java.lang.Thread.getId()获取，通常用自增的方式实现； 5）nid=0x4cb1系统线程id：对应的系统线程id（Native Thread ID)，可以通过 top 命令进行查看，现场id是十六进制的形式； 6）waiting on condition系统线程状态：这里是系统的线程状态； 7）[0x00007fbe4ff7c000]起始栈地址：线程堆栈调用的其实内存地址； 8）java.lang.Thread.State: WAITING (parking)JVM线程状态：这里标明了线程在代码级别的状态。 9）线程调用栈信息：下面就是当前线程调用的详细栈信息，用于代码的分析。堆栈信息应该从下向上解读，因为程序调用的顺序是从下向上的。 案例一：Waiting to lock 和 Blocked123456789&quot;RMI TCP Connection(267865)-172.16.5.25&quot; daemon prio=10 tid=0x00007fd508371000 nid=0x55ae waiting for monitor entry [0x00007fd4f8684000]java.lang.Thread.State: BLOCKED (on object monitor) at org.apache.log4j.Category.callAppenders(Category.java:201) - waiting to lock &lt;0x00000000acf4d0c0&gt; (a org.apache.log4j.Logger) at org.apache.log4j.Category.forcedLog(Category.java:388) at org.apache.log4j.Category.log(Category.java:853) at org.apache.commons.logging.impl.Log4JLogger.warn(Log4JLogger.java:234) at com.tuan.core.common.lang.cache.remote.SpyMemcachedClient.get(SpyMemcachedClient.java:110)…… 1）线程状态是 Blocked，阻塞状态。说明线程等待资源超时了。 2）“waiting to lock &lt;0x00000000acf4d0c0&gt;” 指线程在等待给0x00000000acf4d0c0这个地址上锁。 3）在dump日志里查找字符串0x00000000acf4d0c0，发现有大量线程都在等待给这个地址上锁。如果能在日志里找到谁获得了这个锁（如locked &lt; 0x00000000acf4d0c0 &gt;），就可以顺藤摸瓜了。 4）“waiting for monitor entry” 说明此线程通过synchronized(obj) &#123;……&#125;申请进入了临界区，从而进入了下图1中的 “Entry Set” 队列，但该 obj 对应的monitor被其他线程拥有，所以本线程在Entry Set队列中等待。 5）第一行里，”RMI TCP Connection(267865)-172.16.5.25“是 Thread Name 。tid指Java Thread id。nid指native线程的 id。prio是线程优先级。[0x00007fd4f8684000] 是线程栈起始地址。 Dump文件中的线程状态含义及注意事项： Deadlock：死锁线程，一般指多个线程调用间，进入相互资源占用，导致一直等待无法释放的情况。 Runnable：一般指该线程正在执行状态中，该线程占用了资源，正在处理某个请求，有可能正在传递SQL到数据库执行，有可能在对某个文件操作，有可能进行数据类型等转换。 Waiting on condition：等待资源，或等待某个条件的发生，具体原因需结合stack trace来分析。 如果堆栈信息明确是应用代码，则证明该线程正在等待资源。一般是大量读取某资源，且该资源采用了资源锁的情况下，线程进入等待状态，等待资源的读取，也可能是正在等待其他线程的执行等。 如果发现有大量的线程都在处在Wait on condition，从线程栈看，正等待网络读写，这可能是网络瓶颈的一个征兆。可能是由于网络阻塞导致线程无法执行： 一种情况是网络非常忙，几乎消耗了所有的带宽，仍然有大量数据等待网络读写； 另一种情况也可能是网络空闲，但由于路由等问题，导致包无法正常的到达。 另外一种出现Wait on condition的常见情况是该线程在sleep，等待sleep的时间到了时候，将被唤醒。 Blocked：线程阻塞，是指当前线程执行过程中，所需要的资源长时间等待却一直未能获取到，被容器的线程管理器标识为阻塞状态，可以理解为等待资源超时的线程。 Waiting for monitor entry 和 in Object.wait()：Monitor是 Java 中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者class的锁。每一个对象都有且仅有一个monitor。从下图1中可以看出，每个Monitor在某个时刻，只能被一个线程拥有，该线程就是 “Active Thread”，而其它线程都是 “Waiting Thread”，分别在两个队列 “Entry Set” 和 “Wait Set” 里面等候。在 “Entry Set” 中等待的线程状态是 “Waiting for monitor entry”，而在 “Wait Set” 中等待的线程状态是 “in Object.wait()”。 案例二：Waiting on condition 和 TIMED_WAITING1234567891011&quot;RMI TCP Connection(idle)&quot; daemon prio=10 tid=0x00007fd50834e800 nid=0x56b2 waiting on condition [0x00007fd4f1a59000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000acd84de8&gt; (a java.util.concurrent.SynchronousQueue$TransferStack) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198) at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424) at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323) at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:945) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907) at java.lang.Thread.run(Thread.java:662) 1）“TIMED_WAITING (parking)” 中的timed_waiting指等待状态，但这里指定了时间，到达指定的时间后自动退出等待状态；parking指线程处于挂起中。 2）“waiting on condition” 需要与堆栈中的 “parking to wait for &lt;0x00000000acd84de8&gt; (a java.util.concurrent.SynchronousQueue$TransferStack)” 结合来看。首先，本线程肯定是在等待某个条件的发生，来把自己唤醒。其次，SynchronousQueue并不是一个队列，只是线程之间移交信息的机制，当我们把一个元素放入到SynchronousQueue中时必须有另一个线程正在等待接受移交的任务，因此这就是本线程在等待的条件。 3）其他也看不出来什么。 案例三：in Obejct.wait() 和 TIMED_WAITING12345678&quot;RMI RenewClean-[172.16.7.19:28475]&quot; daemon prio=10 tid=0x0000000041428800 nid=0xb09 in Object.wait() [0x00007f34f4bd0000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x00000000aa672478&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118) - locked &lt;0x00000000aa672478&gt; (a java.lang.ref.ReferenceQueue$Lock) at sun.rmi.transport.DGCClient$EndpointEntry$RenewCleanThread.run(DGCClient.java:516) at java.lang.Thread.run(Thread.java:662) 1）“TIMED_WAITING (on object monitor)”，对于本例而言，是因为本线程调用了java.lang.Object.wait(long timeout)而进入等待状态。 2）“Wait Set” 中等待的线程状态就是“in Object.wait()”。当线程获得了Monitor，进入了临界区之后，如果发现线程继续运行的条件没有满足，它则调用对象（一般就是被synchronized的对象）的wait()方法，放弃了Monitor，进入 “Wait Set” 队列。只有当别的线程在该对象上调用了notify()或者notifyAll()，“Wait Set” 队列中线程才得到机会去竞争，但是只有一个线程获得对象的Monitor，恢复到运行态。 3）RMI RenewClean是DGCClient的一部分。DGC指的是Distributed GC，即分布式垃圾回收。 4）请注意，是先locked &lt;0x00000000aa672478&gt;，后waiting on &lt;0x00000000aa672478&gt;，之所以先锁再等同一个对象，请看下面它的代码实现： 12345678910111213static private class Lock &#123; &#125;;private Lock lock = new Lock();public Reference&lt;? extends T&gt; remove(long timeout)&#123; synchronized (lock) &#123; Reference&lt;? extends T&gt; r = reallyPoll(); if (r != null) return r; for (;;) &#123; lock.wait(timeout); r = reallyPoll(); …… &#125;&#125; 即线程执行过程中，先用synchronized获得了这个对象的Monitor（对应于locked &lt;0x00000000aa672478&gt;）；当执行到lock.wait(timeout);，线程就放弃了Monitor的所有权，进入 “Wait Set” 队列（对应于waiting on &lt;0x00000000aa672478&gt;）。 5）从堆栈信息看，是正在清理remote references to remote objects，引用的租约到了，分布式垃圾回收在逐一清理。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"},{"name":"故障排查","slug":"故障排查","permalink":"https://imalan6.github.io/hexo_blog/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"}]},{"title":"生产环境CPU 100%解决思路","slug":"jvm/生产环境CPU100解决思路","date":"2020-12-16T14:16:52.000Z","updated":"2024-02-14T12:04:57.464Z","comments":false,"path":"2020/12/16/jvm/生产环境CPU100解决思路/","permalink":"https://imalan6.github.io/hexo_blog/2020/12/16/jvm/%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83CPU100%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF/","excerpt":"","text":"生产环境CPU 100%解决思路排查方案如果服务器上部署了若干个Java服务，突然CPU异常告警。定位问题简要步骤如下： 1）找到最耗 CPU 的进程； 2）找到最耗 CPU 的线程； 3）查看堆栈信息，分析线程状态，定位问题代码； 一般来说，有必要在第1步找到问题进程后先使用jstack工具dump出堆栈日志。如果服务很重要，可以先考虑重启服务，保证线上服务的可用性，后面慢慢分析堆栈日志，找出问题。 查看耗时进程执行top命令，查看 CPU 占用率最高的进程，找出进程 ID。 查看耗时线程使用top -Hp &lt;pid&gt;命令，找出进程中最耗CPU的线程，并获得线程ID。 查看线程堆栈由于获得的线程id是十进制形式的，而在堆栈日志中，线程id是十六进制的，所以可以使用命令printf &quot;%x\\n&quot; 10804（也可以使用计算器），将十进制转换为十六进制，方便查找。得到 10804 对应的十六进制是0x2a34。 接着，使用命令jstack 10765 | grep &#39;0x2a34&#39; -C5 --color查看线程堆栈信息。当然，也可以使用jstack 10765 &gt; dump.log命令将堆栈日志保存下来离线分析。 如上图，找到了耗CPU高的线程对应的线程名称 “AsyncLogger-1”，以及看到了该线程正在执行代码的堆栈。 Thread Dump日志分析在thread dump文件里，需要关注的线程状态有： 死锁，Deadlock（重点关注） 执行中，Runnable 等待资源，Waiting on condition（重点关注） 等待获取监视器，Waiting on monitor entry（重点关注） 暂停，Suspended 对象等待中，Object.wait()或TIMED_WAITING 阻塞，Blocked（重点关注） 停止，Parked 保存的日志已经可以直接分析了，但是不是很直观，可以使用其他工具： Thread Dump Analyzer工具TDA（下载地址：https://github.com/irockel/tda/） 在线分析工具：http://spotify.github.io/threaddump-analyzer/ ThreadDump日志分析案例详见 Thread Dump日志分析案例。 JVM常见线程总结 线程名称 所属 解释说明 Attach Listener JVM Attach Listener 线程是负责接收到外部的命令，而对该命令进行执行的并且吧结果返回给发送者。通常我们会用一些命令去要求 jvm 给我们一些反馈信息，如：java -version、jmap、jstack 等等。 如果该线程在 jvm 启动的时候没有初始化，那么，则会在用户第一次执行 jvm 命令时，得到启动。 Signal Dispatcher JVM 前面我们提到第一个 Attach Listener 线程的职责是接收外部 jvm 命令，当命令接收成功后，会交给 signal dispather 线程去进行分发到各个不同的模块处理命令，并且返回处理结果。 signal dispather 线程也是在第一次接收外部 jvm 命令时，进行初始化工作。 CompilerThread0 JVM 用来调用JITing，实时编译装卸class 。 通常，jvm会启动多个线程来处理这部分工作，线程名称后面的数字也会累加，例如：CompilerThread1 Concurrent Mark-Sweep GC Thread JVM 并发标记清除垃圾回收器（就是通常所说的CMS GC）线程， 该线程主要针对于老年代垃圾回收。ps：启用该垃圾回收器，需要在jvm启动参数中加上： -XX:+UseConcMarkSweepGC DestroyJavaVM JVM 执行 main() 的线程在 main 执行完后调用 JNI中 的 jni_DestroyJavaVM() 方法唤起DestroyJavaVM 线程。 JVM在 Jboss 服务器启动之后，就会唤起DestroyJavaVM线程，处于等待状态，等待其它线程（java线程和native线程）退出时通知它卸载JVM。 ContainerBackgroundProcessor 线程 JBOSS 它是一个守护线程, 在jboss服务器在启动的时候就初始化了,主要工作是定期去检查有没有Session过期.过期则清除 Dispatcher-Thread-3 线程 Log4j Log4j 具有异步打印日志的功能，需要异步打印日志的 Appender 都需要注册到 AsyncAppender 对象里面去，由 AsyncAppender 进行监听，决定何时触发日志打印操作。 Finalizer 线程 JVM 这个线程也是在main线程之后创建的，其优先级为10，主要用于在垃圾收集前，调用对象的 finalize() 方法 Gang worker#0 JVM JVM 用于做新生代垃圾回收（monir gc）的一个线程。#号后面是线程编号，例如：Gang worker#1 GC Daemon JVM GC Daemon 线程是 JVM 为 RMI 提供远程分布式 GC 使用的，GC Daemon 线程里面会主动调用System.gc() 方法，对服务器进行Full GC。 IdleRemover JBOSS Jboss连接池有一个最小值， 该线程每过一段时间都会被Jboss唤起，用于检查和销毁连接池中空闲和无效的连接，直到剩余的连接数小于等于它的最小值。 Java2D Disposer JVM 这个线程主要服务于 awt 的各个组件。 InsttoolCacheScheduler_QuartzSchedulerThread Quartz InsttoolCacheScheduler_QuartzSchedulerThread 是 Quartz 的主线程，它主要负责实时的获取下一个时间点要触发的触发器，然后执行触发器相关联的作业 。 InsttoolCacheScheduler_Worker-2 Quartz InsttoolCacheScheduler_Worker-2线程就是ThreadPool线程的一个简单实现，它主要负责分配线程资源去执行InsttoolCacheScheduler_QuartzSchedulerThread线程交给它的调度任务（也就是JobRunShell）。 JBossLifeThread Jboss Jboss主线程启动成功，应用程序部署完毕之后将JBossLifeThread线程实例化并且start，JBossLifeThread线程启动成功之后就处于等待状态，以保持Jboss Java进程处于存活中。 所得比较通俗一点，就是Jboss启动流程执行完毕之后，为什么没有结束？ 就是因为有这个线程hold主了它。 牛b吧～～ JBoss System Threads(1)-1 Jboss 该线程是一个socket服务，默认端口号为： 1099。 主要用于接收外部naming service（Jboss JNDI）请求。 JCA PoolFiller Jboss 该线程主要为JBoss内部提供连接池的托管。 JDWP Event Helper Thread JVM JDWP是通讯交互协议，它定义了调试器和被调试程序之间传递信息的格式。它详细完整地定义了请求命令、回应数据和错误代码，保证了前端和后端的JVMTI和JDI的通信通畅。 该线程主要负责将JDI事件映射成JVMTI信号，以达到调试过程中操作JVM的目的。 JDWP Transport Listener: dt_socket JVM 该线程是一个Java Debugger的监听器线程，负责受理客户端的debug请求。 通常我们习惯将它的监听端口设置为8787。 Low Memory Detector JVM 这个线程是负责对可使用内存进行检测，如果发现可用内存低，分配新的内存空间。 process reaper JVM 该线程负责去执行一个 OS 命令行的操作。 Reference Handler JVM JVM在创建main线程后就创建Reference Handler线程，其优先级最高，为10，它主要用于处理引用对象本身（软引用、弱引用、虚引用）的垃圾回收问题 。 Surrogate Locker Thread (CMS) JVM 这个线程主要用于配合CMS垃圾回收器使用，它是一个守护线程，其主要负责处理GC过程中，Java层的Reference（指软引用、弱引用等等）与jvm 内部层面的对象状态同步。 taskObjectTimerFactory JVM 顾名思义，该线程就是用来执行任务的。 当我们把一个认为交给Timer对象，并且告诉它执行时间，周期时间后，Timer就会将该任务放入任务列队，并且通知taskObjectTimerFactory线程去处理任务，taskObjectTimerFactory线程会将状态为取消的任务从任务列队中移除，如果任务是非重复执行类型的，则在执行完该任务后，将它从任务列队中移除，如果该任务是需要重复执行的，则计算出它下一次执行的时间点。 VM Periodic Task Thread JVM 该线程是 JVM 周期性任务调度的线程，它由 WatcherThread 创建，是一个单例对象。 该线程在 JVM 内使用得比较频繁，比如：定期的内存监控、JVM 运行状况监控，还有经常需要去执行一些 jstat 这类命令查看gc的情况，如下：jstat -gcutil 23483 250 7 这个命令告诉jvm 在控制台打印 PID 为：23483 的 gc 情况，间隔250毫秒打印一次，一共打印7次。 VM Thread JVM 这个线程是jvm里面的线程母体，根据hotspot 源码（vmThread.cpp）里面的注释，它是一个单例的对象（最原始的线程）会产生或触发所有其他的线程，这个单个的VM线程是会被其他线程所使用来做一些 VM 操作（如，清扫垃圾等）。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"},{"name":"故障排查","slug":"故障排查","permalink":"https://imalan6.github.io/hexo_blog/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"}]},{"title":"JVM调优总结","slug":"jvm/JVM调优总结","date":"2020-11-12T13:33:16.000Z","updated":"2024-02-14T11:20:05.059Z","comments":false,"path":"2020/11/12/jvm/JVM调优总结/","permalink":"https://imalan6.github.io/hexo_blog/2020/11/12/jvm/JVM%E8%B0%83%E4%BC%98%E6%80%BB%E7%BB%93/","excerpt":"","text":"JVM调优总结性能调优性能调优包含多个层次，包括架构调优、代码调优、JVM调优、数据库调优和操作系统调优等。架构调优和代码调优是JVM调优的基础，其中架构调优是对系统影响最大的。 JVM调优目标JVM调优的最终目的是让应用程序以最小的硬件承载更大的吞吐。JVM调优主要是针对垃圾收集器的收集性能优化，让应用程序占用更少的内存和延迟，但拥有更大的吞吐量。JVM内存系统级调优主要的目的是减少GC的频率和Full GC的次数。 Full GC：包括Young、Tenured和Perm。因为Full GC需要对整个堆进行回收，所以比较慢，因此应尽可能减少Full GC次数。 导致Full GC的原因： 年老代（Tenured）被写满：尽量让对象在新生代GC时就被回收，让对象在新生代多存活一段时间。另外，不要创建过大的对象及数组，避免其直接在老年代创建对象 。 永久代Pemanet Generation空间不足（Java1.8 以后没有永久代）：增大Perm Gen空间，避免太多静态对象 ， 控制好新生代和旧生代的比例 System.gc()被显示调用：垃圾回收不要手动触发，尽量由 JVM 触发垃圾回收 何时需要JVM调优遇到以下情况，就需要考虑JVM调优了： Heap内存（老年代）持续上涨达到设置的最大内存值； FullGC次数频繁； GC停顿时间过长（超过1秒）； 应用出现OutOfMemory等内存异常； 应用中有使用本地缓存且占用大量内存空间； 系统吞吐量与响应性能不高或下降。 JVM调优量化目标JVM调优的量化目标参考实例： Heap 内存使用率 &lt;&#x3D; 70%; Old generation 内存使用率&lt;&#x3D; 70%; avgpause &lt;&#x3D; 1秒; Full gc次数为0 或avg pause interval&gt;&#x3D; 24 小时 ; 注意：不同应用的 JVM 调优量化目标是不一样的，这里只是一种建议。 JVM调优步骤一般情况下，JVM调优可通过以下步骤进行： 分析GC日志及dump文件，判断是否需要优化，确定瓶颈问题点； 确定JVM调优量化目标； 确定JVM调优参数（根据历史JVM参数来调整）； 依次调优内存、延迟、吞吐量等指标； 对比观察调优前后的差异； 不断的分析和调整，直到找到合适的JVM参数配置； 找到最合适的参数，将这些参数应用到所有服务器，并进行后续跟踪。 以上操作步骤需要多次不断迭代完成。一般是从满足程序的内存使用需求开始，然后是时间延迟要求，最后是吞吐量要求，要基于这个步骤不断优化。 JVM参数规范JVM调优最主要的方法就是通过修改JVM参数达到调优的目的。 -XX 参数被称为不稳定参数，此类参数的设置很容易引起JVM性能上的差异，使JVM存在极大的不稳定性。如果此类参数设置合理将大大提高JVM的性能及稳定性。 不稳定参数语法规则包含以下内容。 布尔类型参数值： -XX:+ ‘+’表示启用该选项 -XX:- ‘-‘表示关闭该选项 数字类型参数值： -XX:&#x3D;给选项设置一个数字类型值，可跟随单位，例如：’m’或’M’表示兆字节;’k’或’K’千字节;’g’或’G’千兆字节。32K与32768是相同大小的。 字符串类型参数值： -XX:&#x3D;给选项设置一个字符串类型值，通常用于指定一个文件、路径或一系列命令列表。例如：-XX:HeapDumpPath=./dump.core JVM部分参数解析比如以下参数示例： 1-Xmx4g –Xms4g –Xmn1200m –Xss512k -XX:NewRatio=4 -XX:SurvivorRatio=8 -XX:PermSize=100m -XX:MaxPermSize=256m -XX:MaxTenuringThreshold=15 上面为 Java7 及以前版本的示例，在 Java8 中永久代的参数-XX:PermSize和-XX:MaxPermSize已经失效。 参数解析： -Xmx4g：堆内存最大值为4GB。 -Xms4g：初始化堆内存大小为4GB。 -Xmn1200m：设置年轻代大小为1200MB。增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3&#x2F;8。 -Xss512k：设置每个线程的堆栈大小。JDK5.0 以后每个线程堆栈大小为1MB，以前每个线程堆栈大小为256K。应根据应用线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 -XX:NewRatio&#x3D;4：设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1 : 4，年轻代占整个堆栈的1&#x2F;5 -XX:SurvivorRatio&#x3D;8：设置年轻代中Eden区与Survivor区的大小比值。设置为8，则两个Survivor区与一个Eden区的比值为2 : 8，一个Survivor区占整个年轻代的1&#x2F;10 -XX:PermSize&#x3D;100m：初始化永久代大小为100MB。 -XX:MaxPermSize&#x3D;256m：设置持久代大小为256MB。 -XX:MaxTenuringThreshold&#x3D;15：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代的存活时间，让对象仅可能在年轻代即被回收。 新生代、老生代、永久代的参数，如果不进行指定，虚拟机会自动选择合适的值，同时也会基于系统的开销自动调整。 可调优参数： -Xms：初始化堆内存大小，默认为物理内存的1&#x2F;64(小于1GB)。 -Xmx：堆内存最大值。默认（MaxHeapFreeRatio 参数可以调整）空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。 -Xmn：新生代大小，包括Eden区与2个Survivor区。 -XX:SurvivorRatio&#x3D;1：Eden区与一个Survivor区比值为1 : 1。 -XX:MaxDirectMemorySize&#x3D;1G：直接内存。报java.lang.OutOfMemoryError: Direct buffer memory异常可以上调这个值。 -XX:+DisableExplicitGC：禁止运行期显式地调用System.gc()来触发FulllGC。 注意: Java RMI 的定时 GC 触发机制可通过配置-Dsun.rmi.dgc.server.gcInterval=86400来控制触发的时间。 -XX:CMSInitiatingOccupancyFraction&#x3D;60：老年代内存回收阈值，默认值为68。 -XX:ConcGCThreads&#x3D;4：CMS 垃圾回收器并行线程线，推荐值为 CPU 核心数。 -XX:ParallelGCThreads&#x3D;8：新生代并行收集器的线程数。 -XX:MaxTenuringThreshold&#x3D;10：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代的存活时间，让对象仅可能在年轻代即被回收。 -XX:CMSFullGCsBeforeCompaction&#x3D;4：指定进行多少次FullGC之后，进行tenured区 内存空间压缩。 -XX:CMSMaxAbortablePrecleanTime&#x3D;500：当abortable-preclean预清理阶段执行达到这个时间时就会结束。 在设置的时候，如果关注性能开销的话，应尽量把永久代的初始值与最大值设置为同一值，因为永久代的大小调整需要进行FullGC才能实现。 内存优化示例众所周知，由于Full GC的成本远远高于Minor GC，因此某些情况下需要尽可能将对象分配在年轻代，这在很多情况下是一个明智的选择。虽然在大部分情况下，JVM会尝试在Eden区分配对象，但是由于空间紧张等问题，很可能不得不将部分年轻对象提前向年老代压缩。因此，在JVM参数调优时可以为应用程序分配一个合理的年轻代空间，以最大限度避免新对象直接进入年老代的情况发生。如下所示代码尝试分配 4MB 内存空间，看一下它的内存使用情况。 123456789public class GCTest &#123; public static void main(String[] args)&#123; byte[] b1,b2,b3,b4; b1=new byte[1024*1024]; //分配 1MB 堆空间，观察堆空间的使用情况 b2=new byte[1024*1024]; b3=new byte[1024*1024]; b4=new byte[1024*1024]; &#125;&#125; 并使用JVM参数-XX:+PrintGCDetails -Xmx20M -Xms20M运行以上代码，输出结果如下： 12345678910[GC (Allocation Failure) [PSYoungGen: 4673K-&gt;504K(6144K)] 4673K-&gt;3083K(19968K), 0.0023390 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap PSYoungGen total 6144K, used 2717K [0x00000000ff980000, 0x0000000100000000, 0x0000000100000000) eden space 5632K, 39% used [0x00000000ff980000,0x00000000ffba94d8,0x00000000fff00000) from space 512K, 98% used [0x00000000fff00000,0x00000000fff7e010,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 13824K, used 2579K [0x00000000fec00000, 0x00000000ff980000, 0x00000000ff980000) object space 13824K, 18% used [0x00000000fec00000,0x00000000fee84c90,0x00000000ff980000) Metaspace used 3178K, capacity 4496K, committed 4864K, reserved 1056768K class space used 344K, capacity 388K, committed 512K, reserved 1048576K 以上结果所示的日志输出显示年轻代Eden的大小有 6MB 左右，在分配空间的时候触发了MinorGC，并将对象移到了老年代。其中： [PSYoungGen: 4673K-&gt;504K(6144K)] 4673K-&gt;3083K(19968K), 0.0023390 secs] [Times: user&#x3D;0.00 sys&#x3D;0.00, real&#x3D;0.00 secs] 以上GC日志各要素含义如下： [PSYoungGen: 4673K-&gt;504K(6144K)] ：[日志类型：YoungGC前新生代内存占用 -&gt; YoungGC后新生代内存占用（新生代总共大小）] ； 4673K-&gt;3083K(19968K), 0.0023390 secs：YoungGC 前 JVM 堆内存占用 -&gt; YoungGC 后 JVM 堆内存占用（JVM 堆总大小），YoungGC 耗时； **[Times: user&#x3D;0.00 sys&#x3D;0.00, real&#x3D;0.00 secs]**：[YoungGC 用户耗时，YoungGC 系统耗时，YoungGC 实际耗时] 现在分配足够大的年轻代空间，使用JVM参数-XX:+PrintGCDetails -Xmx20M -Xms20M -Xmn10M再次运行以上代码，输出结果如下： 123456789Heap PSYoungGen total 9216K, used 7093K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) eden space 8192K, 86% used [0x00000000ff600000,0x00000000ffced410,0x00000000ffe00000) from space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000) to space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000) ParOldGen total 10240K, used 0K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) object space 10240K, 0% used [0x00000000fec00000,0x00000000fec00000,0x00000000ff600000) Metaspace used 3206K, capacity 4496K, committed 4864K, reserved 1056768K class space used 349K, capacity 388K, committed 512K, reserved 1048576K 通过两次结果对比，可以发现通过设置一个较大的年轻代，可以将年轻对象保存在年轻代。一般来说，Survivor区的空间不够，或者占用量达到 50%时，就会使对象进入年老代 (不管它的年龄有多大)。 延迟优化示例对延迟性优化，首先需要了解延迟性需求及可调优的指标。 应用程序可接受的平均停滞时间: 此时间与测量的时间比较 GC持续时间进行比较，可接受的MinorGC频率 GC的频率与可容忍的值进行比较。 最大停顿时间与最差情况下FullGC的持续时间进行比较。 可接受的最大停顿发生的频率：基本就是FullGC的频率。 其中，平均停滞时间和最大停顿时间，对用户体验最为重要。对于上面的指标，相关数据采集包括：MinorGC的持续时间、统计MinorGC的次数、FullGC的最差持续时间、最差情况下，FullGC的频率。 如上图，MinorGC的平均持续时间 0.069 秒，MinorGC的频率为 0.389 秒一次。 新生代空间越大，MinorGC的GC时间越长，频率越低。如果想减少其持续时长，就需要减少其空间大小。如果想减小其频率，就需要加大其空间大小。 这里以减少了新生代空间 10% 的大小，来减小延迟时间。在此过程中，应该保持老年代和持代的大小不变化。调优后的参数如下变化: 1java -Xms359m -Xmx359m -Xmn126m -XX:PermSize=5m -XX:MaxPermSize=5m 吞吐量调优吞吐量调优主要是基于应用程序的吞吐量要求而来的，应用程序应该有一个综合的吞吐指标，这个指标基于整个应用的需求和测试而衍生出来。 评估当前吞吐量和目标差距是否巨大，如果在20%左右，可以修改参数，加大内存，再次从头调试，如果巨大就需要从整个应用层面来考虑，设计以及目标是否一致了，重新评估吞吐目标。 对于垃圾收集器来说，提升吞吐量的性能调优的目标就是尽可能避免或者很少发生FullGC或者Stop-The-World压缩式垃圾收集（CMS），因为这两种方式都会造成应用程序吞吐降低。尽量在MinorGC阶段回收更多的对象，避免对象提升过快到老年代。 开启GC日志 开启语句 1234-XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/gc-regionserver.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=512k 参数详解 -XX:+PrintGCDetails输出 GC 的详细日志 -XX:+PrintGCDateStamps输出 GC 的日期戳 -Xloggc:&#x2F;var&#x2F;log&#x2F;gc-regionserver.logGC 日志输出的路径 -XX:+UseGCLogFileRotation打开 GC 日志滚动记录功能 -XX:NumberOfGCLogFiles设置滚动日志文件的个数，必须大于等于1日志文件命名策略是，.0, .1, …, .n-1，其中n是该参数的值 -XX:GCLogFileSize设置滚动日志文件的大小，必须大于8k当前写日志文件大小超过该参数值时，日志将写入下一个文件 其他有用参数 -XX:+PrintGCApplicationStoppedTime打印 GC 造成应用暂停的时间 -XX:+PrintHeapAtGC在进行 GC 的前后打印出堆的信息 -XX:+PrintTenuringDistribution在每次新生代young GC时，输出幸存区中对象的年龄分布 GC日志分析工具 GCeasy GCeasy是一款在线的GC日志分析器，可以通过GC日志分析进行内存泄露检测、GC暂停原因分析、JVM配置建议优化等功能，而且是可以免费使用的。 网址：https://gceasy.io/ GCViewer 借助GCViewer日志分析工具，可以非常直观地分析出JVM待调优点。可从以下几方面来分析： Memory：分析Totalheap、Tenuredheap、Youngheap内存占用率及其他指标，理论上内存占用率越小越好； Pause：分析Gc pause、Fullgc pause、Total pause三个大项中各指标，理论上GC次数越少越好，GC时长越小越好； 工具下载地址：https://github.com/chewiebug/GCViewer","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"},{"name":"jvm调优","slug":"jvm调优","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm%E8%B0%83%E4%BC%98/"}]},{"title":"pringBoot配置Slf4j和Logback","slug":"springboot/SpringBoot配置Slf4j和Logback","date":"2020-09-12T05:11:56.000Z","updated":"2024-02-14T11:29:03.372Z","comments":false,"path":"2020/09/12/springboot/SpringBoot配置Slf4j和Logback/","permalink":"https://imalan6.github.io/hexo_blog/2020/09/12/springboot/SpringBoot%E9%85%8D%E7%BD%AESlf4j%E5%92%8CLogback/","excerpt":"","text":"SpringBoot配置Slf4j和LogbackLogbackSpringBoot在所有内部日志中使用Commons Logging，但是默认配置也提供了对常用日志的支持，如：Java Util Logging，Log4J，Log4J2和Logback。每种Logger都可以通过配置使用控制台或者文件输出日志内容。 Logback是log4j框架的作者开发的新一代日志框架，它效率更高、能够适应诸多的运行环境，同时天然支持SLF4J。因为logback的效率显著高于log4j，而且logback也是Springboot推荐并且默认使用的日志系统。 默认情况下，SpringBoot会用Logback来记录日志，并用INFO级别输出到控制台。 日志输出内容元素具体如下： 时间日期：精确到毫秒 日志级别：ERROR, WARN, INFO, DEBUG or TRACE 进程ID 分隔符：标识实际日志的开始 线程名：方括号括起来（可能会截断控制台输出） Logger名：通常使用源代码的类名 日志内容 添加日志依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot应用将自动使用logback作为应用日志框架，SpringBoot启动时，由org.springframework.boot.logging.Logging-Application-Listener根据情况初始化并使用。但实际开发中，不需要添加该依赖，因为spring-boot-starter中已经包含了spring-boot-starter-logging，该依赖内容就是SpringBoot默认的日志框架logback。 Slf4j简介Slf4j的全称是Simple Loging Facade For Java(Java简单日志门面)，它是一个针对于各类Java日志框架的统一Facade抽象。Java日志框架众多，常用的有java.util.logging, log4j, logback，commons-logging, Spring框架使用的是Jakarta Commons Logging API (JCL)。 SLF4J定义了统一的日志抽象接口，而真正的日志实现则是在运行时决定的，它提供了各类日志框架的binding。 SLF4J仅仅是一个为Java程序提供日志输出的统一接口，并不是一个具体的日志实现方案，就比如JDBC一样，只是一种规则而已。所以单独的Slf4j是不能工作的，必须搭配其他具体的日志实现方案，比如apache的org.apache.log4j.Logger，jdk自带的java.util.logging.Logger等。 优势解耦客户端。Slf4j只是一种接口，它本身并不关心底层使用什么日志实现方案，所以它支持各种日志实现方案。简单的说，只要我们在类库中使用Slf4j打日志，那么底层使用什么日志实现方案是由使用者决定的，依靠的是配置文件和jar库。 提高效率。Slf4j打印日志使用&#123;&#125;占位符，这样就不会有字符串拼接操作，减少了无用String对象的数量，节省了内存，也提高了效率，同时编码更加方便。 log级别Slf4j有四个级别的log level供选择，从上到下级别由低到高。 Debug：对程序调试有用的信息 info：了解程序运行状态有用的信息 warn：可能会导致错误的警告信息 error：程序运行出现错误的信息 @Slf4j注解使用Slf4j，自己写日志的时候需要使用logger成员变量， private final Logger logger = LoggerFactory.getLogger(LoggerTest.class); 每次写新的类都需要添加logger成员变量。有简单的方式，就是直接使用lombok的@Slf4j注解 首先，在maven依赖中引入lombok： 1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 另外，还需要在IDE中安装lombok插件，重启IDE即可。 Springboot配置日志添加如下依赖。如果是Springboot的话，已经在springboot starter中加入以下依赖了。 12345678&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件在resources下创建logback-spring.xml配置文件。 官方推荐使用的xml名字的格式为：logback-spring.xml而不是logback.xml，因为带-spring后缀的可以使用&lt;springProfile&gt;标签。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration debug=&quot;false&quot;&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name=&quot;LOG_HOME&quot; value=&quot;/home&quot; /&gt; &lt;!--控制台日志，控制台输出 --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度,%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--文件日志，按照每天生成日志文件 --&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt; &lt;logger name=&quot;org.hibernate.type.descriptor.sql.BasicBinder&quot; level=&quot;TRACE&quot; /&gt; &lt;logger name=&quot;org.hibernate.type.descriptor.sql.BasicExtractor&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;org.hibernate.SQL&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;org.hibernate.engine.QueryParameters&quot; level=&quot;DEBUG&quot; /&gt; &lt;logger name=&quot;org.hibernate.engine.query.HQLQueryPlan&quot; level=&quot;DEBUG&quot; /&gt; &lt;!--myibatis log configure--&gt; &lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt; &lt;logger name=&quot;java.sql.Connection&quot; level=&quot;DEBUG&quot;/&gt; &lt;logger name=&quot;java.sql.Statement&quot; level=&quot;DEBUG&quot;/&gt; &lt;logger name=&quot;java.sql.PreparedStatement&quot; level=&quot;DEBUG&quot;/&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;appender-ref ref=&quot;FILE&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; 附其他详细配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt;&lt;!-- scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true --&gt;&lt;!-- scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt;&lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;10 seconds&quot;&gt; &lt;!--&lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot; /&gt;--&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“$&#123;&#125;”来使用变量。 --&gt; &lt;property name=&quot;log.path&quot; value=&quot;D:/mylog&quot; /&gt; &lt;!-- 彩色日志(IDE下载插件才可以生效) --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=&quot;clr&quot; converterClass=&quot;org.springframework.boot.logging.logback.ColorConverter&quot; /&gt; &lt;conversionRule conversionWord=&quot;wex&quot; converterClass=&quot;org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter&quot; /&gt; &lt;conversionRule conversionWord=&quot;wEx&quot; converterClass=&quot;org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter&quot; /&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=&quot;CONSOLE_LOG_PATTERN&quot; value=&quot;$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(---)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;&quot;/&gt; &lt;!--输出到控制台--&gt; &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;info&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/Pattern&gt; &lt;!-- 设置字符集 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到文件--&gt; &lt;!-- 时间滚动输出 level为 DEBUG 日志 --&gt; &lt;appender name=&quot;DEBUG_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_debug.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/debug/log-debug-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录debug级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;debug&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出 level为 INFO 日志 --&gt; &lt;appender name=&quot;INFO_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_info.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/info/log-info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录info级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出 level为 WARN 日志 --&gt; &lt;appender name=&quot;WARN_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_warn.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/warn/log-warn-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录warn级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出 level为 ERROR 日志 --&gt; &lt;appender name=&quot;ERROR_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_error.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/error/log-error-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录ERROR级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- &lt;logger&gt;用来设置某一个包或者具体的某一个类的日志打印级别、 以及指定&lt;appender&gt;。&lt;logger&gt;仅有一个name属性， 一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前logger将会继承上级的级别。 addtivity:是否向上级logger传递打印信息。默认是true。 --&gt; &lt;!--&lt;logger name=&quot;org.springframework.web&quot; level=&quot;info&quot;/&gt;--&gt; &lt;!--&lt;logger name=&quot;org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor&quot; level=&quot;INFO&quot;/&gt;--&gt; &lt;!-- 使用mybatis的时候，sql语句是debug下才会打印，而这里我们只配置了info，所以想要查看sql语句的话，有以下两种操作： 第一种把&lt;root level=&quot;info&quot;&gt;改成&lt;root level=&quot;DEBUG&quot;&gt;这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种就是单独给dao下目录配置debug模式，代码如下，这样配置sql语句会打印，其他还是正常info级别： --&gt; &lt;!-- root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 不能设置为INHERITED或者同义词NULL。默认是DEBUG 可以包含零个或多个元素，标识这个appender将会添加到这个logger。 --&gt; &lt;!--开发环境:打印控制台--&gt; &lt;springProfile name=&quot;dev&quot;&gt; &lt;logger name=&quot;com.nmys.view&quot; level=&quot;debug&quot;/&gt; &lt;/springProfile&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;CONSOLE&quot; /&gt; &lt;appender-ref ref=&quot;DEBUG_FILE&quot; /&gt; &lt;appender-ref ref=&quot;INFO_FILE&quot; /&gt; &lt;appender-ref ref=&quot;WARN_FILE&quot; /&gt; &lt;appender-ref ref=&quot;ERROR_FILE&quot; /&gt; &lt;/root&gt; &lt;!--生产环境:输出到文件--&gt; &lt;!--&lt;springProfile name=&quot;pro&quot;&gt;--&gt; &lt;!--&lt;root level=&quot;info&quot;&gt;--&gt; &lt;!--&lt;appender-ref ref=&quot;CONSOLE&quot; /&gt;--&gt; &lt;!--&lt;appender-ref ref=&quot;DEBUG_FILE&quot; /&gt;--&gt; &lt;!--&lt;appender-ref ref=&quot;INFO_FILE&quot; /&gt;--&gt; &lt;!--&lt;appender-ref ref=&quot;ERROR_FILE&quot; /&gt;--&gt; &lt;!--&lt;appender-ref ref=&quot;WARN_FILE&quot; /&gt;--&gt; &lt;!--&lt;/root&gt;--&gt; &lt;!--&lt;/springProfile&gt;--&gt;&lt;/configuration&gt;","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"https://imalan6.github.io/hexo_blog/tags/springboot/"}]},{"title":"Netty零拷贝Zero-copy机制","slug":"netty/Netty零拷贝Zero-copy机制","date":"2020-07-26T05:17:02.000Z","updated":"2024-02-14T11:26:32.787Z","comments":false,"path":"2020/07/26/netty/Netty零拷贝Zero-copy机制/","permalink":"https://imalan6.github.io/hexo_blog/2020/07/26/netty/Netty%E9%9B%B6%E6%8B%B7%E8%B4%9DZero-copy%E6%9C%BA%E5%88%B6/","excerpt":"","text":"Netty零拷贝Zero-copy机制传统数据拷贝方式在传统数据拷贝方式中，如果遇到这样一个场景：需要从磁盘读取一个文件通过网络发送给客户端。服务端的实现步骤一般是使用如下函数： 12read(file, tmp_buf, len);write(socket, tmp_buf, len); 从用户层面看，虽然只有两个操作步骤：从磁盘读取文件，再将文件写入到socket。但是在操作系统内部经历了一个较为复杂的过程，这个过程如下图所示： 从图中可以看出经历了4次数据拷贝过程： 1）首先，调用read方法，文件从user模式拷贝到了kernel模式，即用户模式—&gt;内核模式的上下文切换，在内部发送sys_read()从文件中读取数据，存储到一个内核地址空间缓存区中。这一步，数据从磁盘复制到内核缓冲区。 2）之后CPU控制将kernel模式数据拷贝到user模式下，即内核模式—&gt;用户模式的上下文切换，read()调用返回，数据被存储到用户地址空间的缓存区中。这一步，数据从内核缓冲区复制到用户空间缓冲区。 3）调用write时候，先将user模式下的内容拷贝到kernel模式下socket的buffer中，即用户模式—&gt;内核模式，数据再次被放置在内核缓存区中，send()套接字调用。这一步，数据从用户缓冲区复制到内核的socket缓冲区。 4）最后将kernel模式下的socket buffer的数据拷贝到网卡设备中，send()套接字调用返回。这一步，数据从socket缓冲区复制到协议引擎（这里是网卡驱动）。 很明显，第2、3次数据拷贝是多余的，白白让数据在用户空间转了一圈，即浪费了时间，又降低了性能。 零拷贝机制零拷贝，即所谓的Zero-copy，是指在操作数据时，不需要将数据从一个内存区域拷贝到另一个内存区域。因为少了一次或多次数据的拷贝，因此程序性能得到提升。如果操作的数据量大，这种性能提升效果是非常明显的。 在操作系统层面上的Zero-copy通常指避免在用户态(User-space)与内核态(Kernel-space)之间来回拷贝数据。例如，Linux提供的mmap系统调用，它可以将一段用户空间内存映射到内核空间，当映射成功后，用户对这段内存区域的修改可以直接映射到内核空间。同样地, 内核空间对这段区域的修改也可以直接映射到用户空间。这样，就不需要在用户态与内核态之间拷贝数据，提高了数据传输的效率。 从上面传统数据拷贝方式看，第2、3次数据拷贝根本就是多余的。应用程序只是起到缓存数据传回到套接字的作用而已，没有其他意义。 应用程序使用zero-copy请求kernel直接把disk的数据传输到socket中，而不需要通过应用程序中转。zero-copy大大提高了应用程序的性能，并且减少了kernel和user模式的上下文切换。 数据可以直接从read buffer读缓存区传输到套接字缓冲区，也就省去了将操作系统的read buffer拷贝到程序的buffer，以及从程序buffer拷贝到socket buffer的步骤，直接将read buffer拷贝到socket buffer。JDK NIO中的transferTo() 方法就能实现这个操作，它依赖于操作系统底层的sendFile()实现。 1public void transferTo(long position, long count, WritableByteChannel target); 而底层是调用的sendFile()方法： 12#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 使用了zero-copy技术后，整个过程如下： 1）transferTo()方法使得文件的内容直接拷贝到了一个read buffer（kernel buffer）中 2）然后数据从kernel buffer拷贝到socket buffer中 3）最后将socket buffer中的数据拷贝到协议引擎（网卡设备）中传输 这里没有了从内核态到用户态的过程，上下文切换从4次减少到2次，同时把数据拷贝的次数从4次降低到3次。 linux 2.1内核开始引入了sendfile函数，用于将文件通过socket传输。 1sendfile(socket, file, len); 该函数通过一次调用完成了文件的传输。该函数通过一次系统调用完成了文件的传输，减少了原来read/write方式的模式切换。此外更是减少了数据的拷贝。 通过sendfile传送文件只需要一次系统调用，当调用sendfile时： 1）首先通过DMA将数据从磁盘读取到kernel buffer中 2）然后将kernel buffer数据拷贝到socket buffer中 3）最后将socket buffer中的数据拷贝到网卡设备中（protocol buffer）发送； sendfile与read/write模式相比，少了一次copy。但是从上述过程中发现从kernel buffer中将数据copy到socket buffer也是没有必要的。 因此，Linux 2.4内核对sendfile做了改进，如图所示： 改进后的处理过程如下： 1）将文件拷贝到kernel buffer中；(DMA引擎将文件内容拷贝到内核缓存区) 2）向socket buffer中追加当前要发生的数据在kernel buffer中的位置和偏移量 3）根据socket buffer中的位置和偏移量直接将kernel buffer的数据拷贝到网卡设备（protocol engine）中 linux 2.1内核中的 “数据被拷贝到socket buffer”的动作，在Linux 2.4内核做了优化，取而代之的是只包含关于数据的位置和长度的信息的描述符被追加到了socket buffer缓冲区中。DMA引擎直接把数据从内核缓冲区传输到网卡设备（protocol engine），从而减少了最后一次拷贝。经过上述过程，数据只经过了2次copy就从磁盘传送出去了。这就是Zero-Copy(这里的零拷贝是针对kernel来讲的，数据在kernel模式下是Zero-Copy)。Java中的TransferTo()方法实现了Zero-Copy。 Zero-Copy技术的使用场景有很多，比如Kafka，Netty等，可以大大提升程序性能。 Netty的零拷贝机制而需要注意的是，Netty中的Zero-copy与上面提到的操作系统层面上的Zero-copy不完全一样，Netty的Zero-coyp应该是多维度的。包含三个层次： 避免从内核空间—&gt;用户空间这个和上述的操作系统系统层面的零拷贝机制一样，Netty在这一层对零拷贝实现就是FileRegion类的transferTo()方法，可以不提供buffer完成整个文件的发送，不再需要开辟buffer在用户-内核空间循环读写。 避免从JVM Heap—&gt;C Heap在JVM层面，每当程序需要执行一个I&#x2F;O操作时，都需要将数据先从JVM管理的堆内存复制到使用C malloc()或类似函数分配的Heap内存中，这样才能够触发系统调用完成操作，这部分内存对于Java应用来说是堆外内存，但是从操作系统来看其实都属于进程的堆区，操作系统并不知道JVM的存在，都是普通的用户程序。这样的话，JVM在I&#x2F;O时永远比使用native语言编写的程序多一次数据复制，这也是所有基于虚拟机的编程语言都无法避免的问题。 而Netty是在适当的位置直接使用堆外内存从而避免了数据从JVM Heap到C Heap的拷贝。 避免在用户空间的多次拷贝在实现应用层数据传输功能时，可能会遇到这样一个场景。假如有一份协议数据, 它由头部和消息体组成, 而头部和消息体是分别存放在两个ByteBuf中，分别是: 12ByteBuf headerByteBuf body 在代码处理时，通常会将header和body合并为一个ByteBuf来操作，这样处理起来更方便。比如： 123ByteBuf allBuf = Unpooled.buffer(header.readableBytes() + body.readableBytes());allBuf.writeBytes(header);allBuf.writeBytes(body); 可以看出，将header和body拷贝到新的allBuf中，这无形中增加了两次额外的数据拷贝操作。 而Netty提供了CompositeByteBuf类，它可以将物理上分散的多个ByteBuf从逻辑上当成一个完整的ByteBuf来操作，这样就免去了重新分配空间再复制数据的开销。Netty的Zero-copy体现在如下几个方面: Netty提供了 CompositeByteBuf 类，可以将多个ByteBuf合并为一个逻辑上的ByteBuf，避免了各个ByteBuf之间的数据拷贝。 通过wrap操作，可以将byte[]数组、ByteBuf、ByteBuffer等包装成一个Netty ByteBuf对象，进而避免了拷贝操作。 ByteBuf支持slice操作，可以将ByteBuf分解为多个共享同一个存储区域的ByteBuf，避免了内存的拷贝。 通过FileRegion包装的FileChannel.tranferTo实现文件传输，可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。","categories":[{"name":"开源组件","slug":"开源组件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://imalan6.github.io/hexo_blog/tags/netty/"}]},{"title":"Netty的高性能NIO模型","slug":"netty/Netty的高性能NIO模型","date":"2020-07-11T07:19:22.000Z","updated":"2024-02-14T11:26:32.743Z","comments":false,"path":"2020/07/11/netty/Netty的高性能NIO模型/","permalink":"https://imalan6.github.io/hexo_blog/2020/07/11/netty/Netty%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BDNIO%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"Netty的高性能NIO模型BIO模型BIO模型BIO，即同步阻塞IO。服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理。我们熟悉的Socket编程就是BIO，每个请求对应一个线程去处理。一个socket对应一个处理线程，这个线程负责这个Socket连接的一系列数据传输操作，如果这个连接不做任何事情必然会造成不必要的线程开销。 由于操作系统允许的线程数量是有限的，多个socket申请与服务端建立连接时，服务端不能提供相应数量的处理线程，没有分配到处理线程的连接就会阻塞等待或被拒绝。如下图是BIO通信模型： 同步阻塞IO的改进模型：采用线程池创建socket线程，但也只是解决了频繁创建线程的问题，无法根本性提升性能。 BIO的问题： 每个请求都需要创建独立的线程，与对应的客户端进行数据Read/Write，业务处理。 当并发量较大时，需要创建足够多的线程处理连接，系统资源消耗很大。 连接建立后，如果当前线程暂时没有数据可读，线程就会阻塞在Read操作上，造成线程资源浪费。 BIO Demo1234567891011121314151617181920212223242526272829303132public class SocketServer &#123; public static void main(String[] args) &#123; try &#123; ServerSocket server = new ServerSocket(8888); System.out.println(&quot;服务器已经启动！&quot;); // 接收客户端发送的信息 Socket socket = server.accept(); InputStream is = socket.getInputStream(); BufferedReader br = new BufferedReader(new InputStreamReader(is)); String info = null; while ((info = br.readLine()) != null) &#123; System.out.println(info); &#125; // 向客户端写入信息 OutputStream os = socket.getOutputStream(); String str = &quot;欢迎登陆到server服务器!&quot;; os.write(str.getBytes()); // 关闭文件流 os.close(); br.close(); is.close(); socket.close(); server.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; NIO模型NIO，即同步非阻塞IO。同步是指线程不断轮询IO事件是否就绪，非阻塞是指线程在等待IO时，可以同时做其他任务。 NIO 有三大核心部分：Channel(通道)，Buffer(缓冲区)，Selector(选择器)，Selector代替了线程本身轮询IO事件，避免了线程阻塞，同时减少了不必要的线程开销。当IO事件就绪时，可以把数据写到Buffer，保证IO成功，而无需线程阻塞式地等待。 通俗理解：NIO可以做到用一个线程来处理多个操作。假设有10000个请求过来，根据实际情况，可以分配50或者100个线程来处理。不像BIO，必须分配10000个线程处理。 Java NIO全称java non-blocking IO，从JDK1.4开始，Java提供了一系列改进的输入&#x2F;输出的新特性。NIO相关类都放在java.nio包及子包下，并且对原http://java.io包中的很多类进行改写。Java NIO的非阻塞模式，当一个线程从channel获取数据时，它仅能得到目前可用的数据，如果目前没有数据可读时，就什么也不操作，直到数据可以读取之前，该线程可以继续做其他事情，而不会保持线程阻塞。非阻塞写也是一样，一个线程请求写入一些数据到channel，不需要等它完全写入，这个线程同时可以去做别的事情。 NIO和BIO的区别 BIO以流的方式处理数据,而NIO以块的方式处理数据,块I&#x2F;O的效率比流I&#x2F;O高很多 BIO是阻塞的，NIO则是非阻塞的 BIO基于字节流和字符流进行操作，而NIO基于Channel(通道)和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector(选择器)用于监听多个通道的事件（比如：连接请求，数据到达等），因此使用单个线程就可以监听多个客户端通道 Reactor模型NIO基于Reactor，是典型的Reactor模型结构。Reactor模式是一种事件处理的模式，将多个输入同时交付给服务处理程序，然后对请求进行多路分解，并同步地分发到到对应的处理器中。 Reactor设计模式是event-driven architecture的一种实现方式，处理多个客户端并发的向服务端请求服务的场景。每种服务在服务端可能由多个方法组成。Reactor会解耦并发请求的服务并分发给对应的事件处理器来处理。 Reactor单线程模型每个客户端发起连接请求都会交给acceptor，acceptor根据事件类型交给线程handler处理，但是由于在同一线程中，容易产生一个handler阻塞影响其他的情况。 对于一些并发量较小的应用场景，可以使用Reactor单线程模型。但对于高负载、高并发的应用场景却不合适，主要原因如下： 一个NIO线程同时处理大量连接，性能上无法支撑，即便NIO线程的CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送； 当NIO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了NIO线程的负载，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈； 一旦NIO线程出问题，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。 Reactor多线程模型在经典的Reactor单线程模式中，尽管一个线程可同时监控多个请求，但是所有读&#x2F;写请求以及对新连接请求的处理都在同一个线程中处理，无法充分利用多CPU的优势，同时读&#x2F;写操作也会阻塞对新连接请求的处理。因此可以引入多线程，并行处理多个读&#x2F;写操作。 这里使用了单线程进行接收客户端的连接，采用了NIO的线程池用来处理客户端对应的IO操作，由于客户端连接较多，采用一个线程处理多个连接，如下图所示： Reactor多线程模型的特点： 有专门一个NIO线程—Acceptor线程用于监听服务端，接收客户端的TCP连接请求； 网络IO操作-读、写等由一个NIO线程池负责，它包含一个任务队列和多个可用的线程，这些NIO线程负责消息的读取、解码、编码和发送； 1个NIO线程可以同时处理多个连接，但是1个连接只对应1个NIO线程，防止发生并发操作问题。 在绝大多数场景下，Reactor多线程模型都可以满足性能需求；但是，在极个别特殊场景中，一个NIO线程负责监听和处理所有的客户端连接可能会存在性能问题。例如并发百万客户端连接，或者服务端需要对客户端握手进行安全认证，但是认证本身非常损耗性能。在这类场景下，单独一个Acceptor线程可能会存在性能不足问题，为了解决性能问题，产生了第三种Reactor线程模型—Reactor主从多线程模型。 Reactor主从多线程模型比起第二种多线程模型，它将Reactor分成两部分，mainReactor负责监听并accept新连接，然后将建立的socket通过多路复用器（Acceptor）分派给subReactor。subReactor负责多路分离已连接的socket，读写网络数据，业务处理功能，交给worker线程池完成。通常，subReactor个数上可与CPU个数等同。 Reactor主从多线程模型流程如下： 从主线程池中随机选择一个Reactor线程作为Acceptor线程，用于绑定监听端口，接收客户端连接； Acceptor线程接收客户端连接请求之后创建新的SocketChannel，将其注册到主线程池的其它Reactor线程上，由其负责接入认证、IP黑白名单过滤、握手等操作； 第2步完成之后，业务层的链路正式建立，将SocketChannel从主线程池的Reactor线程的多路复用器上摘除，重新注册到Sub线程池的线程上，用于处理I&#x2F;O的读写操作。 AIO模型NIO是同步IO，程序需要IO操作时，必须进行IO操作后才能进行下一步操作。AIO是对NIO的改进，它基于Proactor模型。每个socket连接在事件分离器注册 IO完成事件和IO完成事件处理器。程序需要进行IO时，向分离器发出IO请求并把所用的Buffer区域告知分离器，分离器通知操作系统进行IO操作，操作系统自己不断尝试获取IO权限并进行IO操作（数据保存在Buffer区），操作完成后通知分离器。 AIO是发出IO请求后，由操作系统自己去获取IO权限并进行IO操作；NIO则是发出IO请求后，由线程不断尝试获取IO权限，获取到后通知应用程序自己进行IO操作。 同步&#x2F;异步：数据如果尚未就绪，是否需要等待数据结果。 阻塞&#x2F;非阻塞：进程&#x2F;线程需要操作的数据如果尚未就绪，是否妨碍了当前进程&#x2F;线程的后续操作。应用程序的调用是否立即返回。","categories":[{"name":"开源组件","slug":"开源组件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://imalan6.github.io/hexo_blog/tags/netty/"}]},{"title":"Netty检查连接断开的几种方法","slug":"netty/Netty检查连接断开的几种方法","date":"2020-07-09T04:55:22.000Z","updated":"2024-02-14T11:26:32.763Z","comments":false,"path":"2020/07/09/netty/Netty检查连接断开的几种方法/","permalink":"https://imalan6.github.io/hexo_blog/2020/07/09/netty/Netty%E6%A3%80%E6%9F%A5%E8%BF%9E%E6%8E%A5%E6%96%AD%E5%BC%80%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/","excerpt":"","text":"Netty检查连接断开的几种方法最近项目中需要判定客户端是否还在线，需要用到心跳检测机制。这里总结一下。 心跳检测机制网络中接收和发送数据都是通过操作系统的socket实现的。但是如果套接字已经断开，那发送和接收数据就会出问题。 但如何判断套接字是否断开了呢？这就需要建立一种机制，能够检测通信对方是否还存活。如果已经断开，就要释放资源。这种机制通常采用心跳检测实现。 所谓的“心跳”就是定时发送一个自定义的结构体（心跳包或心跳帧），让对方知道自己“在线”，以确保链接的有效性。心跳检测规定定时发送心跳检测数据包，接收方接心跳包后回复，否则认为连接断开。 Netty心跳检测方式pipeline加入IdleStateHandlerNetty提供了心跳检测类IdleStateHandler，它有三个参数，分别是读超时时间、写超时时间、读写超时时间。 readerIdleTime：读超时时间 writerIdleTime：写超时时间 allIdleTime：所有类型超时时间 这里最重要是的readerIdleTime，当设置了readerIdleTime以后，服务端server会每隔readerIdleTime时间去检查一次channelRead方法被调用的情况，如果在readerIdleTime时间内该channel上的channelRead()方法没有被触发，就会调用userEventTriggered方法。 12345//读超时时间设置为10s，0表示不监控ch.pipeline().addLast(new IdleStateHandler(10, 0, 0, TimeUnit.SECONDS));//加入处理事件ch.pipeline().addLast(new ServerHeartBeat()); 重写userEventTriggered方法重写ChannelInboundHandlerAdapter处理类的userEventTriggered方法，在方法中处理idleEvent.state() == IdleState.READER_IDLE情况。 1234567891011121314151617public class ServerHeartBeat extends ChannelInboundHandlerAdapter &#123; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent) &#123; //超时事件 IdleStateEvent idleEvent = (IdleStateEvent) evt; if (idleEvent.state() == IdleState.READER_IDLE) &#123; //读 ctx.channel().close(); &#125; else if (idleEvent.state() == IdleState.WRITER_IDLE) &#123; //写 &#125; else if (idleEvent.state() == IdleState.ALL_IDLE) &#123; //全部 &#125; &#125; super.userEventTriggered(ctx, evt); &#125;&#125; TCP连接心跳检测方式TCP心跳机制上面采用的是Netty的心跳检测机制，属于应用层自定义的心跳检测方式。 应用层实现心跳机制好处： 灵活，应用层心跳可以自由定义，可实现各时间间隔（秒级、毫秒级）的检测，包里还可以携带额外的信息。 通用，应用层的心跳不依赖于底层协议。如果后期想把TCP改为UDP，协议层不提供心跳机制了，但应用层的心跳依旧是通用的。 应用层实现心跳机制坏处： 增加开发量，由于使用特定的网络框架，还可能很增加代码结构的复杂度。 额外增加了网络通信数据包，流量消耗更大。 TCP协议本身也实现了心跳检测机制。所以，也可以使用TCP的心跳机制检测连接是否断开。 如果设置了心跳，TCP会在一定时间（比如设置的是3秒钟）内发送设置的次数的心跳（比如2次），并且该心跳信息不会影响自己定义的协议。 TCP心跳设置TCP协议自带的保活功能，使用起来很简单。Linux环境下，修改/etc/sysctl.conf文件，添加以下内容： 12345678#表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是7200秒（2小时），改为5秒钟。net.ipv4.tcp_keepalive_time = 5#如果对方不予应答，探测包的发送次数net.ipv4.tcp_keepalive_probes = 5#探测消息发送的频率net.ipv4.tcp_keepalive_intvl = 1 这个是修改的Linux TCP发送探测包配置的。修改完成后输入以下命令生效 12/sbin/sysctl -p/sbin/sysctl -w net.ipv4.route.flush=1 还可以使用echo的方式修改，命令如下： 123#echo 5 &gt; /proc/sys/net/ipv4/tcp_keepalive_time#echo 5 &gt; /proc/sys/net/ipv4/tcp_keepalive_probes#echo 1 &gt; /proc/sys/net/ipv4/tcp_keepalive_intvl 修改后查看下参数，验证设置是否已经生效。 123#cat /proc/sys/net/ipv4/tcp_keepalive_time #cat /proc/sys/net/ipv4/tcp_keepalive_probes #cat /proc/sys/net/ipv4/tcp_keepalive_intvl 这样设置完成以后，每次客户端断开连接后5秒后会执行以下方法。 使用Netty，重写handlerRemoved方法12345678public class TcpServerHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt;&#123; @Override public void handlerRemoved(ChannelHandlerContext ctx) throw Exception&#123; //执行客户端断开连接后的业务操作 &#125;&#125; 这里的时间设置不一定适合各业务场景，需要根据具体的业务设置合适的时间间隔。有时候网络不稳定，一个探测包没有探测到，系统就自动断开连接了。 使用redis保存连接服务端收到客户端发送的心跳数据包后，使用redis保存，同时设置超时时间，一旦超时，触发超时事件，表示客户端连接出问题了。 比如：心跳时间为60s，那么服务器端收到客户端心跳数据包后，保存到redis，并设置超时事件为70s（根据实际情况，需要大于心跳时间），一旦超时触发超时事件，进行连接断开逻辑处理。","categories":[{"name":"开源组件","slug":"开源组件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://imalan6.github.io/hexo_blog/tags/netty/"}]},{"title":"RabbitMQ消息确认机制","slug":"rabbitmq/RabbitMQ消息确认机制","date":"2020-06-23T15:22:12.000Z","updated":"2024-02-14T11:22:12.432Z","comments":false,"path":"2020/06/23/rabbitmq/RabbitMQ消息确认机制/","permalink":"https://imalan6.github.io/hexo_blog/2020/06/23/rabbitmq/RabbitMQ%E6%B6%88%E6%81%AF%E7%A1%AE%E8%AE%A4%E6%9C%BA%E5%88%B6/","excerpt":"","text":"RabbitMQ消息确认机制两种确认机制RabbitMQ的消息确认有两种： 对生产端发送消息的确认。这种是用来确认生产者将消息发送给交换器，交换器传递给队列的过程中，消息是否成功投递。发送确认分为两步，一是确认是否到达交换器，二是确认是否到达队列。 对消费端消费消息的确认。这种是确认消费者是否成功消费了队列中的消息。 对生产端发送消息的确认rabbitmq对生产端发送消息的确认分为事务和实现confirm机制。不过一般不使用事务，性能消耗太大。 对生产端的confirm机制详见：RabbitMQ可靠消息投递 消费端消费消息后的确认为了保证消息能可靠到达消费端，RabbitMQ也提供了消费端的消息确认机制。消费者在声明队列时，可以指定noAck参数，当noAck=false时，RabbitMQ会等待消费者显式发回ack后才从内存(和磁盘，如果是持久化消息的话)中移去消息。否则，RabbitMQ会在队列中消息被消费后立即删除它。 采用消息确认机制后，只要令noAck=false，消费者就有足够的时间处理消息，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。 消费者消息的确认分为： AcknowledgeMode.AUTO：自动确认（默认） AcknowledgeMode.MANUAL：手动确认 AcknowledgeMode.NONE：不确认 在spring-boot中，消费者手动确认配置方法： 1spring.rabbitmq.listener.simple.acknowledge-mode = manual 消费者手动确认消费成功手动确认方法void basicAck(long deliveryTag, boolean multiple) throws IOException； deliveryTag：该消息的index multiple：是否批量确认。true：将一次性ack所有小于deliveryTag的消息。 消费者成功处理消息后，手动调用channel.basicAck(message.getMessageProperties().getDeliveryTag(), false)方法对消息进行消费确认。 123456try &#123; channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); // 手动确认消息 System.out.println(&quot;投递消息确认成功，tag：&quot;+message.getMessageProperties().getDeliveryTag());&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 消费失败手动确认方法void basicNack(long deliveryTag, boolean multiple, boolean requeue) throws IOException; deliveryTag:该消息的index。 multiple：是否批量. true：将一次性拒绝所有小于deliveryTag的消息。 requeue：被拒绝的是否重新入队列。 void basicReject(long deliveryTag, boolean requeue) throws IOException; deliveryTag:该消息的index。 requeue：被拒绝的是否重新入队列。 channel.basicNack方法与channel.basicReject方法区别在于basicNack可以批量拒绝多条消息，而basicReject一次只能拒绝一条消息。 消费者手动确认可能的问题消息无法ack消费端在消费消息过程中出现异常，不能回复ack应答，消息将变成unacked状态，且一直处于队列中。如果积压的消息过多将会导致程序无法继续消费数据。 消费端服务重启，断开rabbitmq的连接后，unacked的消息状态会重新变为ready等待消费。但是如果不重启消费端服务，消息将一直驻留在RabbitMQ中。 所以，如果想不重启消费端的话，可以捕获异常，然后调用basicNack，让消息重新进入队列再次消费。 无效消息循环重入队列在上一个问题中，如果消费端捕获异常，并执行basicNack应答，将消息重新放入队列中，可能会出现另一个问题： 如果消息或者代码本身有bug，每次处理这个消息都会报异常，那消息将一直处于消费——&gt;报异常——&gt;重入队列——&gt;继续消费——&gt;报异常。。。的死循环过程。 以上两个问题其实属于同一类问题，都需要我们确保代码在消费消息后，一定要通知RabbitMQ，不然消息将一直驻留在RabbitMQ中。如果消息成功消费，则调用channel.basicAck正常通知RabbitMQ；如果消费失败，则调用channel.basicNack或者channel.basicReject确认消费失败。 但防止死循环有两种处理办法： 1）根据处理过程中报的不同异常类型，选择消息要不要重入队列。 1234567891011121314151617181920212223enum Action &#123; ACCEPT, // 处理成功 RETRY, // 可以重试的错误 REJECT, // 无需重试的错误&#125;Action action = Action.RETRY; try &#123; // 如果成功完成则action=Action.ACCEPT&#125;catch (Exception e) &#123; // 根据异常种类决定是ACCEPT、RETRY还是 REJECT&#125;finally &#123; // 通过finally块来保证Ack/Nack会且只会执行一次 if (action == Action.ACCEPT) &#123; channel.basicAck(tag); &#125; else if (action == Action.RETRY) &#123; channel.basicNack(tag, false, true); &#125; else &#123; channel.basicNack(tag, false, false); &#125; &#125; 2）将处理失败的消息放入另一个队列中，手动取出处理。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://imalan6.github.io/hexo_blog/tags/rabbitmq/"}]},{"title":"RabbitMQ原理和使用方法总结","slug":"rabbitmq/RabbitMQ原理和使用方法总结","date":"2020-06-22T05:49:03.000Z","updated":"2024-02-14T11:22:12.454Z","comments":false,"path":"2020/06/22/rabbitmq/RabbitMQ原理和使用方法总结/","permalink":"https://imalan6.github.io/hexo_blog/2020/06/22/rabbitmq/RabbitMQ%E5%8E%9F%E7%90%86%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/","excerpt":"","text":"RabbitMQ原理和使用方法总结简介消息队列消息队列，即MQ(全称Message Queue)。消息队列是在消息的传输过程中保存消息的容器。它是典型的生产者—消费者模型。生产者不断向消息队列中生产消息，消费者不断的从队列中获取消息。消息队列提供一个异步通信机制，消息的发送者不必一直等到消息被成功处理才返回，而是可以立即返回。 消息中间件负责处理网络通信，如果网络连接不可用，消息被暂存于队列当中，当网络畅通的时候在将消息转发给订阅了队列的应用程序或服务处理。 消息的生产和消费都是异步的，消息队列只关心消息的发送和接收，没有业务逻辑的侵入，实现了生产者和消费者的解耦。 以电商系统为例，比如在用户下单时，订单服务需要调用库存服务进行商品扣库存操作。按照传统方式，下单要等到库存服务成功返回之后才能显示下单成功，如果这时网络出现故障导致库存服务一直没有返回，那用户将一直处于等待中，使得用户体验变得很差。在这种情况下，就可以在订单服务和库存服务之间使用消息队列进行解耦。订单服务将扣库存消息发送到消息队列中后直接返回，库存服务会自动去消息队列中获取消息处理，用户无需等待。这样既提高了并发量，又降低了服务之间的耦合度。 JMS和AMQPJMS（Java MessageService）是指JMS API。JMS是由Sun公司早期提出的消息标准，旨在为Java应用提供统一的消息操作，包括create、send、receive等。JMS已经成为Java Enterprise Edition的一部分。用户可以根据相应的接口实现JMS服务进行通信和相关操作。 AMQP（Advanced Message Queue Protocol）是一种协议，最早用于解决金融领域不同平台之间的消息传递交互问题。AMQP和JMS有本质的差别，AMQP不从API层进行限定，而是直接定义网络交换的数据格式。这使得实现了AMQP的消息发送者和消费者可以使用不同语言实现，只要采用相应的数据格式即可。 两者的区别如下： JMS定义了统一的接口，统一对消息的处理，而AMQP是通过规定协议来统一数据交互格式； JMS限定了必须使用Java语言；而AMQP只是协议，不规定实现方式，因此是跨语言的； JMS规定了两种消息模型，而AMQP的消息模型更加丰富。 常见的MQ产品如下： ActiveMQ：基于JMS规范实现，采用Java语言开发，是Apache下面的项目； RabbitMQ：基于AMQP协议实现，采用Erlang语言开发，稳定性好； RocketMQ：基于JMS规范实现，采用Java语言开发，阿里产品，目前交由Apache基金会； Kafka：由Apache软件基金会开发的开源流处理平台，采用Scala和Java开发，主要用于处理日志； RabbitMQRabbitMQ是一个开源的消息队列服务器。RabbitMQ基于AMQP协议实现，采用Erlang语言开发。Erlang语言在数据交互方面性能非常优秀，RabbitMQ具有很高的性能。RabbitMQ官方地址：http://www.rabbitmq.com 应用场景 异步处理，发送者把消息放入消息队列中可以直接返回，无需等到处理完成才返回。 应用解耦，消息发送者和消费者之间不必受对方的影响，只通过一个简单的容器来联系，可以更独立自主。 流量削峰，当请求量剧增时，发送者可以发请求发送到消息队列，当消息队列满了就拒绝响应，跳转到错误页面，这样就可以避免系统崩溃。 日志处理，将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。 工作原理基本结构RabbitMQ的基本结构如下图： Broker：消息队列服务进程，包括两个部分：Exchange和Queue。 Exchange：消息队列交换机，按一定的规则将消息路由转发到队列中，对消息进行过滤。 Queue：消息队列，存储消息的队列，消息到达队列并转发给指定的消费者。多个消费者可以订阅同一个Queue，Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。 Virtual Host：虚拟主机，用于逻辑隔离。一个虚拟主机里面可以有若干个Exchange和Queue，同一个虚拟主机里面不能有相同名称的Exchange或Queue。 Connection：连接，应用程序与Broker的网络连接，TCP连接。 Channel：信道，消息读写等操作在信道中进行。客户端可以建立多个信道，每个信道代表一个会话任务。 Message：消息，应用程序和服务器之间传送的数据，消息可以非常简单，也可以很复杂。 Binding：绑定，交换器和消息队列之间的虚拟连接，绑定中可以包含一个或者多个RoutingKey。 RoutingKey：路由键，生产者将消息发送给交换器的时候，会发送一个RoutingKey，用来指定路由规则，这样交换器就知道把消息发送到哪个队列。路由键通常为一个“.”分割的字符串，例如“com.rabbitmq”。 Producer：消息生产者，即生产方客户端，生产方客户端将消息发送。 Consumer：消息消费者，即消费方客户端，接收MQ转发的消息。 工作流程生产者发送消息流程： 1）生产者和Broker建立TCP连接 2）生产者和Broker建立通道 3）生产者通过通道消息发送给Broker，由Exchange将消息进行转发 4）Exchange将消息转发到指定的Queue 消费者接收消息流程： 1）消费者和Broker建立TCP连接 2）消费者和Broker建立通道 3）消费者监听指定的Queue 4）当有消息到达Queue时Broker默认将消息推送给消费者 5）消费者接收到消息 6）ack回复 PrefetchCount当有多个消费者订阅同一个Queue时，Queue中的消息会被平摊给多个消费者处理。这时如果每个消费者处理消息的时间不同，就有可能导致某些消费者一直在处理，而另一些消费者很快就处理完手头工作并一直空闲的情况。遇到这种情况，可以通过设置prefetchCount来限制Queue每次发送给每个消费者的消息数，比如设置prefetchCount=1，则Queue每次给每个消费者发送一条消息，等消费者处理完这条消息后，Queue会再给该消费者发送一条消息。这样，处理速度快的消费者接受消息的频率就会快些，而处理速度慢的消费者接受消息的频率就会慢些，很好地均衡了多个消费者的工作量。 Exchange类型RabbitMQ常用的Exchange Type有：direct、topic、fanout、headers四种（AMQP规范里还提到两种Exchange Type，分别为system与自定义），下面分别进行介绍。 DirectDirect类型的Exchange路由规则很简单，它会把消息路由到Routing Key指定的队列中，也就是说Routing Key与Binding Key完全匹配的Queue中。 如上图所示，如果用routingKey=”orange”发送消息到Exchange，则消息会路由到Queue1（amqp.gen-S9b…，这是由RabbitMQ自动生成的Queue名称），如果用routingKey=”black”或routingKey=”green”来发送消息，则消息会路由到Queue2。如果我们以其他routingKey发送消息，则消息不会路由到这两个Queue中。 TopicDirect类型的Exchange路由规则是完全匹配binding key与routing key，这种严格的匹配方式在很多情况下不能满足实际业务需求。topic类型的Exchange在匹配规则上进行了扩展，它与direct类型的Exchange相似，也是将消息路由到binding key与routing key相匹配的Queue中，但这里的匹配规则有些不同，它约定： routing key为一个句点号“. ”分隔的字符串（将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“com.rabbitmq”、“orange.abc”、“123.xyz.abc” binding key与routing key一样也是句点号“. ”分隔的字符串 binding key中可以存在两种特殊字符“*”与“#”，用于做模糊匹配，其中“*”用于匹配一个单词，“#”用于匹配多个单词（可以是零个） 如上图所示： routingKey&#x3D;”abc.orange.rabbit”的消息会同时路由到Q1与Q2 routingKey&#x3D;”lazy.orange.abc”的消息也会同时路由到Q1和Q2 routingKey&#x3D;”lazy.xyz.abc”的消息只会路由到Q2 routingKey&#x3D;”lazy.xyz.rabbit”的消息只会路由到Q2，但注意只会投递给Q2一次，虽然这个routingKey与Q2的两个bindingKey都匹配。 routingKey&#x3D;”quick.xyz.abc”、routingKey&#x3D;”orange”、routingKey&#x3D;”abc.orange.xyz.rabbit”的消息将会被丢弃，因为它们没有匹配任何bindingKey FanoutFanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。 如上图所示，生产者（P）发送到Exchange（X）的所有消息都会路由到图中的两个Queue，并最终被C1与C2消费。 Headersheaders类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。 该类型的Exchange在实际中很少使用，不做过多介绍。 部署使用部署略，详见devops—docker部分 Springboot集成RabbitMQ添加配置： 123456789spring: application: name: land-service-producer #配置rabbitMq服务器 rabbitmq: host: 127.0.0.1 port: 5672 username: admin password: admin 添加一个配置类，创建一个exchange和两个queue，并且让exchange和两个queue分别绑定起来，代码如下： 123456789101112131415161718192021222324252627282930313233343536@Configurationpublic class RabbitMqConfig &#123; public final static String QUEUE_NAME_1 = &quot;land_queue1&quot;; public final static String QUEUE_NAME_2 = &quot;land_queue2&quot;; public final static String EXCHANGE_NAME = &quot;land_exchange&quot;; @Bean public Queue queue1() &#123; // 创建一个queue 1 return new Queue(RabbitMqConfig.QUEUE_NAME_1); &#125; @Bean public Queue queue2() &#123; // 创建一个queue 2 return new Queue(RabbitMqConfig.QUEUE_NAME_2); &#125; @Bean TopicExchange exchange() &#123; // 创建一个topic exchange return new TopicExchange(EXCHANGE_NAME); &#125; @Bean Binding bindingExchangeMessage() &#123; // exchange和queue1绑定，并指定binding key return BindingBuilder.bind(queue1()).to(exchange()).with(&quot;topic.com.alan6.#&quot;); &#125; @Bean Binding bindingExchangeMessages() &#123; // exchange和queue2绑定，并指定binding key return BindingBuilder.bind(queue2()).to(exchange()).with(&quot;topic.message.*&quot;); &#125;&#125; 发送者代码： 1234567891011121314151617@RunWith(SpringRunner.class)@SpringBootTest(classes = ProducerApplication.class)public class RabbitMQTest &#123; @Autowired private AmqpTemplate rabbitTemplate; @Test public void sendMessageTest() &#123; // 测试消息 String msg = &quot;this is a test&quot;; // 路由key String routingKey = &quot;topic.com.alan6.www&quot;; // 发送消息 this.rabbitTemplate.convertAndSend(RabbitMqConfig.EXCHANGE_NAME, routingKey, msg); &#125;&#125; 消费者代码： 123456789@Component@RabbitListener(queues = &quot;land_queue1&quot;) //注解，消费land_queue1的消息public class Consume &#123; @RabbitHandler // 消费处理注解 public void consumer(String msg)&#123; // 参数为需要处理的消息 System.out.println(&quot;consume msg：&quot; + msg); &#125;&#125; 测试运行rabbitmq，启动producer测试代码，向rabbitmq发送消息： 可以看见，rabbitmq已经接收到1个消息，正在等待消费，然后启动消费者应用： rabbitmq中的消息已经被取走消费。 Tracing记录消息RabbitMQ的Tracing能跟踪RabbitMQ中消息的流入流出情况。rabbitmq_tracing插件会对流入流出的消息做封装，然后将封装后的消息存入相应的trace文件之中。 使用rabbitmq-plugins enable rabbitmq_tracing命令来启动rabbitmq_tracing插件。如果是使用docker部署的，先进入docker环境，再开启。 在rabbitmq的GUI管理界面 “Admin” 选项右侧原本只有 ”Users”、”Virtual Hosts”和 ”Policies“ 三项，在添加rabbitmq_tracing插件之后，会多出”Tracing”选项。 Name：自定义日志名称，建议标准点容易区分。 Format：表示输出的消息日志格式，有Text和JSON两种，Text格式的日志方便人类阅读，JSON的方便程序解析。Text相比JSON格式占用空间稍大点。 JSON格式的payload（消息体）默认会采用Base64进行编码。 Max payload bytes：表示每条消息的最大限制，单位为B。比如设置了了此值为10，那么当有超过10B的消息经过RabbitMQ时会被截断。如消息“trace test payload.”会被截断成“trace test”。 Pattern：用来设置匹配模式，如“#” 匹配所有消息流入流出的情况，即当有客户端生产消息或消费消息的时候，都会把相应的消息日志记录下来。“publish.#” 匹配所有消息流入的情况；“deliver.#” 匹配所有消息流出的情况；“publish.exchange.b2b.gms.ass”只匹配发送者(Exchanges)为exchange.b2b.gms.ass的所有消息流入的情况。 持久化RabbitMQ默认是不持久Exchange、Queue、Binding以及队列中消息的，这意味着一旦RabbitMQ重启，所有已声明的队列，Exchange，Binding以及队列中的消息都会丢失。为了防止丢失，需要实现持久化。但持久化会对RabbitMQ的性能造成很大的影响，可能会下降10倍不止。所以，为了提高rabbitmq的性能，没有必要持久化的可以不用设置为持久化。 Exchange 和 Queue 持久化把Exchange和Queue的durable属性置为true，可以实现Queue和Exchange的持久化。但这里需要注意的是，只有Exchange和Queues的durable都为true时才能绑定，否则在绑定时，RabbitMQ会报错的。 Message 持久化消息的持久化需要在消息投递的时候设置delivery mode值为2。消息持久化必须同时要求exchange和queue也是持久化的。持久化的代价就是性能损失,磁盘IO远远慢于RAM(使用SSD会显著提高消息持久化的性能) , 持久化会大大降低RabbitMQ每秒可处理的消息。两者的性能差距可能在10倍以上。 exchange持久化，在声明时指定durable &#x3D;&gt; 1 queue持久化，在声明时指定durable &#x3D;&gt; 1 消息持久化，在投递时指定delivery_mode &#x3D;&gt; 2（1是非持久化）","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://imalan6.github.io/hexo_blog/tags/rabbitmq/"}]},{"title":"RabbitMQ可靠消息投递","slug":"rabbitmq/RabbitMQ可靠消息投递","date":"2020-06-21T13:19:29.000Z","updated":"2024-02-14T11:22:12.407Z","comments":false,"path":"2020/06/21/rabbitmq/RabbitMQ可靠消息投递/","permalink":"https://imalan6.github.io/hexo_blog/2020/06/21/rabbitmq/RabbitMQ%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E6%8A%95%E9%80%92/","excerpt":"","text":"RabbitMQ可靠消息投递生产端向rabbitmq发送消息时，由于网络等原因可能导致消息发送失败。所以，rabbitmq必须有机制确保消息能准确到达rabbitmq。如果不能到达，必须反馈给生产端进行重发。 RabbitMQ消息的可靠性投递主要两种实现： 通过实现消费的重试机制，通过@Retryable来实现重试，可以设置重试次数和重试频率 生产端实现消息可靠性投递 两种方法消费端都可能收到重复消息，要求消费端必须实现幂等性消费。 消息投递到Exchange的确认模式rabbitmq的消息投递的过程为： producer ——&gt; rabbitmq broker cluster ——&gt; exchange ——&gt; queue ——&gt; consumer 生产端发送消息到rabbitmq broker后，异步接受从rabbitmq返回的ack确认信息。 生产端收到返回的ack确认消息后，根据ack是true还是false，调用confirmCallback接口进行处理。 在application.yml中开启生产端confirm模式 123spring: rabbitmq: publisher-confirms: true 实现ConfirmCallback接口中的confirm方法，ack为true表示消息发送成功，ack为false表示消息发送失败 1234567891011121314151617181920@Component@Slf4jpublic class RabbitTemplateConfig implements ConfirmCallback&#123; @Autowired private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; rabbitTemplate.setConfirmCallback(this); // 指定 ConfirmCallback &#125; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if (!ack) &#123; //try to resend msg &#125; else &#123; //delete msg in db &#125; &#125;&#125; 注意：在confirmCallback回调接口中是没有消息数据的，所以即使消息发送失败，生产端也无法在这个回调接口中直接重发，confirmCallback只能起到一个通知的作用。 消息投递失败的重发机制如果rabbitmq返回ack失败，生产端也无法确认消息是否真的发送成功，也会造成数据丢失。最好的办法是使用rabbitmq的事务机制，但是rabbitmq的事务机制效率极低，每秒钟处理的消息仅几百条，不适合并发量大的场景。 另外一种实现思路： 1）生产端保存每次发送的消息，如果发送成功就删除消息； 2）如果发送失败就取出消息重新发送； 3）如果超时还没有收到mq返回的ack，同样取出消息重新发送。 这样就可以避免消息丢失的风险。以使用redis保存消息msg为例，具体实现方案为： 1）生产端在发送消息之前，生成ack唯一确认的id； 2）以ackId为键，消息为value，保存进redis缓存，设置超时时间； 3）redis实现超时触发接口，当key过期时，重发消息并再次执行第2步； 4）生产端实现ConfirmCallback接口； 5）ConfirmCallback接口触发时，若ack为true，则直接删除此次ackId对应的msg；若ack为false，则将该ackId对应的msg取出重发； 网上另外的实现方案： 不通过设置redis超时时间触发超时事件进行重发，而是取出消息放入一个ackFailList中，然后开启定时任务，扫描ackFailList，重发失败的msg。 网上的这套方案思路上和上一个方案差不多，是采用的额外的List来保存发送失败的消息，由于List保存在内存中，不具备持久化的功能，如果生产端程序异常退出将导致消息丢失，所以并不安全。可以考虑保存到数据库中。 消息未投递到queue的退回模式生产端通过实现ReturnCallback接口，启动消息失败返回，消息路由不到队列时会触发该回调接口。 在application.yml中开启return模式 123spring: rabbitmq: publisher-returns: true 实现ReturnCallback接口，可以获取消息主体内容，实现消息重发 12345678910111213141516171819202122@Component@Slf4jpublic class RabbitTemplateConfig implements ReturnCallback &#123; @Autowired private RabbitTemplate rabbitTemplate; @PostConstruct public void init() &#123; //指定 ReturnCallback rabbitTemplate.setReturnCallback(this); &#125; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; log.info(&quot;消息主体 message : &#123;&#125;&quot;, message); log.info(&quot;消息主体 message : &#123;&#125;&quot;, replyCode); log.info(&quot;描述：&#123;&#125;&quot;, replyText); log.info(&quot;消息使用的交换器 exchange : &#123;&#125;&quot;, exchange); log.info(&quot;消息使用的路由键 routing : &#123;&#125;&quot;, routingKey); &#125;&#125;","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://imalan6.github.io/hexo_blog/tags/rabbitmq/"}]},{"title":"Netty线程模型","slug":"netty/Netty(2)Thread-model","date":"2020-06-14T14:19:14.000Z","updated":"2024-02-14T11:55:20.456Z","comments":false,"path":"2020/06/14/netty/Netty(2)Thread-model/","permalink":"https://imalan6.github.io/hexo_blog/2020/06/14/netty/Netty(2)Thread-model/","excerpt":"前言在之前的 Netty心跳机制 一文中认识了 Netty。 但其实只是能用，为什么要用 Netty？它有哪些优势？这些其实都不清楚。 本文就来从历史源头说道说道。 传统 IO在 Netty 以及 NIO 出现之前，我们写 IO 应用其实用的都是用 java.io.* 下所提供的包。 比如下面的伪代码： 123456789ServeSocket serverSocket = new ServeSocket(8080);Socket socket = serverSocket.accept() ;BufferReader in = .... ;String request ; while((request = in.readLine()) != null)&#123; new Thread(new Task()).start()&#125;","text":"前言在之前的 Netty心跳机制 一文中认识了 Netty。 但其实只是能用，为什么要用 Netty？它有哪些优势？这些其实都不清楚。 本文就来从历史源头说道说道。 传统 IO在 Netty 以及 NIO 出现之前，我们写 IO 应用其实用的都是用 java.io.* 下所提供的包。 比如下面的伪代码： 123456789ServeSocket serverSocket = new ServeSocket(8080);Socket socket = serverSocket.accept() ;BufferReader in = .... ;String request ; while((request = in.readLine()) != null)&#123; new Thread(new Task()).start()&#125; 大概是这样，其实主要想表达的是：这样一个线程只能处理一个连接。 如果是 100 个客户端连接那就得开 100 个线程，1000 那就得 1000 个线程。 要知道线程资源非常宝贵，每次的创建都会带来消耗，而且每个线程还得为它分配对应的栈内存。 即便是我们给 JVM 足够的内存，大量线程所带来的上下文切换也是受不了的。 并且传统 IO 是阻塞模式，每一次的响应必须的是发起 IO 请求，处理请求完成再同时返回，直接的结果就是性能差，吞吐量低。 Reactor 模型因此业界常用的高性能 IO 模型是 Reactor。 它是一种异步、非阻塞的事件驱动模型。 通常也表现为以下三种方式： 单线程 从图中可以看出： 它是由一个线程来接收客户端的连接，并将该请求分发到对应的事件处理 handler 中，整个过程完全是异步非阻塞的；并且完全不存在共享资源的问题。所以理论上来说吞吐量也还不错。 但由于是一个线程，对多核 CPU 利用率不高，一旦有大量的客户端连接上来性能必然下降，甚至会有大量请求无法响应。最坏的情况是一旦这个线程哪里没有处理好进入了死循环那整个服务都将不可用！ 多线程 因此产生了多线程模型。 其实最大的改进就是将原有的事件处理改为了多线程。 可以基于 Java 自身的线程池实现，这样在大量请求的处理上性能提示是巨大的。 虽然如此，但理论上来说依然有一个地方是单点的；那就是处理客户端连接的线程。 因为大多数服务端应用或多或少在连接时都会处理一些业务，如鉴权之类的，当连接的客户端越来越多时这一个线程依然会存在性能问题。 于是又有了下面的线程模型。 主从多线程 该模型将客户端连接那一块的线程也改为多线程，称为主线程。 同时也是多个子线程来处理事件响应，这样无论是连接还是事件都是高性能的。 Netty 实现以上谈了这么多其实 Netty 的线程模型与之的类似。 我们回到之前 SpringBoot 整合长连接心跳机制 中的服务端代码： 1234567891011121314151617181920212223242526private EventLoopGroup boss = new NioEventLoopGroup();private EventLoopGroup work = new NioEventLoopGroup();/** * 启动 Netty * * @return * @throws InterruptedException */@PostConstructpublic void start() throws InterruptedException &#123; ServerBootstrap bootstrap = new ServerBootstrap() .group(boss, work) .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(nettyPort)) //保持长连接 .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new HeartbeatInitializer()); ChannelFuture future = bootstrap.bind().sync(); if (future.isSuccess()) &#123; LOGGER.info(&quot;启动 Netty 成功&quot;); &#125;&#125; 其实这里的 boss 就相当于 Reactor 模型中处理客户端连接的线程池。 work 自然就是处理事件的线程池了。 那么如何来实现上文的三种模式呢？其实也很简单： 单线程模型： 1234private EventLoopGroup group = new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap() .group(group) .childHandler(new HeartbeatInitializer()); 多线程模型： 12345private EventLoopGroup boss = new NioEventLoopGroup(1);private EventLoopGroup work = new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap() .group(boss,work) .childHandler(new HeartbeatInitializer()); 主从多线程： 12345private EventLoopGroup boss = new NioEventLoopGroup();private EventLoopGroup work = new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap() .group(boss,work) .childHandler(new HeartbeatInitializer()); 相信大家一看也明白。 总结其实看过了 Netty 的线程模型之后能否对我们平时做高性能应用带来点启发呢？ 我认为是可以的： 接口同步转异步处理。 回调通知结果。 多线程提高并发效率。 无非也就是这些，只是做了这些之后就会带来其他问题： 异步之后事务如何保证？ 回调失败的情况？ 多线程所带来的上下文切换、共享资源的问题。 这就是一个博弈的过程，想要做到一个尽量高效的应用是需要不断磨合试错的。 上文相关的代码： https://github.com/crossoverJie/netty-action 欢迎关注公众号一起交流：","categories":[{"name":"开源组件","slug":"开源组件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://imalan6.github.io/hexo_blog/tags/netty/"}]},{"title":"Netty心跳机制","slug":"netty/Netty(1)TCP-Heartbeat","date":"2020-06-12T15:12:22.000Z","updated":"2024-02-14T11:42:31.856Z","comments":false,"path":"2020/06/12/netty/Netty(1)TCP-Heartbeat/","permalink":"https://imalan6.github.io/hexo_blog/2020/06/12/netty/Netty(1)TCP-Heartbeat/","excerpt":"前言Netty 是一个高性能的 NIO 网络框架，本文基于 SpringBoot 以常见的心跳机制来认识 Netty。 最终能达到的效果： 客户端每隔 N 秒检测是否需要发送心跳。 服务端也每隔 N 秒检测是否需要发送心跳。 服务端可以主动 push 消息到客户端。 基于 SpringBoot 监控，可以查看实时连接以及各种应用信息。 效果如下：","text":"前言Netty 是一个高性能的 NIO 网络框架，本文基于 SpringBoot 以常见的心跳机制来认识 Netty。 最终能达到的效果： 客户端每隔 N 秒检测是否需要发送心跳。 服务端也每隔 N 秒检测是否需要发送心跳。 服务端可以主动 push 消息到客户端。 基于 SpringBoot 监控，可以查看实时连接以及各种应用信息。 效果如下： IdleStateHandlerNetty 可以使用 IdleStateHandler 来实现连接管理，当连接空闲时间太长（没有发送、接收消息）时则会触发一个事件，我们便可在该事件中实现心跳机制。 客户端心跳当客户端空闲了 N 秒没有给服务端发送消息时会自动发送一个心跳来维持连接。 核心代码代码如下： 12345678910111213141516171819202122232425262728293031323334public class EchoClientHandle extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(EchoClientHandle.class); @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent)&#123; IdleStateEvent idleStateEvent = (IdleStateEvent) evt ; if (idleStateEvent.state() == IdleState.WRITER_IDLE)&#123; LOGGER.info(&quot;已经 10 秒没有发送信息！&quot;); //向服务端发送消息 CustomProtocol heartBeat = SpringBeanFactory.getBean(&quot;heartBeat&quot;, CustomProtocol.class); ctx.writeAndFlush(heartBeat).addListener(ChannelFutureListener.CLOSE_ON_FAILURE) ; &#125; &#125; super.userEventTriggered(ctx, evt); &#125; @Override protected void channelRead0(ChannelHandlerContext channelHandlerContext, ByteBuf in) throws Exception &#123; //从服务端收到消息时被调用 LOGGER.info(&quot;客户端收到消息=&#123;&#125;&quot;,in.toString(CharsetUtil.UTF_8)) ; &#125;&#125; 实现非常简单，只需要在事件回调中发送一个消息即可。 由于整合了 SpringBoot ，所以发送的心跳信息是一个单例的 Bean。 123456789101112@Configurationpublic class HeartBeatConfig &#123; @Value(&quot;$&#123;channel.id&#125;&quot;) private long id ; @Bean(value = &quot;heartBeat&quot;) public CustomProtocol heartBeat()&#123; return new CustomProtocol(id,&quot;ping&quot;) ; &#125;&#125; 这里涉及到了自定义协议的内容，请继续查看下文。 当然少不了启动引导： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Componentpublic class HeartbeatClient &#123; private final static Logger LOGGER = LoggerFactory.getLogger(HeartbeatClient.class); private EventLoopGroup group = new NioEventLoopGroup(); @Value(&quot;$&#123;netty.server.port&#125;&quot;) private int nettyPort; @Value(&quot;$&#123;netty.server.host&#125;&quot;) private String host; private SocketChannel channel; @PostConstruct public void start() throws InterruptedException &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new CustomerHandleInitializer()) ; ChannelFuture future = bootstrap.connect(host, nettyPort).sync(); if (future.isSuccess()) &#123; LOGGER.info(&quot;启动 Netty 成功&quot;); &#125; channel = (SocketChannel) future.channel(); &#125; &#125;public class CustomerHandleInitializer extends ChannelInitializer&lt;Channel&gt; &#123; @Override protected void initChannel(Channel ch) throws Exception &#123; ch.pipeline() //10 秒没发送消息 将IdleStateHandler 添加到 ChannelPipeline 中 .addLast(new IdleStateHandler(0, 10, 0)) .addLast(new HeartbeatEncode()) .addLast(new EchoClientHandle()) ; &#125;&#125; 所以当应用启动每隔 10 秒会检测是否发送过消息，不然就会发送心跳信息。 服务端心跳服务器端的心跳其实也是类似，也需要在 ChannelPipeline 中添加一个 IdleStateHandler 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class HeartBeatSimpleHandle extends SimpleChannelInboundHandler&lt;CustomProtocol&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(HeartBeatSimpleHandle.class); private static final ByteBuf HEART_BEAT = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(new CustomProtocol(123456L,&quot;pong&quot;).toString(),CharsetUtil.UTF_8)); /** * 取消绑定 * @param ctx * @throws Exception */ @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; NettySocketHolder.remove((NioSocketChannel) ctx.channel()); &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent)&#123; IdleStateEvent idleStateEvent = (IdleStateEvent) evt ; if (idleStateEvent.state() == IdleState.READER_IDLE)&#123; LOGGER.info(&quot;已经5秒没有收到信息！&quot;); //向客户端发送消息 ctx.writeAndFlush(HEART_BEAT).addListener(ChannelFutureListener.CLOSE_ON_FAILURE) ; &#125; &#125; super.userEventTriggered(ctx, evt); &#125; @Override protected void channelRead0(ChannelHandlerContext ctx, CustomProtocol customProtocol) throws Exception &#123; LOGGER.info(&quot;收到customProtocol=&#123;&#125;&quot;, customProtocol); //保存客户端与 Channel 之间的关系 NettySocketHolder.put(customProtocol.getId(),(NioSocketChannel)ctx.channel()) ; &#125;&#125; 这里有点需要注意： 当有多个客户端连上来时，服务端需要区分开，不然响应消息就会发生混乱。 所以每当有个连接上来的时候，我们都将当前的 Channel 与连上的客户端 ID 进行关联（因此每个连上的客户端 ID 都必须唯一）。 这里采用了一个 Map 来保存这个关系，并且在断开连接时自动取消这个关联。 12345678910111213141516171819public class NettySocketHolder &#123; private static final Map&lt;Long, NioSocketChannel&gt; MAP = new ConcurrentHashMap&lt;&gt;(16); public static void put(Long id, NioSocketChannel socketChannel) &#123; MAP.put(id, socketChannel); &#125; public static NioSocketChannel get(Long id) &#123; return MAP.get(id); &#125; public static Map&lt;Long, NioSocketChannel&gt; getMAP() &#123; return MAP; &#125; public static void remove(NioSocketChannel nioSocketChannel) &#123; MAP.entrySet().stream().filter(entry -&gt; entry.getValue() == nioSocketChannel).forEach(entry -&gt; MAP.remove(entry.getKey())); &#125;&#125; 启动引导程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859Componentpublic class HeartBeatServer &#123; private final static Logger LOGGER = LoggerFactory.getLogger(HeartBeatServer.class); private EventLoopGroup boss = new NioEventLoopGroup(); private EventLoopGroup work = new NioEventLoopGroup(); @Value(&quot;$&#123;netty.server.port&#125;&quot;) private int nettyPort; /** * 启动 Netty * * @return * @throws InterruptedException */ @PostConstruct public void start() throws InterruptedException &#123; ServerBootstrap bootstrap = new ServerBootstrap() .group(boss, work) .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(nettyPort)) //保持长连接 .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new HeartbeatInitializer()); ChannelFuture future = bootstrap.bind().sync(); if (future.isSuccess()) &#123; LOGGER.info(&quot;启动 Netty 成功&quot;); &#125; &#125; /** * 销毁 */ @PreDestroy public void destroy() &#123; boss.shutdownGracefully().syncUninterruptibly(); work.shutdownGracefully().syncUninterruptibly(); LOGGER.info(&quot;关闭 Netty 成功&quot;); &#125;&#125; public class HeartbeatInitializer extends ChannelInitializer&lt;Channel&gt; &#123; @Override protected void initChannel(Channel ch) throws Exception &#123; ch.pipeline() //五秒没有收到消息 将IdleStateHandler 添加到 ChannelPipeline 中 .addLast(new IdleStateHandler(5, 0, 0)) .addLast(new HeartbeatDecoder()) .addLast(new HeartBeatSimpleHandle()); &#125;&#125; 也是同样将IdleStateHandler 添加到 ChannelPipeline 中，也会有一个定时任务，每5秒校验一次是否有收到消息，否则就主动发送一次请求。 因为测试是有两个客户端连上所以有两个日志。 自定义协议上文其实都看到了：服务端与客户端采用的是自定义的 POJO 进行通讯的。 所以需要在客户端进行编码，服务端进行解码，也都只需要各自实现一个编解码器即可。 CustomProtocol： 1234567public class CustomProtocol implements Serializable&#123; private static final long serialVersionUID = 4671171056588401542L; private long id ; private String content ; //省略 getter/setter&#125; 客户端的编码器： 123456789public class HeartbeatEncode extends MessageToByteEncoder&lt;CustomProtocol&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, CustomProtocol msg, ByteBuf out) throws Exception &#123; out.writeLong(msg.getId()) ; out.writeBytes(msg.getContent().getBytes()) ; &#125;&#125; 也就是说消息的前八个字节为 header，剩余的全是 content。 服务端的解码器： 12345678910111213141516public class HeartbeatDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; long id = in.readLong() ; byte[] bytes = new byte[in.readableBytes()] ; in.readBytes(bytes) ; String content = new String(bytes) ; CustomProtocol customProtocol = new CustomProtocol() ; customProtocol.setId(id); customProtocol.setContent(content) ; out.add(customProtocol) ; &#125;&#125; 只需要按照刚才的规则进行解码即可。 实现原理其实联想到 IdleStateHandler 的功能，自然也能想到它实现的原理： 应该会存在一个定时任务的线程去处理这些消息。 来看看它的源码： 首先是构造函数: 12345678public IdleStateHandler( int readerIdleTimeSeconds, int writerIdleTimeSeconds, int allIdleTimeSeconds) &#123; this(readerIdleTimeSeconds, writerIdleTimeSeconds, allIdleTimeSeconds, TimeUnit.SECONDS);&#125; 其实就是初始化了几个数据： readerIdleTimeSeconds：一段时间内没有数据读取 writerIdleTimeSeconds：一段时间内没有数据发送 allIdleTimeSeconds：以上两种满足其中一个即可 因为 IdleStateHandler 也是一种 ChannelHandler，所以会在 channelActive 中初始化任务： 1234567891011121314151617181920212223242526272829303132333435@Overridepublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // This method will be invoked only if this handler was added // before channelActive() event is fired. If a user adds this handler // after the channelActive() event, initialize() will be called by beforeAdd(). initialize(ctx); super.channelActive(ctx);&#125;private void initialize(ChannelHandlerContext ctx) &#123; // Avoid the case where destroy() is called before scheduling timeouts. // See: https://github.com/netty/netty/issues/143 switch (state) &#123; case 1: case 2: return; &#125; state = 1; initOutputChanged(ctx); lastReadTime = lastWriteTime = ticksInNanos(); if (readerIdleTimeNanos &gt; 0) &#123; readerIdleTimeout = schedule(ctx, new ReaderIdleTimeoutTask(ctx), readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (writerIdleTimeNanos &gt; 0) &#123; writerIdleTimeout = schedule(ctx, new WriterIdleTimeoutTask(ctx), writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (allIdleTimeNanos &gt; 0) &#123; allIdleTimeout = schedule(ctx, new AllIdleTimeoutTask(ctx), allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125;&#125; 也就是会按照我们给定的时间初始化出定时任务。 接着在任务真正执行时进行判断： 1234567891011121314151617181920212223242526272829303132private final class ReaderIdleTimeoutTask extends AbstractIdleTask &#123; ReaderIdleTimeoutTask(ChannelHandlerContext ctx) &#123; super(ctx); &#125; @Override protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = readerIdleTimeNanos; if (!reading) &#123; nextDelay -= ticksInNanos() - lastReadTime; &#125; if (nextDelay &lt;= 0) &#123; // Reader is idle - set a new timeout and notify the callback. readerIdleTimeout = schedule(ctx, this, readerIdleTimeNanos, TimeUnit.NANOSECONDS); boolean first = firstReaderIdleEvent; firstReaderIdleEvent = false; try &#123; IdleStateEvent event = newIdleStateEvent(IdleState.READER_IDLE, first); channelIdle(ctx, event); &#125; catch (Throwable t) &#123; ctx.fireExceptionCaught(t); &#125; &#125; else &#123; // Read occurred before the timeout - set a new timeout with shorter delay. readerIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125; &#125;&#125; 如果满足条件则会生成一个 IdleStateEvent 事件。 SpringBoot 监控由于整合了 SpringBoot 之后不但可以利用 Spring 帮我们管理对象，也可以利用它来做应用监控。 actuator 监控当我们为引入了: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 就开启了 SpringBoot 的 actuator 监控功能，他可以暴露出很多监控端点供我们使用。 如一些应用中的一些统计数据： 存在的 Beans： 更多信息请查看：https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html 但是如果我想监控现在我的服务端有多少客户端连上来了，分别的 ID 是多少？ 其实就是实时查看我内部定义的那个关联关系的 Map。 这就需要暴露自定义端点了。 自定义端点暴露的方式也很简单： 继承 AbstractEndpoint 并复写其中的 invoke 函数： 1234567891011121314151617public class CustomEndpoint extends AbstractEndpoint&lt;Map&lt;Long,NioSocketChannel&gt;&gt; &#123; /** * 监控端点的 访问地址 * @param id */ public CustomEndpoint(String id) &#123; //false 表示不是敏感端点 super(id, false); &#125; @Override public Map&lt;Long, NioSocketChannel&gt; invoke() &#123; return NettySocketHolder.getMAP(); &#125;&#125; 其实就是返回了 Map 中的数据。 再配置一个该类型的 Bean 即可： 12345678910111213@Configurationpublic class EndPointConfig &#123; @Value(&quot;$&#123;monitor.channel.map.key&#125;&quot;) private String channelMap; @Bean public CustomEndpoint buildEndPoint()&#123; CustomEndpoint customEndpoint = new CustomEndpoint(channelMap) ; return customEndpoint ; &#125;&#125; 这样我们就可以通过配置文件中的 monitor.channel.map.key 来访问了： 一个客户端连接时： 两个客户端连接时： 整合 SBA这样其实监控功能已经可以满足了，但能不能展示的更美观、并且多个应用也可以方便查看呢？ 有这样的开源工具帮我们做到了： https://github.com/codecentric/spring-boot-admin 简单来说我们可以利用该工具将 actuator 暴露出来的接口可视化并聚合的展示在页面中： 接入也很简单，首先需要引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt;&lt;/dependency&gt; 并在配置文件中加入： 1234# 关闭健康检查权限management.security.enabled=false# SpringAdmin 地址spring.boot.admin.url=http://127.0.0.1:8888 在启动应用之前先讲 SpringBootAdmin 部署好： 这个应用就是一个纯粹的 SpringBoot ，只需要在主函数上加入 @EnableAdminServer 注解。 12345678910@SpringBootApplication@Configuration@EnableAutoConfiguration@EnableAdminServerpublic class AdminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AdminApplication.class, args); &#125;&#125; 引入： 12345678910&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;1.5.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt; &lt;version&gt;1.5.6&lt;/version&gt;&lt;/dependency&gt; 之后直接启动就行了。 这样我们在 SpringBootAdmin 的页面中就可以查看很多应用信息了。 更多内容请参考官方指南： http://codecentric.github.io/spring-boot-admin/1.5.6/ 自定义监控数据其实我们完全可以借助 actuator 以及这个可视化页面帮我们监控一些简单的度量信息。 比如我在客户端和服务端中写了两个 Rest 接口用于向对方发送消息。 只是想要记录分别发送了多少次： 客户端： 123456789101112131415161718192021222324252627282930313233343536@Controller@RequestMapping(&quot;/&quot;)public class IndexController &#123; /** * 统计 service */ @Autowired private CounterService counterService; @Autowired private HeartbeatClient heartbeatClient ; /** * 向服务端发消息 * @param sendMsgReqVO * @return */ @ApiOperation(&quot;客户端发送消息&quot;) @RequestMapping(&quot;sendMsg&quot;) @ResponseBody public BaseResponse&lt;SendMsgResVO&gt; sendMsg(@RequestBody SendMsgReqVO sendMsgReqVO)&#123; BaseResponse&lt;SendMsgResVO&gt; res = new BaseResponse(); heartbeatClient.sendMsg(new CustomProtocol(sendMsgReqVO.getId(),sendMsgReqVO.getMsg())) ; // 利用 actuator 来自增 counterService.increment(Constants.COUNTER_CLIENT_PUSH_COUNT); SendMsgResVO sendMsgResVO = new SendMsgResVO() ; sendMsgResVO.setMsg(&quot;OK&quot;) ; res.setCode(StatusEnum.SUCCESS.getCode()) ; res.setMessage(StatusEnum.SUCCESS.getMessage()) ; res.setDataBody(sendMsgResVO) ; return res ; &#125;&#125; 只要我们引入了 actuator 的包，那就可以直接注入 counterService ，利用它来帮我们记录数据。 当我们调用该接口时： 在监控页面中可以查询刚才的调用情况： 服务端主动 push 消息也是类似，只是需要在发送时候根据客户端的 ID 查询到具体的 Channel 发送： 总结以上就是一个简单 Netty 心跳示例，并演示了 SpringBoot 的监控，之后会继续更新 Netty 相关内容，欢迎关注及指正。 本文所有代码： https://github.com/crossoverJie/netty-action","categories":[{"name":"开源组件","slug":"开源组件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://imalan6.github.io/hexo_blog/tags/netty/"}]},{"title":"kafka基本概念","slug":"kafka/kafka基本概念","date":"2020-05-11T13:10:29.000Z","updated":"2024-02-14T12:02:26.792Z","comments":false,"path":"2020/05/11/kafka/kafka基本概念/","permalink":"https://imalan6.github.io/hexo_blog/2020/05/11/kafka/kafka%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","excerpt":"","text":"什么是kafkaKafka最初是由Linkedin公司开发的，是一个分布式的、可扩展的、容错的、支持分区的（Partition）、多副本的（replica）、基于Zookeeper框架的发布-订阅消息系统，Kafka适合离线和在线消息消费，被广泛应用于大数据处理。Kafka是用Scala语言开发，它的Java版本称为Jafka。 基本概念主题Topic 一个主题topic包含多个分区，每个分区就是一个日志，每个日志按消息追加的方式写入分区 分区分区规则 分区规则指的是将每个Topic划分成多个分区（Partition），每个分区是一组有序的消息日志，生产者生产的每条消息只会被发送到其中一个分区。 分区 (Partition) 是一个有序的、不可变的数据序列，消息数据被不断的添加到序列的尾部。分区中的每一条消息数据都被赋予了一个连续的数字ID，即偏移量 (offset) ，用于唯一标识分区中的每条消息数据。 分区(Partition)的作用就是提供负载均衡的能力，单个topic的不同分区可存储在相同或不同节点机上，为实现系统的高伸缩性（Scalability），不同的分区被放置到不同节点的机器上，各节点机独立地执行各自分区的读写任务，如果性能不足，可通过添加新的节点机器来增加整体系统的吞吐量。 分区结构 分区数据使用消息日志（Log）方式保存数据，具体方式是在磁盘上创建只能追加写（Append-only）消息的物理文件。因为只能追加写入，因此避免了缓慢的随机I&#x2F;O操作，改为性能较好的顺序I&#x2F;O写操作。Kafka日志文件分为多个日志段（Log Segment），消息被追加写到当前最新的日志段中，当写满一个日志段后Kafka会自动切分出一个新的日志段，并将旧的日志段封存。 Kafka将消息数据根据分区进行存储，分区分为若干Segment，每个Segment的大小相等。Segment由index file、log file、timeindex file等组成，后缀为”.index”和”.log”，分别表示为Segment索引文件、数据文件，每一个Segment存储着多条信息。 分区策略 默认根据消息的key进行分区选择，即hash(key) % numPartion，保证了相同key的消息被路由到相同分区。 当key为null时，从缓存中取分区id或者随机取一个区分。 分区策略是决定生产者将消息发送到哪个分区的算法。Kafka提供默认的分区策略，同时支持自定义分区策略。 分区特点 kafka只能保证分区内消息有序，无法保证分区间有序，所以消费时，数据是相对有序的。如果要保证消费有序，必须为消息指定key，让所有消息映射到同一个分区。 BrokerBroker：一个 Kafka 节点就是一个 Broker，多个Broker可组成一个Kafka 集群。 如果某个 Topic 下有 n 个Partition 且集群有 n 个Broker，那么每个Broker会存储该 Topic 下的一个 Partition 如果某个 Topic 下有 n 个Partition 且集群中有 m+n 个Broker，那么只有 n 个Broker会存储该Topic下的一个 Partition 如果某个 Topic 下有 n 个Partition 且集群中的Broker数量小于 n，那么一个 Broker 会存储该 Topic 下的一个或多个 Partition，这种情况尽量避免，会导致集群数据不均衡","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://imalan6.github.io/hexo_blog/tags/kafka/"}]},{"title":"JVM 运行时内存结构","slug":"jvm/JVM运行时内存结构","date":"2020-04-11T13:12:22.000Z","updated":"2024-02-14T11:20:05.077Z","comments":false,"path":"2020/04/11/jvm/JVM运行时内存结构/","permalink":"https://imalan6.github.io/hexo_blog/2020/04/11/jvm/JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/","excerpt":"","text":"JVM 运行时内存结构JVM 内存结构概念Java 虚拟机定义了程序运行期间会使用的各种运行时数据区，其中有一些会随着虚拟机启动而创建，随着虚拟机的退出而销毁；而另一些则与线程一一对应，随着线程的开始而创建，随着线程的结束而销毁。具体的运行时数据区如下图所示： 在 Java 虚拟机规范中，定义了五种运行时数据区，分别是 Java 堆、方法区、虚拟机栈、本地方法区、程序计数器。其中 Java 堆和方法区是线程共享的。 Java 堆Java 堆是所有线程共享的一块内存区域，它在虚拟机启动时就会被创建，并且单个JVM进程有且仅有一个 Java 堆。Java 堆是用来存放对象实例及数组的，代码中通过new关键字创建出来的对象都存放在这里。所以这里也是垃圾回收的主要目标，于是它又叫做GC堆。根据垃圾回收器的规则，我们可以对 Java 堆进行进一步的划分，具体 Java 堆内存结构如下图所示： 我们可以将 Java 堆划分为新生代和老年代两个大模块。在新生代中，我们又可以进一步分为Eden空间、From Survivor空间（s0）、To Survivor空间（s1），Survivor 空间有一个为空，用于发生GC时存放存活对象，老年代存放的是经过多次Minor GC仍然存活的对象或者是一些大对象，FGC就是发生在老年代。 上面就是 Java 堆的具体结构，Java 堆中的各空间大小是可以动态控制的，主要通过这三个参数： -Xms：JVM 启动时申请的初始Heap值，默认为操作系统物理内存的1&#x2F;64，例如-Xms20m -Xmx：JVM 可申请的最大Heap值，默认值为物理内存的1&#x2F;4，例如-Xmx20m。最好将-Xms和-Xmx设为相同值，避免每次垃圾回收完成后 JVM 重新分配内存； -Xmn：设置新生代的内存大小，-Xmn是将NewSize与MaxNewSize设为一致，也可以分别设置这两个参数。 Java 虚拟机规范规定，Java 堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。也就是说堆的内存是一块块拼凑起来的。要增加堆空间时，往上“拼凑”（可扩展性）即可，但当堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出java.lang.OutOfMemoryError: Java heap space异常。 方法区方法区（Method Area）与 Java 堆一样，是各个线程共享的内存区域，是 Java 虚拟机中唯二的内存共享区域。在 Java 虚拟机规范中是这样定义方法区的：它存储了每个类的结构信息，例如运行时常量池、字段、方法数据、构造函数和普通方法的字节码内容，还包括一些在类、实例、接口初始化时用到的特殊方法。 方法区在虚拟机启动的时候被创建，虽然方法区是堆的逻辑组成部分，但是简单的虚拟机实现可以选择在这个区域不实现垃圾收集与压缩，方法区在实际内存空间中可以不是连续的，对于方法区的容量，你可以是固定的，也可以随着程序的执行动态扩展，并且在不需要过多空间时自动收缩。 上面都是 Java 虚拟机中的规范，来看看具体的实现，拿我们常用的HotSpot虚拟机来说，在 JDK1.8 之前，方法区也被称作为永久代，这个方法区会发生我们常见的java.lang.OutOfMemoryError: PermGen space异常，我们也可以通过启动参数来控制方法区的大小： -XX:PermSize 设置最小空间 -XX:MaxPermSize 设置最大空间 在 JDK1.8 之后，HotSpot 虚拟机对方法区进行了改动，移除了永久代，将原来存放在永久代的数据迁移到 Java 堆和Metaspace，方法区被移至到了Metaspace，字符串常量移至Java Heap。也就是说从 JDK1.8 开始，Metaspace也就是我们所谓的方法区，为什么要做这个改变呢？可能是因为以下两点原因： 由于PermGen内存经常会溢出，引发恼人的java.lang.OutOfMemoryError: PermGen，因此JVM的开发者希望这一块内存可以灵活管理，不要再经常出现这样的OOM。 移除PermGen可以促进HotSpot JVM与JRockit VM的融合，因为JRockit没有永久代。 可以通过设置参数来控制Metaspace的空间大小，主要有以下几个命令： -XX:MetaspaceSize ：分配给类元数据空间（以字节计）的初始大小。MetaspaceSize的值设置的过大会延长垃圾回收时间。垃圾回收过后，引起下一次垃圾回收的类元数据空间的大小可能会变大。 -XX:MaxMetaspaceSize： 分配给类元数据空间的最大值，超过此值就会触发Full GC，此值默认没有限制，但应取决于系统内存的大小。JVM会动态地改变此值。 -XX:MinMetaspaceFreeRatio：表示一次GC以后，为了避免增加元数据空间的大小，空闲的类元数据的容量的最小比例，不够就会导致垃圾回收。 -XX:MaxMetaspaceFreeRatio：表示一次GC以后，为了避免增加元数据空间的大小，空闲的类元数据的容量的最大比例，不够就会导致垃圾回收。 Java 虚拟机栈每一个线程都拥有自己私有的 Java 虚拟机栈。这个 Java 虚拟机栈跟线程同时创建，所以它跟线程有相同的生命周期。Java 虚拟机栈描述的是 Java 方法执行的内存模型：每一个方法在执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，每一个方法从调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中的入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身。根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 其中 64 位长度的long和double类型的数据会占用 2 个局部变量空间（Slot），其余的数据类型只占用 1 个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 Java 虚拟机栈既允许被实现成固定的大小，也允许根据计算动态来扩展和收缩。如果采用固定大小的话，每一个线程的 Java 虚拟机栈容量可以在线程创建的时候独立选定。在 Java 虚拟机栈中会发生两种异常： 如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出StackOverflowError异常； 如果 Java 虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存或者在创建新的线程时没有足够的内存去创建对应的 Java 虚拟机栈，那么虚拟机将会抛出java.lang.OutOfMemoryError:Unable to create new native thread异常。 程序计数器程序计数器也是线程私有的，它只需要一块较小的内存空间，你可以把它看作当前线程所执行的字节码的行号指示器，在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 我们知道在多线程的情况下，并不是一条线程一直执行完，而是多个线程轮流切换执行，所以为了线程切换后能够恢复到正确的执行位置，我们就需要程序计数器来告诉线程接下来该执行哪条指令。如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址，如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 需要特别注意的是，程序计数器是唯一一个在 Java 虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 本地方法栈本地方法栈（Native Method Stacks）与 Java 虚拟机栈所发挥的作用是非常相似的，其区别不过是 Java 虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的 Native 方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。 与 Java 虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 常见内存溢出错误有了对JVM内存结构的清晰认识，就可以帮助我们理解不同的OutOfMemoryErrors，下面列举一些比较常见的内存溢出错误，通过查看冒号“：”后面的提示信息，基本上就能断定是JVM运行时数据的哪个区域出现了问题。 1Exception in thread “main”: java.lang.OutOfMemoryError: Java heap space 原因：对象不能被分配到堆内存中。 1Exception in thread “main”: java.lang.OutOfMemoryError: PermGen space 原因：类或者方法不能被加载到老年代。它可能出现在一个程序加载很多类的时候，比如引用了很多第三方的库。 1Exception in thread “main”: java.lang.OutOfMemoryError: Requested array size exceeds VM limit 原因：创建的数组大于堆内存的空间。 1Exception in thread “main”: java.lang.OutOfMemoryError: request &lt;size&gt; bytes for &lt;reason&gt;. Out of swap space? 原因：分配本地分配失败。JNI、本地库或者Java虚拟机都会从本地堆中分配内存空间。 1Exception in thread “main”: java.lang.OutOfMemoryError: &lt;reason&gt; &lt;stack trace&gt;（Native method） 原因：同样是本地方法内存分配失败，只不过是JNI或者本地方法或者 Java 虚拟机发现。 小结JVM 采用栈和堆的设计思路，使得栈是运行时的单位，而堆是存储的单位。栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪儿。 在 Java 中，一个线程有相应的一个线程栈与之对应，因为不同的线程执行逻辑有所不同，因此需要一个独立的线程栈。而堆则是所有线程共享的。栈因为是运行单位，因此里面存储的信息都是跟当前线程（或程序）运行相关信息的。包括局部变量、程序运行状态、方法返回值等；而堆只负责存储对象信息。 栈是程序运行最根本的东西，程序运行可以没有堆，但是不能没有栈。而堆是为栈进行数据存储服务的，是一块共享的内存。不过，正是因为栈和堆分离设计的思想，才使得 Java 的垃圾回收更方便。 在 Java 中，main方法就是栈的起始点，也是程序的起始点。程序要运行总是有一个起点的。同 C 语言一样，Java 中的main就是那个起点，无论什么 Java 程序，找到main方法，就找到了程序执行的入口。程序运行永远都是在栈中进行的，因而参数传递时，只存在传递基本类型和对象引用的问题，不会直接传对象本身。 JVM 内存结构的基本情况大致总结如下：","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"}]},{"title":"docker部署nginx配置SSL证书实现https","slug":"docker/docker部署nginx配置SSL证书实现https","date":"2020-03-23T06:11:09.000Z","updated":"2024-02-14T10:18:54.307Z","comments":false,"path":"2020/03/23/docker/docker部署nginx配置SSL证书实现https/","permalink":"https://imalan6.github.io/hexo_blog/2020/03/23/docker/docker%E9%83%A8%E7%BD%B2nginx%E9%85%8D%E7%BD%AESSL%E8%AF%81%E4%B9%A6%E5%AE%9E%E7%8E%B0https/","excerpt":"","text":"docker部署nginx配置SSL证书实现https拉镜像1#docker pull nginx 创建并启动容器1234567docker run -p 8443:443 --name nginx8443 \\-v /usr/local/docker/nginx8443/html:/usr/share/nginx/html \\-v /usr/local/docker/nginx8443/logs:/var/log/nginx \\-v /usr/local/docker/nginx8443/conf/nginx.conf:/etc/nginx/nginx.conf \\-v /usr/local/docker/nginx8443/conf/cert:/etc/nginx/cert \\-v /etc/localtime:/etc/localtime \\-d nginx volume映射参数： &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html：部署网站的根目录 &#x2F;etc&#x2F;nginx&#x2F;nginx.conf：nginx配置文件 &#x2F;etc&#x2F;nginx&#x2F;cert：证书存放目录 说明：因为服务器上的443端口已经被其他项目占用，这里使用8443端口来部署，记得打开防火墙端口限制。运行时会报如下错误： 这是由于/etc/nginx/nginx.conf是目录，却被映射到文件。只需要到/usr/local/docker/nginx8443/conf/目录下删除nginx.conf目录，然后新建一个nginx.conf配置文件即可，见第三步。 添加配置文件到/usr/local/docker/nginx8443/conf/目录下删除nginx.conf目录，然后新建一个nginx.conf配置文件，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; ssl on; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ssl_certificate /etc/nginx/cert/xxx.pem; #证书路径 ssl_certificate_key /etc/nginx/cert/xxx.key; #请求认证 key 的路径 server &#123; listen 443; #监听端口，ssl默认443端口。如果需要配置多个端口，可以继续添加server，用不同的端口就行 server_name www.xxx.com; #服务器域名，需要和申请的证书匹配 location / &#123; root /usr/share/nginx/html; #网站根目录，和容器创建时指定的位置一致 index index.html index.htm; &#125; &#125;&#125; 添加完配置文件后，重启nginx容器，并检查下日志看是否有error。 12#docker restart nginx8443#docker logs nginx8843 测试重启容器，一切正常后，在/usr/local/docker/nginx8443/html目录下，新建一个index.html，输入hello world！，浏览器访问https://www.xxx.com:8443，即可正常访问。","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"},{"name":"网络安全","slug":"docker/网络安全","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"},{"name":"nginx","slug":"nginx","permalink":"https://imalan6.github.io/hexo_blog/tags/nginx/"},{"name":"ssl证书","slug":"ssl证书","permalink":"https://imalan6.github.io/hexo_blog/tags/ssl%E8%AF%81%E4%B9%A6/"},{"name":"https","slug":"https","permalink":"https://imalan6.github.io/hexo_blog/tags/https/"},{"name":"网络安全","slug":"网络安全","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"docker部署nexus私有仓库","slug":"docker/docker部署nexus私有仓库","date":"2020-03-18T15:11:21.000Z","updated":"2024-02-14T10:18:32.114Z","comments":false,"path":"2020/03/18/docker/docker部署nexus私有仓库/","permalink":"https://imalan6.github.io/hexo_blog/2020/03/18/docker/docker%E9%83%A8%E7%BD%B2nexus%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/","excerpt":"","text":"docker部署nexus私有仓库简介最近项目需要对接银行系统，对方提供了一些jar包，这些三方jar是没有上传到中央仓库的，所以无法直接在maven中依赖，因此决定搭建一个Maven私服来处理。maven仓库的使用结构如下图： 通常，我们开发项目并没有使用到虚线标识的那两部分，基本都是通过本机的Maven直接访问中央仓库，下载jar包到本地仓库。现在我们需要搭建中间虚线部分。 docker安装nexus1、下载镜像官方镜像地址：https://hub.docker.com/r/sonatype/nexus3/tags 1#docker pull sonatype/nexus3 //下载镜像 2、安装12345#mkdir /usr/local/docker/nexus //新建目录#chmod 777 /usr/local/docker/nexus //修改权限//nexus默认使用8081端口#docker run -d --restart=always -p 8081:8081 --name nexus -v /usr/local/docker/nexus:/nexus-data sonatype/nexus3 3、nexus密码安装完成后可访问管理平台：http://ip:8081 默认管理员用户名：admin 密码：admin123 如果提示密码不对，需要到容器里面去修改密码。方式如下： 12345//进入容器#docker exec -it nexus /bin/bash//进入/opt/sonatype/sonatype-work/sonatype-work/目录，找到admin.password文件，里面的内容就是密码#cat admin.password 红色部分就是admin的密码。这个只是临时密码，修改密码后admin.password文件会消失。 配置nexus登录nexus管理平台后（注意必须admin登录才行，不然只能浏览模式），可以看到如下界面： 1、创建Blob stores在创建repository之前，还需要先指定文件存储目录，便于统一管理。就需要创建Blob stores 创建好后可以看到blob stores有两个，一个是系统默认的，一个是刚创建的。如果不想自己创建，使用系统默认的文件存储目录（在sonatype-work/nexus3/blobs）也是可以的。到时候创建repository时，存储目录选择default就可以了。 2、nexus仓库 如图所示，代理仓库负责代理远程中央仓库，托管仓库负责本地资源，组资源库 &#x3D; 代理资源库 + 托管资源库。 3、创建proxy repository代理仓库 选择maven2(proxy)，代理仓库 设置代理仓库 其他的可以采用默认，以后需要修改的可以再修改。 4.创建hosted repository仓库 上图的Hosted设置选项，选项中有三个值： Allow redeploy：允许同一个版本号下重复提交代码, nexus以时间区分 Disable redeploy：不允许同一个版本号下重复提交代码 Read-Only：不允许提交任何版本 原生的maven-releases库是Disable redeploy设置， maven-snapshots是Allow redeploy。 5、创建group repository组仓库 将hosted repositories宿主仓库的顺序放在proxy repositories代理仓库之前，因为一个group仓库组中可以包括宿主仓库和代理仓库。而整个group repository是作为一个public repository给用户使用的。 所以当查找jar包的时候，如果代理资源库在前面，那就是先从远程去查找jar包，而不是先从宿主仓库（本地仓库）去查找jar包。 设置mavenMaven下的setting.xml文件和项目中的pom.xml文件的关系是：settting.xml文件是全局设置，而pom.xml文件是局部设置。pom.xml文件对于项目来说，是优先使用的。而pom.xml文件中如果没有配置镜像地址的话，就按照settting.xml中定义的地址去查找。 1、修改maven配置文件setting.xml 如上图方式获取组仓库smart_group的仓库地址，修改setting.xml文件如下： 1234567891011121314151617&lt;!--nexus服务器,id为组仓库name--&gt;&lt;servers&gt; &lt;server&gt; &lt;id&gt;smart_group&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;!--仓库组的url地址，id和name可以写组仓库name，mirrorOf的值设置为central--&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;smart_group&lt;/id&gt; &lt;name&gt;smart_group&lt;/name&gt; &lt;url&gt;http://******:8081/repository/smart_group/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 修改后可以重新编译项目，必须添加参数-U,（-U，--update-snapshots，强制更新releases、snapshots类型的插件或依赖库，否则maven一天只会更新一次snapshot依赖）。代理仓库会从远程中央仓库下载jar包 1#mvn clean compile -U 这个时候可以看到代理仓库已经从中央仓库下载了项目编译需要的jar包。同样地，在组仓库中也能看到所有的jar包，包括代理仓库和宿主仓库的。 2、通过管理平台上传三方jar包有些jar是第三方提供的，在中央仓库中是没有的，我们可以上传这些本地三方jar包到hosted repository宿主仓库中。 上传成功后，就可以看到hosted repository和group repository中已经有了刚上传的三方jar包 然后项目中通过编译打包就可以下载jar包到本地repository中了，记住maven clean、compile、package首次执行时加参数-U。 3、通过命令上传三方jar包在setting.xml配置文件中添加hosted repository server 123456&lt;!--id自定义，但是在使用命令上传的时候会用到--&gt;&lt;server&gt; &lt;id&gt;smart_hosted&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; 使用如下命令上传jar包： 1mvn deploy:deploy-file -DgroupId=com.alan6.land -DartifactId=land-user -Dversion=0.0.1 -Dpackaging=jar -Dfile=d:\\land-service-user.jar -Durl=http://ip:8081/repository/smart_group/ -DrepositoryId=smart_group 命令解释： -DgroupId&#x3D;com.alan6.land 自定义 -DartifactId&#x3D;land-user 自定义 -Dversion&#x3D;0.0.1 自定义，三个自定义，构成pom.xml文件中的标识 -Dpackaging&#x3D;jar 传的类型是jar类型 -Dfile&#x3D;D:\\jar\\land-user-0.0.1.jar jar包的本地磁盘位置 -Durl&#x3D;http://ip:8081/repository/smart_hosted/ hosted资源库的地址 -DrepositoryId&#x3D;smart_hosted 需要和setting.xml文件中配置的ID一致 上传成功后，hosted repository中已经可以看到了 deploy部署jar包到私服1、release和snapshots jar包区别SNAPSHOT版本代表不稳定（快照版本），还在处于开发阶段，随时都会有变化。当上传同样的版本号jar包的时候，SNAPSHOT会在版本号的后面自动追加一串新的数字，即日志标签，nexus会根据日志标签区分出不同的版本，在maven引用时，如果使用的是snapshot版本，重新导入maven的时候，会去私库拉取最新上传的代码。 RELEASE则代表稳定的版本（发布版本），一般上线后都会改用RELEASE版本。也就是说1.0，2.0这样的版本只能有一个，也就是说当前版本号下，不可能出现不同的jar。 2、创建snapshot仓库可以在nexus上添加一个snapshot仓库，专门用于存放snapshot版本的jar包。snapshot仓库也是hosted类型的，创建方式和hosted repository类型。创建好后，加入到组仓库里面就可以了。 3、项目pom.xml文件配置可以在项目的pom文件中设置具体的releases库和snapshots库。如果当前项目的版本号的后缀名中带着-SNAPSHOT，类似&lt;version&gt;***-SNAPSHOT&lt;/version&gt;，就会将项目jar包提交到snapshots库中，没有带-SNAPSHOT的话会提交releases库中。 在pom.xml文件中配置distributionManagement节点如下，在项目中执行deploy命令后，jar包将会被上传到nexus中。 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;!--release版本仓库--&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://ip:8081/repository/smart_hosted/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;!--snapshot版本仓库--&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://ip:8081/repository/smart_snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 默认地，maven编译打包不会下载SNAPSHOT版本的jar包，所以还需要在pom.xml文件中配置支持下载snapshot版本jar包。 123456789&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;smart_group&lt;/id&gt; &lt;url&gt;http://ip:8081/repository/smart_group/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 至此，nexus搭建完毕，支持本地部署依赖jar包","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"},{"name":"nexus","slug":"nexus","permalink":"https://imalan6.github.io/hexo_blog/tags/nexus/"}]},{"title":"JVM 类加载器和双亲委派机制","slug":"jvm/JVM类加载器和双亲委派机制","date":"2020-03-18T05:45:03.000Z","updated":"2024-02-14T11:20:05.037Z","comments":false,"path":"2020/03/18/jvm/JVM类加载器和双亲委派机制/","permalink":"https://imalan6.github.io/hexo_blog/2020/03/18/jvm/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%92%8C%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/","excerpt":"","text":"JVM 类加载器和双亲委派机制类加载器Java 虚拟机的类加载有三大步骤：加载，链接，初始化。其中加载是指查找字节流（也就是由 Java 编译器生成的 class 文件）并据此创建类的过程，这中间我们需要借助类加载器来查找字节流。Java 虚拟机提供了 3 种类加载器，分别是：启动（Bootstrap）类加载器、扩展（Extension）类加载器、应用（Application）类加载器。除了启动类加载器外，其他的类加载器都是java.lang.ClassLoader的子类。 1）启动类&#x2F;引导类加载器：Bootstrap ClassLoader 启动类加载器，也叫根类加载器。这个类加载器使用 C&#x2F;C++ 语言实现的，嵌套在 JVM 内部，java 程序无法直接操作这个类。它用来加载 Java 核心类库，如：JAVA_HOME/jre/lib/rt.jar、resources.jar、sun.boot.class.path路径下的包，用于提供 jvm 运行所需的包。 启动类加载器比较特殊，它不是java.lang.ClassLoader的子类，它没有父类加载器。它加载扩展类加载器和应用程序类加载器，并成为他们的父类加载器。 出于安全考虑，启动类只加载包名为：java、javax、sun开头的类。 2）扩展类加载器：Extension ClassLoader Java 语言编写，由sun.misc.Launcher$ExtClassLoader实现，派生继承自java.lang.ClassLoader，父类加载器为启动类加载器。 负责加载扩展目录 (%JAVA_HOME%/jre/lib/ext) 下的jar包，用户可以把自己开发的类打包成jar包放在这个目录下即可扩展核心类以外的新功能。 3）应用程序类加载器：Application Classloader Java 语言编写，由sun.misc.Launcher$AppClassLoader实现，派生继承自java.lang.ClassLoader，父类加载器为启动类加载器。负责加载CLASSPATH环境变量所指定的jar包与类路径。一般来说，用户自定义的类就是由APP ClassLoader加载的。开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 应用程序都是由以上三种类加载器互相配合进行加载的。如果有需要，我们也可以自定义类加载器。因为 JVM 自带的 ClassLoader 只能从本地文件系统加载标准的 class 文件，如果编写了自己的 ClassLoader，便可以做到如下几点： 1）在执行代码之前，自动验证数字签名。 2）动态地创建符合用户特定需要的定制化构建类。 3）从特定的场所取得 java class，例如数据库中和网络中。 JVM 类加载机制 1）全盘负责。当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入。 2）父类委托。先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类。 3）缓存机制。缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效。 类加载方式类加载有三种方式： 1）命令行启动应用时候由 JVM 初始化加载； 2）通过Class.forName()方法动态加载； 3）通过ClassLoader.loadClass()方法动态加载。 例子： 12345678910111213141516package com.neo.classloader;public class loaderTest &#123; public static void main(String[] args) throws ClassNotFoundException &#123; ClassLoader loader = HelloWorld.class.getClassLoader(); System.out.println(loader); //使用ClassLoader.loadClass()来加载类，不会执行初始化块 loader.loadClass(&quot;Test&quot;); //使用Class.forName()来加载类，默认会执行初始化块 Class.forName(&quot;Test&quot;); //使用Class.forName()来加载类，并指定ClassLoader，初始化时不执行静态块 Class.forName(&quot;Test&quot;, false, loader); &#125; &#125; Test 类代码： 12345public class Test &#123; static &#123; System.out.println(&quot;静态初始化块执行了！&quot;); &#125; &#125; 分别切换加载方式，会有不同的输出结果。 Class.forName()和ClassLoader.loadClass()区别： 1）Class.forName()：将类的.class文件加载到JVM中之外，还会对类进行解释，执行类中的static块； 2）ClassLoader.loadClass()：只干一件事情，就是将.class文件加载到 JVM 中，不会执行static中的内容,只有在newInstance才会去执行static块。 3）Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。 双亲委派机制JVM 对class文件采用的是按需加载的方式，当需要使用该类时，JVM 才会将它的class文件加载到内存中产生class对象。 在加载类的时候，是采用的双亲委派机制，即把请求交给父类处理的一种任务委派模式。 工作原理 1）如果一个类加载器接收到了类加载请求，它自己不会先去加载，而是把这个请求委托给父类加载器去执行。 2）如果父类还存在父类加载器，则继续向上委托，一直委托到启动类加载器：Bootstrap ClassLoader。 3）如果父类加载器可以完成加载任务，就返回成功结果；如果父类加载失败，则由子类自己去尝试加载，如果子类加载失败就会抛出ClassNotFoundException异常，这就是双亲委派模式。 我们来看ClassLoader中loadClass方法： 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 首先判断类是否已加载过，加载过就直接返回 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; //有父类加载器，调用父加载器的loadClass c = parent.loadClass(name, false); &#125; else &#123; //调用Bootstrap Classloader c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; long t1 = System.nanoTime(); //到自己指定类加载路径下查找是否有class字节码 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 这种加载方式可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子类加载器再加载一次。其次也考虑到安全因素，比如我们自己写的一个java.lang.String的类，通过双亲委派机制传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载我们新写的java.lang.String，而直接返回已加载过的String.class，这样保证生成的对象是同一种类型。 自定义类加载器通常情况下，我们都是直接使用 JVM 提供的类加载器。但某些情况下，我们需要自定义类加载器。比如应用是通过网络来传输 Java 类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。 自定义一个Person类，代码如下： 1234567public class Person &#123; private int age; private String name; //省略getter/setter方法&#125; 测试代码： 1234567public class Test &#123; public static void main(String[] args) throws Exception &#123; Person person = new Person(); System.out.println(&quot;person是由&quot; + person.getClass().getClassLoader() + &quot;加载的&quot;); &#125;&#125; 运行结果如下： 然后把Person.class放置在其他目录下 再运行测试代码，发现会抛出ClassNotFoundException异常，因为在指定路径下查找不到class文件。 现在，我们自定义一个类加载器，负责加载Person类。我们只需要继承ClassLoader并重写findClass方法即可，这里面写查找字节码的逻辑。 1234567891011121314151617181920212223242526272829public class PersonClassLoader extends ClassLoader &#123; private String classPath; public PersonClassLoader(String classPath) &#123; this.classPath = classPath; &#125; private byte[] loadByte(String name) throws Exception &#123; name = name.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;); FileInputStream fis = new FileInputStream(classPath + &quot;/&quot; + name + &quot;.class&quot;); int len = fis.available(); byte[] data = new byte[len]; fis.read(data); fis.close(); return data; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try &#123; byte[] data = loadByte(name); return defineClass(name, data, 0, data.length); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new ClassNotFoundException(); &#125; &#125;&#125; 测试类： 12345678public class Test &#123; public static void main(String[] args) throws Exception &#123; PersonClassLoader classLoader = new PersonClassLoader(&quot;/home/shenxinjian&quot;); Class&lt;?&gt; pClass = classLoader.loadClass(&quot;com.test.classloading.demo.Person&quot;); System.out.println(&quot;person是由&quot; + pClass.getClassLoader() + &quot;类加载器加载的&quot;); &#125;&#125; 自定义类加载器的核心在于对字节码文件的获取，如果是加密的字节码则需要在该类中对文件进行解密。这里的测试代码并未对class文件进行加密，因此没有解密的过程。这里需要注意： 1）这里传递的文件名需要是类的全限定性名称，即com.test.classloading.demo.Person 格式的，因为defineClass方法是按这种格式进行处理的。 2）最好不要重写loadClass方法，因为这样容易破坏双亲委托模式。 3）Person类本身可以被 AppClassLoader类加载，因此我们不能把com/test/classloading/demo/Person.class放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由AppClassLoader加载，而不会通过我们自定义类加载器来加载。 自定义类加载器作用 1）当class文件不在classPath路径下，如上面那种情况，默认系统类加载器无法找到该class文件，在这种情况下我们需要实现一个自定义的classLoader来加载特定路径下的class文件来生成class对象。 2）当一个class文件是通过网络传输并且可能会进行相应的加密操作时，需要先对class文件进行相应的解密后再加载到 JVM 内存中，这种情况下也需要编写自定义的ClassLoader并实现相应的逻辑。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"}]},{"title":"JVM 类加载机制","slug":"jvm/JVM类加载机制","date":"2020-03-17T15:12:23.000Z","updated":"2024-02-14T11:20:05.017Z","comments":false,"path":"2020/03/17/jvm/JVM类加载机制/","permalink":"https://imalan6.github.io/hexo_blog/2020/03/17/jvm/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"JVM 类加载机制概念首先，在代码编译后，就会生成 JVM（Java 虚拟机）能够识别的二进制字节流文件（*.class）。JVM 把 class 文件中的类描述数据从文件加载到内存，并对数据进行校验、转换解析、初始化，使这些数据最终成为可以被 JVM 直接使用的 Java 类型，这个过程就叫做 JVM 的类加载机制。 类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类加载的最终结果是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向 Java 程序员提供了访问方法区内的数据结构的接口。 类加载器并不需要等到某个类被首次使用时再加载它，JVM 规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）。如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 加载 .class 文件的主要方式如下： 1）从本地系统中的.class文件直接加载 2）从zip，jar，war等归档文件中加载.class文件 3）通过网络下载.class文件 4）从专有数据库中提取.class文件 5）将 Java 源文件动态编译为.class文件 类的生命周期类的生命周期是指一个 class 从加载到内存直至卸载出内存的过程，包含加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段，如下图所示： 其中，验证、准备、解析三个阶段统称为连接（Linking），而加载、连接、初始化又可以统称为类加载的过程，所以我们有时又可以称类的生命周期包含加载、连接、初始化、使用和卸载这5个阶段，或者是类加载、使用、卸载这3个阶段。 回到上图，加载、验证、准备、初始化和卸载这5个阶段的开始顺序是确定的，如图中箭头所示。之所以强调“开始顺序”，是因为这里的先后顺序仅仅是各阶段开始时间的顺序，而不是进行或完成的顺序，这些阶段通常是相互交叉地混合式进行的。比如加载和验证，并不是说非要等到加载完成之后，才开始验证阶段，在加载的阶段中，会穿插各种检验动作，否则对于连格式都不符合的字节流，又怎能正确解析出其中的静态数据结构从而转化为方法区中的数据结构呢？对于解析阶段，其开始时间则比较特殊，既可能在加载阶段就开始（对常量池中的符号引用的解析），也可能在初始化阶段之后才开始（支持 Java 语言的动态绑定）。 加载 主要流程 加载过程不是指的类加载机制，而是类加载机制中的加载阶段。在这个阶段，JVM 主要完成3件事： 1）通过一个类的全限定名（包名 + 类名）来获取定义此类的二进制字节流（class文件）。 2）将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。方法区就是用来存放已被加载的类信息，常量，静态变量，编译后的代码的运行时内存区域。 3）在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 相对于类加载机制的其他阶段，加载阶段相对来说可控性比较强，该阶段既可以使用系统提供的类加载器完成，也可以由用户自定义的类加载器来完成。开发人员可以通过定义自己的类加载器去控制字节流的获取方式。加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中，而且在 Java 堆（永久代）中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 对于上述中所说的“内存”，虚拟机规范并没有明确规定是在 Java 堆还是方法区中，对于我们最为熟悉的 HotSpot 虚拟机，是存放在 Java 堆的永久代中。实际上永久代是 HotSpot 虚拟机特有的，是它对虚拟机规范中方法区概念的具体实现（JDK1.7 及以下，在 JDK1.8 及以上叫做元空间 metaspace）。 加载时机 虚拟机规范中并未强制规定加载阶段具体什么时候开始，由虚拟机自由把握。就我们所熟知的 HotSpot 虚拟机来说，有两种情况： 1）预加载。虚拟机在启动时会预先加载rt.jar中的class文件，其中包括java.lang.*、java.util.*、java.io.*等运行时常用的类。 2）运行时加载。当虚拟机在运行过程中需要某个类时，如果该类的class未被加载则加载。 连接阶段1、验证连接的第一个阶段，确保从 class 文件中所加载的字节流符合当前虚拟机的要求，且不会危害虚拟机自身的安全。该阶段会依次进行如下验证： 1）文件格式验证：判断当前字节流是否符合class文件格式的规范。如是否以class文件的oxCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中常量的类型是否合法等等。校验的目的是保证字节流能正确地解析并存储于方法区内，通过验证后，会在方法区中存储，后面的校验动作都是基于方法区的存储结构进行，不再直接操作字节流。 2）元数据验证：语义分析，判断其描述的信息是否符合 Java 语言的规范要求。如该类除了java.lang.Object之外，是否有其他父类；该类的父类是否继承了不允许被继承的final类等 3）字节码验证：通过数据流和控制流分析，判断程序语义是否合法、符合逻辑。如保证跳转指令不会跳转到方法体以外的字节码指令上、方法体中的类型转换是有效的等。 4）符号引用验证：发生在解析阶段将符号引用转为直接引用的时候，确保解析动作能正确执行。如符号引用中通过字符串描述的全限定名是否能找到对应类。 从上面可以看出，验证阶段非常重要，关乎虚拟机的安全，但它并不是必须的，它对程序运行期没有影响，如果所引用的类已被反复使用和验证过，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。通常来讲，应用所加载的class文件都是由我们本地或服务器的 JDK 编译通过的，我们都确定它是符合虚拟机要求的，对于这类class文件其实并不需要验证，主要是像从网络加载的class字节流或是通过动态字节码技术生成的字节流，出于安全的考虑，是必须要经过严格验证的。 2、准备准备阶段做的唯一一件事就是为类的静态变量分配内存，并将其初始化为默认值。注意这里的初始化和后面要讲的“初始化阶段”是不同的，容易混淆。这些内存都在方法区中分配。注意事项如下： 1）对于初始化为默认值这一点，有两个角度的理解：从 Java 应用层面讲，会为不同的类型设置对应的零值，如对于int、long、byte等整数对应就是 0，对于float、double等浮点数则是 0.0，而对于引用类型则是 null，有个零值映射表；从 JVM 层面，实际上就是分配了一块全 0 值的内存，只是不同的数据类型对于 0 值有不同的解释含义，这是 Java 编译器自动完成的。 2）如果类的静态变量是 final 类型的，即它的字段属性表中存在ConstantValue属性，那么在准备阶段就会被初始化为程序指定的值，比如对于public static final int len = 10，在准备阶段len的值已经被设置为10了。实际上对于final的类变量，在编译时就已经将其结果放入了调用它的类的常量池中，这种类变量的访问并不会触发其所属类的初始化阶段。 3、解析该阶段把类在常量池中的符号引用转为直接引用。符号引用就是一组用来描述目标的字面量，说白了就是静态的占位符，与内存布局无关，而直接引用则是运行时的，是指内存中直接指向目标的指针、相对偏移量或间接定位到目标的句柄。解析工作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符这7类符号引用，将其替换为直接引用。 初始化 类初始化方式 初始化，就是执行类的构造器方法init()，为类的静态变量赋予正确的初始值的过程。JVM 负责对类进行初始化，主要对类变量进行初始化。在 Java 中对类变量进行初始值设定有两种方式： 1）声明类变量时指定初始值； 2）使用静态代码块为类变量指定初始值。 类初始化步骤 1）假如这个类还没有被加载和连接，则程序先加载并连接该类； 2）假如该类的直接父类还没有被初始化，则先初始化其直接父类； 3）假如类中有初始化语句，则系统依次执行这些初始化语句。 类初始化时机 只有当对类主动使用的时候才会导致类的初始化，Java虚拟机规范中严格规定了有且只有五种情况必须对类进行初始化： 1）使用new字节码指令创建类的实例，或者使用getstatic、putstatic读取或设置一个静态字段的值（放入常量池中的常量除外），或者调用一个静态方法的时候，对应类必须进行过初始化。 2）通过java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则要首先进行初始化。 3）当初始化一个类的时候，如果发现其父类没有进行过初始化，则首先触发父类初始化。 4）当虚拟机启动时，用户需要指定一个主类（包含main()方法的类），虚拟机会首先初始化这个类。 5）使用 jdk1.7 的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、RE_invokeStatic的方法句柄，并且这个方法句柄对应的类没有进行初始化，则需要先触发其初始化。 被动引用实例 例子一： 通过子类引用父类的静态字段，对于父类属于“主动引用”的第一种情况，父类会被初始化；对于子类，没有符合“主动引用”的情况，故子类不会进行初始化。代码如下： 123456789101112131415161718192021222324//父类class SuperClass &#123; //静态变量value public static int value = 666; //静态块，父类初始化时会调用 static&#123; System.out.println(&quot;父类初始化！&quot;); &#125;&#125;//子类class SubClass extends SuperClass&#123; //静态块，子类初始化时会调用 static&#123; System.out.println(&quot;子类初始化！&quot;); &#125;&#125;//主类、测试类public class InitTest &#123; public static void main(String[] args)&#123; System.out.println(SubClass.value); &#125;&#125; 输出结果： 12父类初始化！666 例子二： 通过数组来引用类，不会触发类的初始化，因为是数组被new，但是类没有被new，所以没有触发任何“主动引用”情况，属于“被动引用”。代码如下： 12345678910111213141516//父类class SuperClass &#123; //静态变量value public static int value = 666; //静态块，父类初始化时会调用 static&#123; System.out.println(&quot;父类初始化！&quot;); &#125;&#125;//主类、测试类public class InitTest &#123; public static void main(String[] args)&#123; SuperClass[] test = new SuperClass[10]; &#125;&#125; 没有任何结果输出。 例子三： 静态常量在编译阶段就会被存入调用类的常量池中，不会引用到定义常量的类，这是一个特例，不会触发类的初始化。 123456789101112131415//常量类class ConstClass &#123; static&#123; System.out.println(&quot;常量类初始化！&quot;); &#125; public static final String HELLOWORLD = &quot;hello world!&quot;;&#125;//主类、测试类public class NotInit &#123; public static void main(String[] args)&#123; System.out.println(ConstClass.HELLOWORLD); &#125;&#125; 输出结果： 1hello world! 卸载当一个类被判定为无用类时，才可以被卸载，需要同时满足如下条件： 1）类的所有实例都已被回收； 2）加载该类的ClassLoader已被回收； 3）该类对应的java.lang.Class对象没有在任何地方被引用。 对于满足上述 3 个条件的无用类，虚拟机可以对其进行回收，但并不是必然的，是否回收可通过-Xnoclassgc参数控制。在大量使用反射、动态代理等字节码框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代（特指HotSpot虚拟机）不会溢出。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"}]},{"title":"JVM 垃圾回收机制","slug":"jvm/JVM垃圾回收机制","date":"2020-03-13T13:11:12.000Z","updated":"2024-02-14T11:20:05.004Z","comments":false,"path":"2020/03/13/jvm/JVM垃圾回收机制/","permalink":"https://imalan6.github.io/hexo_blog/2020/03/13/jvm/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/","excerpt":"","text":"JVM 垃圾回收机制GC 作用垃圾回收GC（Garbage Collection）是JVM垃圾回收器提供的一种用于在空闲时间不定时回收无任何对象引用的对象占据的内存空间的一种机制，目的是为了清除不再使用的对象，从而释放内存空间。因为程序在运行过程中会不断的分配内存空间，如果不进行垃圾回收，内存迟早会被消耗空。除非内存无限大，我们可以任意的分配而不回收，否则垃圾回收是必须的。 对象引用关系从JDK 1.2版本开始，Java 存在4种对象引用关系。什么的对象引用关系，决定了其是否需要被垃圾回收，以及被回收的时机。详见 对象引用关系总结。 1）强引用（Strong Reference）：如 “Object obj = new Object()”，这类引用是 Java 程序中最普遍的。只要强引用还存在，垃圾收集器就永远不会回收掉被引用的对象。 2）软引用（Soft Reference）：它用来描述一些可能还有用，但并非必须的对象。在系统内存不够用时，这类引用关联的对象将被垃圾收集器回收。JDK1.2 之后提供了 SoftReference 类来实现软引用。 3）弱引用（Weak Reference）：它也是用来描述非必须对象的，但它的强度比软引用更弱些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在 JDK1.2 之后，提供了WeakReference类来实现弱引用。 4）虚引用（Phantom Reference）：最弱的一种引用关系，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的是希望能在这个对象被收集器回收时收到一个系统通知。JDK1.2 之后提供了PhantomReference类来实现虚引用。 对象存活分析算法Java 语言规范没有明确说明 JVM 使用哪种垃圾回收算法，但是任何一种垃圾回收算法一般要做两件基本的事情： 1）找到所有存活对象。 2）回收被无用对象占用的内存空间，使该空间可被程序再次使用。 因此，垃圾收集器在对堆区和方法区进行回收前，首先要确定这些区域的对象哪些可以被回收，哪些还不能回收，这就需要先判断对象是否存活。常用的对象存活判定算法如下： 引用计数算法（Reference Counting） 引用计数是垃圾收集器中的早期策略，这种方法很简单。它实际上是通过在每个对象头中分配一个空间来保存该对象被引用的次数。当一个对象被创建时，将其被引用的次数设置为1。当任何其它变量被赋值为这个对象的引用时，计数加1（比如：a = b，则b引用的对象实例的计数+1）。但当一个对象实例的某个引用超过了生命周期或者被赋值为一个新值时，也就是删除对该对象的引用时，对象实例的引用计数-1。当该对象的引用计数为0时，那么该对象就会被回收。 优点：引用计数收集器执行简单，判定效率高，交织在程序运行中。对程序不被长时间打断的实时环境比较有利。 缺点：无法检测对象之间的循环引用关系。同时，引用计数器增加了程序执行的开销。所以 Java 语言并没有选择这种算法进行垃圾回收。 如下代码： 123456789101112131415161718public class ReferenceTest &#123; public static void main(String[] args) &#123; TestObject object1=new TestObject(); TestObject object2=new TestObject(); object1.object=object2; object2.object=object1; object1=null; object2=null; &#125;&#125;class TestObject&#123; TestObject object;&#125; 这段代码是用来验证引用计数算法不能检测出循环引用。最后面两句将object1和object2赋值为null，也就是说object1和object2指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为 0，那么垃圾收集器就永远不会回收它们。 引用计数垃圾收集机制是在引用计数变化为 0 的即刻发生，而且只针对某一个对象以及它所依赖的其它对象。所以，我们一般也称呼引用计数垃圾收集为直接的垃圾收集机制。而采用引用计数的垃圾收集机制将垃圾收集的开销分摊到整个应用程序的运行当中，而不是在进行垃圾收集时，要挂起整个应用的运行，直到对堆中所有对象的处理都结束。因此，采用引用计数的垃圾收集不属于严格意义上的 “Stop-The-World“ 的垃圾收集机制。 可达性分析算法（根搜索算法） 可达性分析算法是从离散数学中的图论引入的，程序把所有的引用关系看作一张图，从一个节点GC ROOT开始，寻找对应的引用节点，找到这个节点以后，继续寻找这个节点的引用节点，当所有的引用节点寻找完毕之后，剩余的没有被引用到的节点，则被认为是无用的节点，将会被判定为是可回收的对象。 在 Java 语言中，将某些特殊的对象定义为GC Roots，包括下面几种： 1）虚拟机栈中引用的对象（栈帧中的本地变量表）； 2）方法区中类静态属性引用的对象； 3）方法区中常量引用的对象； 4）本地方法栈中 JNI（Native方法）引用的对象。 关于标记引用节点需要注意： 1）开始进行标记前，需要先暂停应用线程，否则如果对象图一直在变化的话是无法真正去遍历它的。暂停应用线程以便 JVM 可以更好地分析对象引用关系，这种情况被称之为安全点（Safe Point），这会触发一次Stop The World(STW)暂停。触发安全点的原因很多，但最常见的就是垃圾回收了。 2）暂停时间的长短并不取决于堆内对象的多少也不是堆的大小，而是存活对象的多少。因此，调高堆的大小并不会影响到标记阶段的时间长短。 另外，可达性分析算法能正确处理循环引用，保证每个活对象只会被访问一次就能确定其存活性。对象图里是否存在循环引用，可达性分析都能正确判断对象的存活与否。 垃圾回收（GC）算法 标记-清除算法（Mark-Sweep） 这是最基础的垃圾回收算法，之所以说它是最基础的是因为它最容易实现，思想也是最简单的。标记-清除算法分为两个阶段：标记阶段和清除阶段。标记阶段的任务是标记出所有需要被回收的对象，清除阶段就是回收被标记的对象所占用的空间。具体过程如下图所示： 标记-清除算法采用从根集合（GC Roots）进行扫描，对存活的对象进行标记，标记完毕后，再扫描整个空间中未被标记的对象，进行回收，如下图所示。标记-清除算法不需要进行对象的移动，只需对不存活的对象进行处理，在存活对象比较多的情况下极为高效。 优点：不需要进行对象的移动，并且仅对不存活的对象进行处理，在存活对象比较多的情况下极为高效。 缺点：1）标记和清除过程效率都不高。这种方法需要使用一个空闲列表来记录所有的空闲区域及大小，对空闲列表的管理也会增加工作量。2）标记清除后会产生大量不连续的内存碎片。碎片太多可能会导致后续过程中需要为大对象分配空间时无法找到足够的空间而再次触发新的垃圾回收动作。 复制算法（Copying） 为了解决 Mark-Sweep 算法的缺陷，Copying 算法被提了出来。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用的内存空间一次清理掉，这样一来就不容易产生内存碎片的问题。具体过程如下图所示： 这种算法虽然实现简单，运行高效也不容易产生内存碎片，但是内存使用率却大大降低，将能够使用的内存缩减到原来的一半。另外，Copying 算法的效率跟存活对象的数目有很大的关系，如果存活对象很多，那么 Copying 算法的效率将大大降低。 复制算法的提出是为了克服句柄的开销和解决内存碎片的问题。它开始时把堆分成一个对象面和多个空闲面，程序从对象面为对象分配空间，当对象满了，基于Copying 算法的垃圾收集就从根集合（GC Roots）中扫描活动对象，并将每个活动对象复制到空闲面，使得活动对象所占的内存之间没有空闲区域，这样空闲面变成了对象面，而原来的对象面变成了空闲面，程序会在新的对象面分配内存。 标记—整理算法（Mark-compact） 为了解决 Copying 算法的缺陷，充分利用内存空间，提出了 Mark-Compact 算法。该算法的标记阶段和 Mark-Sweep 算法一样，但是在完成标记之后，它不是直接清理可回收对象，而是将存活对象向一端移动，然后清理掉存活对象端边界以外的内存。在把存活对象集中向某端移动过程中，不需要处理被标记为垃圾的对象，因为迟早会被回收，所以可以直接覆盖它们的内存空间。当存活对象移动完毕，除开存活对象端边界以外的剩余内存都是可回收的。 标记-整理算法是在标记-清除算法的基础上，又进行了对存活对象的移动，因此代价更高，但是却解决了内存碎片的问题。具体流程如下图： 分代收集算法（Generational Collection） 分代收集算法是目前大部分 JVM 垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为新生代（Young Generation）和老年代（Tenured Generation），在堆区之外还有一个永久代（Permanet Generation）。新生代的特点是每次垃圾回收时都有大量对象需要被回收，而老年代的特点是每次垃圾回收时只有少量对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。 目前大部分垃圾收集器对于新生代都采取 Copying 算法，因为新生代中每次垃圾回收都要回收大部分对象，也就是说需要复制的操作次数较少，但是实际项目中并不是按照 1 ：1 的比例来划分新生代空间的。一般来说是将新生代划分为一块较大的Eden空间和两块较小的Survivor空间（通常为 8 : 1 : 1）。每次使用Eden空间和其中的一块Survivor空间。当进行垃圾回收时，将Eden和Survivor中还存活的对象复制到另一块Survivor空间中，然后清理掉Eden和刚才使用过的Survivor空间。 而由于老年代的特点是每次回收都只回收少量对象，所以一般使用的是 Mark-Compact 算法。 1、年轻代（Young Generation）的回收算法 (回收主要以 Copying 为主) a）所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。 b）新生代内存按照 8 : 1 : 1 的比例分为一个eden区和两个survivor（survivor0，survivor1）区。大部分对象在Eden区中生成。回收时先将eden区存活对象复制到一个survivor0区，然后清空eden区；当 survivor0 区也存放满了时，则将eden区和survivor0区存活对象复制到另一个survivor1区，然后清空eden 区和survivor0区，此时survivor0区是空的，然后将survivor0区和survivor1区交换，即保持survivor1区为空， 如此往复。当Eden区没有足够空间的时候就触发 jvm 发起一次Minor GC。 c）当survivor1区不足以存放eden和survivor0的存活对象时，就将存活对象直接存放到老年代。若是老年代也满了就会触发一次Full GC (Major GC)，也就是新生代、老年代都进行回收。 d）新生代发生的GC叫做Minor GC，Minor GC发生频率比较高，且不一定等Eden区满了才触发。 2、年老代（Old Generation）的回收算法（回收主要以 Mark-Compact 为主） a）在年轻代中经历了多次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 b）内存比新生代也大很多（大概比例是 1 : 2），当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。 3、持久代（Permanent Generation）也就是方法区的回收算法 持久代也称方法区，用于存放静态文件，如 Java 类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。 方法区存储内容是否需要回收的判断条件不一样。方法区主要回收的内容有：废弃常量和无用的类。对于废弃常量也可通过引用的可达性来判断，但是对于无用的类则需要同时满足下面 3 个条件： a）该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例； b）加载该类的ClassLoader已经被回收； c）该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 永久代空间在 Java 8 中已经被移除。取而代之的是元空间（MetaSpace）。因此不会再出现 “java.lang.OutOfMemoryError: PermGen error” 错误。 垃圾回收器按执行机制划分，Java 有四种类型的垃圾回收器，分别是：串行垃圾回收器（Serial Garbage Collector），并行垃圾回收器（Parallel Garbage Collector），并发标记扫描垃圾回收器（CMS Garbage Collector），G1垃圾回收器（G1 Garbage Collector）。 每种垃圾回收器都有自己的特点，适合不同的应用场景。我们可以通过设置不同的JVM参数选择不同的垃圾回收器。 串行垃圾回收器（Serial Garbage Collector） 它为单线程环境设计，只使用一个单独的线程进行垃圾回收，运行时会冻结所有应用程序线程进行工作，可能不适合服务器环境。它最适合的是简单的命令行程序，是client级别默认的GC方式。 通过JVM参数-XX:+UseSerialGC可以使用串行垃圾回收器。 并行垃圾回收器（Parallel Garbage Collector） 与串行垃圾回收器不同，它使用多线程进行垃圾回收。但当执行垃圾回收时，它也会冻结所有的应用程序线程。它是JVM默认垃圾回收器。适用于多CPU、对暂停时间要求较短的应用上，是server级别默认采用的GC方式。 通过JVM参数-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数。 并发标记扫描垃圾回收器（CMS Garbage Collector） 并发标记垃圾回收使用多线程扫描堆内存，标记需要清理的实例并清理被标记过的实例。并发标记垃圾回收器只会在下面两种情况持有应用程序所有线程。 1）当标记的引用对象在Tenured区域； 2）在进行垃圾回收的时候，堆内存的数据被并发改变。 相比并行垃圾回收器，并发标记扫描垃圾回收器使用更多的CPU来确保程序的吞吐量。如果可以分配更多CPU，那么并发标记扫描垃圾回收器是更好的选择。 通过JVM参数-XX:+USeParNewGC使用并发标记扫描垃圾回收器。 G1垃圾回收器（G1 Garbage Collector） G1是一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。 它是专门针对以下应用场景设计的：像CMS收集器一样，能与应用程序线程并发执行。整理空闲空间更快，需要GC停顿时间更好预测。不希望牺牲大量的吞吐性能，不需要更大的Java Heap。 G1收集器的设计目标是取代CMS收集器，它同CMS相比，在以下方面表现的更出色： 1）G1是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。 2）G1的Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。 以上各种GC机制是需要组合使用的，指定方式由下表所示：","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"}]},{"title":"JVM垃圾回收器总结","slug":"jvm/JVM常见垃圾回收器","date":"2020-03-08T14:32:23.000Z","updated":"2024-02-14T11:20:04.974Z","comments":false,"path":"2020/03/08/jvm/JVM常见垃圾回收器/","permalink":"https://imalan6.github.io/hexo_blog/2020/03/08/jvm/JVM%E5%B8%B8%E8%A7%81%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/","excerpt":"","text":"JVM垃圾回收器总结常见3类垃圾回收器1.新生代收集器 Serial PraNew Parallel Scavenge 2.老年代收集器 Serial Old Parallel Old CMS 3.可用于新生代和老年代 G1 新生代垃圾回收器1.Serial串行收集器—复制算法 Serial 收集器是新生代单线程收集器，优点是简单高效，算是最基本、发展历史最悠久的收集器。它在进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集完成。 Serial 收集器依然是虚拟机运行在Client模式下默认新生代收集器，对于运行在Client模式下的虚拟机来说是一个很好的选择。 2.ParNew收集器—复制算法 ParNew 收集器是新生代并行收集器，其实就是Serial收集器的多线程版本。 除了使用多线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样。 3.Parallel Scavenge（并行回收）收集器—复制算法 Parallel Scavenge收集器是新生代并行收集器，追求高吞吐量，高效利用 CPU。 该收集器的目标是达到一个可控制的吞吐量（Throughput）。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 &#x3D; 运行用户代码时间 &#x2F;（运行用户代码时间 + 垃圾收集时间） 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可用高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 老年代垃圾回收器1.Serial Old 收集器—标记整理算法 Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程(串行)收集器，使用标记整理算法。这个收集器的主要意义也是在于给Client模式下的虚拟机使用。 如果在Server模式下，主要两大用途： 1）在 JDK1.5 以及之前的版本中与Parallel Scavenge收集器搭配使用 2）作为 CMS 收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用 2.Parallel Old 收集器—标记整理算法 Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和“标记-整理”算法。这个收集器在1.6中才开始提供。 3.CMS收集器—标记整理算法 CMS(Concurrent Mark Sweep) 收集器是一种以获取最短回收停顿时间为目标的收集器。 目前很大一部分的 Java 应用集中在互联网站或者 B&#x2F;S 系统的服务端上，这类应用尤其重视服务器的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS 收集器就非常符合这类应用的需求。 CMS收集器是基于“标记—清除”算法实现的，它的运作过程相对前面几种收集器来说更复杂一些，整个过程分为4个步骤： 1）初始标记； 2）并发标记； 3）重新标记； 4）并发清除。 其中，初始标记、重新标记这两个步骤仍然需要 “Stop The World” CMS收集器主要优点： 1）并发收集； 2）低停顿。 CMS三个明显的缺点： 1）CMS收集器无法处理浮动垃圾，可能出现 “Concurrent Mode Failure” 失败而导致另一次Full GC的产生。在JDK1.5的默认设置下，CMS 收集器当老年代使用了68%的空间后就会被激活； 2）CMS收集器无法处理浮动垃圾，可能出现 “Concurrent Mode Failure” 失败而导致另一次Full GC的产生。在JDK1.5的默认设置下，CMS 收集器当老年代使用了68%的空间后就会被激活。 3）CMS是基于“标记-清除”算法实现的收集器，手机结束时会有大量空间碎片产生。空间碎片过多，可能会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前出发FullGC。 新生代&#x2F;老年代垃圾回收器1.G1收集器—标记整理算法 JDK1.7 后全新的回收器, 用于取代CMS收集器。 G1收集器的优势： 1）独特的分代垃圾回收器,分代GC: 分代收集器, 同时兼顾年轻代和老年代； 2）使用分区算法, 不要求eden, 年轻代或老年代的空间都连续； 3）并行性: 回收期间, 可由多个线程同时工作, 有效利用多核cpu资源； 4）空间整理: 回收过程中, 会进行适当对象移动, 减少空间碎片； 5）可预见性:G1可选取部分区域进行回收, 可以缩小回收范围, 减少全局停顿。 G1收集器的运作大致可划分为以下步骤： G1收集器的阶段分以下几个步骤： 1）初始标记（它标记了从GC Root开始直接可达的对象）； 2）并发标记（从GC Roots开始对堆中对象进行可达性分析，找出存活对象）； 3）最终标记（标记那些在并发标记阶段发生变化的对象，将被回收）； 4）筛选回收（首先对各个Regin的回收价值和成本进行排序，根据用户所期待的GC停顿时间指定回收计划，回收一部分Region）。 总结本文主要介绍了 JVM 中的垃圾回收器，主要包括串行回收器、并行回收器以及 CMS回收器、G1回收器。他们各自都有优缺点，通常来说你需要根据你的业务，进行基于垃圾回收器的性能测试，然后再做选择。下面给出配置回收器时，经常使用的参数： -XX:+UseSerialGC：在新生代和老年代使用串行收集器 -XX:+UseParNewGC：在新生代使用并行收集器 -XX:+UseParallelGC ：新生代使用并行回收收集器，更加关注吞吐量 -XX:+UseParallelOldGC：老年代使用并行回收收集器 -XX:ParallelGCThreads：设置用于垃圾回收的线程数 -XX:+UseConcMarkSweepGC：新生代使用并行收集器，老年代使用CMS+串行收集器 -XX:ParallelCMSThreads：设定CMS的线程数量 -XX:+UseG1GC：启用G1垃圾回收器","categories":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"}]},{"title":"SpringBoot集成Netty","slug":"springboot/SpringBoot集成Netty","date":"2020-02-12T13:23:36.000Z","updated":"2024-02-14T11:29:03.340Z","comments":false,"path":"2020/02/12/springboot/SpringBoot集成Netty/","permalink":"https://imalan6.github.io/hexo_blog/2020/02/12/springboot/SpringBoot%E9%9B%86%E6%88%90Netty/","excerpt":"","text":"SpringBoot集成Netty添加依赖12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.36.Final&lt;/version&gt;&lt;/dependency&gt; 服务处理类123456789101112131415161718192021222324252627282930@Slf4jpublic class NettyServerHandler extends ChannelInboundHandlerAdapter &#123; //连接建立 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.info(&quot;连接建立&quot;); &#125; //收到消息 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; log.info(&quot;服务器收到消息: &#123;&#125;&quot;, msg.toString()); ctx.write(&quot;返回消息&quot;); ctx.flush(); &#125; //链接关闭 @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; log.info(&quot;关闭连接&quot;); &#125; //发生异常 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 初始化类123456789public class ServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; //添加编解码 socketChannel.pipeline().addLast(&quot;decoder&quot;, new StringDecoder(CharsetUtil.UTF_8)); socketChannel.pipeline().addLast(&quot;encoder&quot;, new StringEncoder(CharsetUtil.UTF_8)); socketChannel.pipeline().addLast(new NettyServerHandler()); &#125;&#125; Netty Server启动类12345678910111213141516171819202122232425262728293031@component@Slf4jpublic class NettyServer &#123; @PostConstruct public void start() throws InterruptedException &#123; //主线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(5); //工作线程组 EventLoopGroup workGroup = new NioEventLoopGroup(20); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class) //服务端可连接队列数,对应TCP/IP协议listen函数中backlog参数 .option(ChannelOption.SO_BACKLOG, 1024) //设置TCP长连接,一般如果两个小时内没有数据的通信时,TCP会自动发送一个活动探测数据报文 .childOption(ChannelOption.SO_KEEPALIVE, true) .localAddress(inetSocketAddress) .childHandler(serverChannelInitializer); ChannelFuture future = bootstrap.bind().sync(); if(future.isSuccess()) &#123; log.info(&quot;启动netty Server&quot;); &#125; &#125; @PreDestroy public void destory() throws InterruptedException &#123; bossGroup.shutdownGracefully().sync(); workerGroup.shutdownGracefully().sync(); log.info(&quot;关闭netty&quot;); &#125;&#125; SpringBoot启动类123456@SpringBootApplicationpublic class NettyApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NettyApplication.class, args); &#125;&#125;","categories":[{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://imalan6.github.io/hexo_blog/tags/netty/"},{"name":"springboot","slug":"springboot","permalink":"https://imalan6.github.io/hexo_blog/tags/springboot/"}]},{"title":"安装docker，docker compose","slug":"docker/安装docker和dockercompose","date":"2019-12-12T07:59:59.000Z","updated":"2024-02-14T10:19:28.369Z","comments":false,"path":"2019/12/12/docker/安装docker和dockercompose/","permalink":"https://imalan6.github.io/hexo_blog/2019/12/12/docker/%E5%AE%89%E8%A3%85docker%E5%92%8Cdockercompose/","excerpt":"","text":"安装docker，docker compose安装docker1、升级所有包（这步版本够用不要随便进行，会更新系统内核，可能导致开不了机）1#yum update //升级所有包，同时升级软件和系统内核(#yum upgrade //升级所有包，不升级软件和系统内核） 2、安装依赖包1#yum install -y yum-utils device-mapper-persistent-data lvm2 3、添加aliyun docker软件包源1#yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 4、添加软件包源到本地缓存12#yum makecache fast#rpm --import https://mirrors.aliyun.com/docker-ce/linux/centos/gpg 5、安装docker1#yum -y install docker-ce 6、设置开机启动docker1#systemctl enable docker 7、重启docker1#systemctl restart docker &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 添加国内源：修改或新增 /etc/docker/daemon.json1234#vim /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;: [&quot;https://pee6w651.mirror.aliyuncs.com&quot;]&#125; 附国内镜像：docker 官方中国区：https://registry.docker-cn.com 网易：http://hub-mirror.c.163.com 中国科技大学：https://docker.mirrors.ustc.edu.cn 阿里云：https://pee6w651.mirror.aliyuncs.com 1#systemctl restart docker.service 安装docker-composeDocker Compose项目是Docker官方的开源项目，负责实现对Docker容器集群的快速编排。Docker Compose中的两个重要概念： 服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例 项目 (project)：由一组关联的应用容器组成的一个完整业务单元 一个项目可以由多个服务关联（容器）而成，并使用docker-compose.yml进行管理。 方法一：1、下载软件包1#curl -L https://github.com/docker/compose/releases/download/1.25.5/docker-compose-`uname -s `-`uname -m` &gt; /usr/local/bin/docker-compose 2、添加可执行权限1#chmod +x /usr/local/bin/docker-compose 3、检查安装1#docker-compose -v 方法二：1、检查linux有没有安装python-pip包1#yum install python-pip -y 2、没有python-pip包就执行命令1#yum -y install epel-release 3、执行成功之后，再次执行1#yum install python-pip 4、对安装好的pip进行升级1#pip install --upgrade pip 5、安装docker-compose1#pip install docker-compose 6、检查安装1#docker-compose -version","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"}]},{"title":"一次慢查询sql导致的故障排查","slug":"mysql/一次慢查询sql导致的故障排查","date":"2019-11-22T07:24:19.000Z","updated":"2024-02-14T11:24:46.241Z","comments":false,"path":"2019/11/22/mysql/一次慢查询sql导致的故障排查/","permalink":"https://imalan6.github.io/hexo_blog/2019/11/22/mysql/%E4%B8%80%E6%AC%A1%E6%85%A2%E6%9F%A5%E8%AF%A2sql%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/","excerpt":"","text":"一次慢查询sql导致的故障排查最近项目后台管理系统出现问题，页面刷新没有数据，这里记录一下排查和解决的过程。 现象1、后台页面没有数据，刷新也不起作用。 2、查看浏览器页面接口返回消息，后台接口报错500，初步定为应该后台接口出了问题。 3、检查后台服务，hystrix报timeout，相关服务超时。 问题分析1、查看被调用的服务，没有报错，但是log没有继续打印，最后执行完几条sql后卡住了，初步估计是运行太慢导致的问题。 2、服务没有问题，就得看看数据库是否出问题了，执行 #show processlist 查看mysql正在运行的sql线程。发现有部分sql语句卡住，状态一直是Sending data，没有变过。这是导致mysql运行慢的问题了 3、查看mysql慢查询日志，发现有部分sql执行效率太低，query time超过了10秒（相当慢的查询，数据库工程师背锅）。和上面卡住的sql语句一比对，发现正是这部分sql，那问题是找到了。 解决1、explain分析sql，查看是否使用索引； 2、优化sql，查询时间要小于2s； 3、加大mysql缓存","categories":[{"name":"数据库","slug":"数据库","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://imalan6.github.io/hexo_blog/tags/mysql/"}]},{"title":"Idea使用docker插件部署服务到远程服务器","slug":"docker/Idea使用docker插件部署服务到远程服务器","date":"2019-11-18T05:15:29.000Z","updated":"2024-02-14T10:14:55.257Z","comments":false,"path":"2019/11/18/docker/Idea使用docker插件部署服务到远程服务器/","permalink":"https://imalan6.github.io/hexo_blog/2019/11/18/docker/Idea%E4%BD%BF%E7%94%A8docker%E6%8F%92%E4%BB%B6%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1%E5%88%B0%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"Idea使用docker插件部署服务到远程服务器docker部署单个服务1、Idea安装docker插件 首先给Idea安装docker插件，方式为：File ——&gt; Settings ——&gt; Plugins，安装后重启IDE 2、配置远程docker主机 1）首先登陆远程docker主机，修改配置文件/usr/lib/systemd/system/docker.service 1#vim /usr/lib/systemd/system/docker.service 打开文件，找到ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock这一行，在后面添加-H tcp://0.0.0.0:2375，表示打开2375端口，支持远程连接docker 2）修改文件后保存，重新加载配置文件并重启docker服务 12#systemctl daemon-reload#systemctl restart docker.service 3）Idea配置docker主机，File ——&gt; Settings ——&gt;Build，Execution，Depolyment ——&gt; Docker，添加一个Docker主机，TCP socket中添加远程主机+端口，以tcp://开头，tcp://192.168.0.6:2375，添加后会自动连接远程docker主机，下方看到connection successful表示连接成功，否则表示连接失败。 4）docker主机连接成功后，在docker插件面板中可以看到docker主机的容器和镜像，以及docker容器运行的日志等信息 3、创建Dockerfile文件 在服务根目录创建docker文件夹，路径如下 在docker目录创建一个Dockerfile文件，内容： 12345FROM java:8VOLUME /tmpADD land-service-hi.jar app.jarEXPOSE 8800ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 内容参数解释见docker 4、配置pom文件 在build的plugins插件标签中添加： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;!-- 打包成可执行jar包 --&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;utf-8&lt;/encoding&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;!--将插件绑定在某个phase执行--&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;!--用户只需执行mvn package ，就会自动执行mvn docker:build--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!--指定docker文件目录--&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;/docker&lt;/dockerDirectory&gt; &lt;!--指定生成的镜像名--&gt; &lt;imageName&gt;land/$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;!--指定标签--&gt; &lt;imageTags&gt; &lt;imageTag&gt;latest&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;!--指定远程 docker api地址--&gt; &lt;dockerHost&gt;http://192.168.0.6:2375&lt;/dockerHost&gt; &lt;!-- 这里是复制 jar 包到 docker 容器指定目录配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;!--jar 包所在的路径 此处配置的 即对应 target 目录--&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;!-- 需要包含的 jar包 ，这里对应的是 Dockerfile中添加的文件名 --&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 5、打包部署 通过上面一系列配置后，maven打包服务时将自动build 镜像到远程主机，通过docker插件的面板可以看到镜像已经推送到远程主机 1#mvn clean package -DskipTests docker部署多个服务1、服务创建容器 给每个服务都进行上面的配置后，使用maven在父项目打包时，将自动上传所有服务的镜像到远程docker主机。这样，虽然上传了服务镜像到远程主机，但远程主机并没有创建和启动对应的容器。 方法：可以通过在docker面板手动创建容器，以后每次使用maven打包服务时，不仅会上传镜像同时还会自动重启远程主机的docker容器。 同样地，为每个服务手动创建一个容器，然后在项目根目录打包时，每个服务的镜像都会上传到远程docker主机并自动重启容器。 2、使用docker-compose 可以使用上面手动创建容器的方法，让远程docker主机启动容器。也可以待各个服务镜像上传到远程主机后，使用docker-compose完成服务编排，然后启动各个微服务。 1）在远程docker主机编辑docker-compose.yml文件 12345678910111213141516171819202122232425262728293031version: &#x27;2&#x27;services: land-eureka: image: land/land-eureka:latest container_name: land-eureka ports: - &#x27;8761:8761&#x27; land-zuul: image: land/land-zuul:latest container_name: land-zuul ports: - &#x27;9000:9000&#x27; land-netty: image: land/land-netty:latest container_name: land-netty ports: - &#x27;8000:8000&#x27; land-service-hi: image: land/land-service-hi:latest container_name: land-service-hi ports: - &#x27;8800:8800&#x27; land-service-consumer: image: land/land-service-consumer:latest container_name: land-service-consumer ports: - &#x27;8801:8801&#x27; 2）在docker-compose.yml文件目录下运行docker-compose命令，启动容器 1#docker-compose up -d","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"}]},{"title":"docker部署redis","slug":"docker/docker部署redis","date":"2019-11-11T15:35:09.000Z","updated":"2024-02-14T10:19:17.130Z","comments":false,"path":"2019/11/11/docker/docker部署redis/","permalink":"https://imalan6.github.io/hexo_blog/2019/11/11/docker/docker%E9%83%A8%E7%BD%B2redis/","excerpt":"","text":"docker部署redis1、搜索镜像1#docker search redis 2、拉取镜像1#docker pull redis 3、创建redis容器1#docker run -d --name redis --restart always -p 6379:6379 -v /usr/local/redis/data:/data redis --requirepass &quot;123456&quot; --appendonly yes 创建redis容器（指定配置文件）#docker run -d --name redis --restart always -p 6379:6379 -v /usr/local/redis/config:/etc/redis -v /usr/local/redis/data:/data redis redis-server /etc/redis/redis.conf --requirepass &quot;123456&quot; --appendonly yes 参数说明： -p 6379:6379 容器redis端口6379映射宿主主机6379 –name redis 容器名字为redis -v &#x2F;usr&#x2F;local&#x2F;redis&#x2F;conf:&#x2F;etc&#x2F;redis docker镜像redis默认无配置文件，在宿主主机/usr/local/redis/conf下创建redis.conf配置文件，会将宿主机的配置文件复制到docker中 -v &#x2F;root&#x2F;redis&#x2F;redis01&#x2F;data:&#x2F;data 容器/data映射到宿主机/usr/local/redis/data下 -d redis 后台模式启动redis redis-server &#x2F;etc&#x2F;redis&#x2F;redis.conf redis将以/etc/redis/redis.conf为配置文件启动 –appendonly yes 开启redis的AOF持久化，默认为false，不持久化","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"}]},{"title":"docker部署elk日志采集系统（kafka方式）","slug":"docker/docker部署elk日志采集系统（kafka方式）","date":"2019-10-17T15:11:09.000Z","updated":"2024-02-14T10:12:58.908Z","comments":false,"path":"2019/10/17/docker/docker部署elk日志采集系统（kafka方式）/","permalink":"https://imalan6.github.io/hexo_blog/2019/10/17/docker/docker%E9%83%A8%E7%BD%B2elk%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E7%B3%BB%E7%BB%9F%EF%BC%88kafka%E6%96%B9%E5%BC%8F%EF%BC%89/","excerpt":"","text":"docker部署elk日志采集系统（kafka方式）logback+elk，tcp方式发送环境搭建参考上一篇：docker部署elk日志采集系统（tcp方式） tcp方式存在的问题：tcp方式在日志量比较大，并发量较高的情况下，可能导致日志丢失。可以考虑采用kafka保存日志消息，做一个流量削峰。 logback+kafka+elk1、docker安装zookeeper+kafka 拉镜像： 12#docker pull wurstmeister/zookeeper#docker pull wurstmeister/kafka 运行zookeeper： 1#docker run -d --name zookeeper --restart always --publish 2181:2181 --volume /etc/localtime:/etc/localtime wurstmeister/zookeeper:latest 运行kafka： 12345#docker run -d --name kafka --restart always --publish 9092:9092 --link zookeeper --env KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \\--env KAFKA_ADVERTISED_HOST_NAME=kafka所在宿主机的IP \\--env KAFKA_ADVERTISED_PORT=9092 \\--volume /etc/localtime:/etc/localtime \\wurstmeister/kafka:latest 2、配置logback发送到kafka 在服务端的pom文件添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.github.danielwegener&lt;/groupId&gt; &lt;artifactId&gt;logback-kafka-appender&lt;/artifactId&gt;&lt;/dependency&gt; 在logback-spring.xml配置文件中添加appender 1234567891011121314151617181920212223&lt;appender name=&quot;kafka&quot; class=&quot;com.github.danielwegener.logback.kafka.KafkaAppender&quot;&gt; &lt;encoder class=&quot;com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder&quot;&gt; &lt;layout class=&quot;net.logstash.logback.layout.LogstashLayout&quot; &gt; &lt;includeContext&gt;true&lt;/includeContext&gt; &lt;includeCallerData&gt;true&lt;/includeCallerData&gt; &lt;customFields&gt;&#123;&quot;system&quot;:&quot;test&quot;&#125;&lt;/customFields&gt; &lt;fieldNames class=&quot;net.logstash.logback.fieldnames.ShortenedFieldNames&quot;/&gt; &lt;/layout&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!--kafka topic 需要与配置文件里面的topic一致 --&gt; &lt;topic&gt;kafka_elk&lt;/topic&gt; &lt;keyingStrategy class=&quot;com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy&quot; /&gt; &lt;deliveryStrategy class=&quot;com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy&quot; /&gt; &lt;producerConfig&gt;bootstrap.servers=192.168.33.128:9092&lt;/producerConfig&gt;&lt;/appender&gt;&lt;!-- 日志输出级别 --&gt;&lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;appender-ref ref=&quot;FILE&quot;/&gt; &lt;appender-ref ref=&quot;kafka&quot; /&gt;&lt;/root&gt; 3、配置logstash 启动elk，进入容器： 1#docker exec -it elk /bin/bash 进入/etc/logstash/conf.d/目录，创建配置文件logstash.conf，编辑内容，主要是input和output 12345678910111213141516171819input &#123; kafka &#123; bootstrap_servers =&gt; [&quot;192.168.33.128:9092&quot;] auto_offset_reset =&gt; &quot;latest&quot; consumer_threads =&gt; 5 decorate_events =&gt; true group_id =&gt; &quot;elk&quot; topics =&gt; [&quot;elk_kafka&quot;] type =&gt; &quot;bhy&quot; &#125;&#125;output &#123; stdout &#123;&#125; elasticsearch &#123; hosts =&gt; [&quot;192.168.33.128:9200&quot;] index =&gt; &quot;kafka-elk-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; 编辑/etc/init.d/logstash，修改 12LS_USER=root //原来默认为logstashLS_GROUP=root //原为默认为logstash 修改完成后退出，重启elk容器 1#docker restart elk 4、配置kibana 配置方式和上一篇docker部署elk日志采集系统（tcp方式）差不多，Index Pattern选择logstash中配置的 “kafka-elk-日期“ 。","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"},{"name":"elk","slug":"elk","permalink":"https://imalan6.github.io/hexo_blog/tags/elk/"}]},{"title":"docker部署elk日志采集系统（tcp方式）","slug":"docker/docker部署elk日志采集系统（tcp方式）","date":"2019-10-15T05:32:25.000Z","updated":"2024-02-14T10:12:30.961Z","comments":false,"path":"2019/10/15/docker/docker部署elk日志采集系统（tcp方式）/","permalink":"https://imalan6.github.io/hexo_blog/2019/10/15/docker/docker%E9%83%A8%E7%BD%B2elk%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E7%B3%BB%E7%BB%9F%EF%BC%88tcp%E6%96%B9%E5%BC%8F%EF%BC%89/","excerpt":"","text":"docker部署elk日志采集系统（tcp方式）elk概念ELK是Elasticsearch、Logstash、Kibana的简称，这三者是核心套件，但并非全部。 Elasticsearch：实时全文搜索和分析引擎，提供搜集、分析、存储数据三大功能。Elasticsearch是一套开放REST和JAVA API等结构提供高效搜索功能，可扩展的分布式系统。它构建于Apache Lucene搜索引擎库之上。 Logstash：用来搜集、分析、过滤日志的工具。它支持几乎任何类型的日志，包括系统日志、错误日志和自定义应用程序日志。它可以从许多来源接收日志，这些来源包括syslog、消息传递（例如RabbitMQ）和JMX，它能够以多种方式输出数据，包括电子邮件、websockets和Elasticsearch。 Kibana：基于Web的可视化图形界面，用于搜索、分析和可视化存储在Elasticsearch指标中的日志数据。它利用Elasticsearch的REST接口来检索数据，不仅允许用户创建他们自己的数据的定制仪表板视图，还允许他们以特殊的方式查询和过滤数据。 docker安装elk1、拉镜像，运行 12#docker pull sebp/elk#docker run -d -it --name elk --restart always -p 5601:5601 -p 9200:9200 -p 5044:5044 -e ES_MIN_MEM=128m -e ES_MAX_MEM=2048m sebp/elk 5601 - Kibana web接口 9200 - Elasticsearch JSON接口 5044 - Logstash日志接收接口 logstash有多种接受数据的方式，这里使用logback直接通过tcp的方式发送日志到logstash，还可以使用redis作为消息队列对日志数据做一个中转。 2、elasticsearch报错解决 elasticsearch启动时可能遇到错误，报elasticsearch用户拥有的内存权限太小，至少需要262144。 解决方法： 1sysctl -w vm.max_map_count=262144 查看结果： 1sysctl -a|grep vm.max_map_count，显示 vm.max_map_count = 262144 上述方法修改之后，如果重启虚拟机将失效。可以在/etc/sysctl.conf文件最后添加一行vm.max_map_count=262144，即可永久修改。 配置elk采集日志（tcp方式）1、配置tcp方式发送日志 在服务的pom.xml中添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;&lt;/dependency&gt; 在logback-spring.xml中添加 appender，发送日志到logstash 123456789101112131415161718192021222324252627282930313233343536&lt;springProperty scope=&quot;context&quot; name=&quot;springAppName&quot; source=&quot;spring.application.name&quot;/&gt; &lt;appender name=&quot;logstash&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt; &lt;destination&gt;192.168.0.6:5044&lt;/destination&gt; &lt;!-- &lt;encoder charset=&quot;UTF-8&quot; class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot; /&gt; --&gt; &lt;!-- 日志输出编码 --&gt; &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt; &lt;providers&gt; &lt;timestamp&gt; &lt;timeZone&gt;UTC&lt;/timeZone&gt; &lt;/timestamp&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; &quot;severity&quot;: &quot;%level&quot;, &quot;service&quot;: &quot;$&#123;springAppName:-&#125;&quot;, &quot;trace&quot;: &quot;%X&#123;X-B3-TraceId:-&#125;&quot;, &quot;span&quot;: &quot;%X&#123;X-B3-SpanId:-&#125;&quot;, &quot;exportable&quot;: &quot;%X&#123;X-Span-Export:-&#125;&quot;, &quot;pid&quot;: &quot;$&#123;PID:-&#125;&quot;, &quot;thread&quot;: &quot;%thread&quot;, &quot;class&quot;: &quot;%logger&#123;40&#125;&quot;, &quot;rest&quot;: &quot;%message&quot; &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;appender-ref ref=&quot;FILE&quot;/&gt; &lt;appende-ref ref=&quot;logstash&quot; /&gt; &lt;/root&gt; 2、配置logstash发送日志到 elasticsearch 由于sebp/elk中logstash的input默认采用filebeat，这里采用tcp方式，所以首先需要进入elk容器中修改input的方式为tcp。logstash默认会使用 etc/logstash/conf.d/中的配置文件。 启动elk，进入容器： 1#docker exec -it elk /bin/bash 进入/etc/logstash/conf.d/配置目录，修改02-beats-input.conf配置文件如下： 123456789101112input &#123; tcp &#123; port =&gt; 5044 codec =&gt; json_lines &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost:9200&quot;] &#125;&#125; 修改完成后退出，重启elk容器 1#docker restart elk 3、配置kibana 启动服务，日志就被发送到logstash中了，访问localhost:5601进入kibana界面。 配置index pattern，点击Management ——&gt; Index Patterns ——&gt; Create index pattern 下面列出了两个可选的index pattern，输入logstash*，下一步。选择时间@timestamp，这样数据展示会以时间排序。 最后，在kabina首页查看采集到的日志","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"},{"name":"elk","slug":"elk","permalink":"https://imalan6.github.io/hexo_blog/tags/elk/"}]},{"title":"docker部署rabbitmq和rabbitmq集群","slug":"docker/docker部署rabbitmq和rabbitmq集群","date":"2019-08-29T14:11:21.000Z","updated":"2024-02-14T10:19:07.202Z","comments":false,"path":"2019/08/29/docker/docker部署rabbitmq和rabbitmq集群/","permalink":"https://imalan6.github.io/hexo_blog/2019/08/29/docker/docker%E9%83%A8%E7%BD%B2rabbitmq%E5%92%8Crabbitmq%E9%9B%86%E7%BE%A4/","excerpt":"","text":"docker部署rabbitmq和rabbitmq集群部署RabbitMQ单机1、查询rabbitmq镜像1#docker search rabbitmq:management 2、拉取rabbitmq镜像1#docker pull rabbitmq:management 3、创建并启动容器 创建和启动 1#docker run -d --hostname my-rabbit --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:management 创建和启动（同时设置用户和密码） 1#docker run -d --hostname my-rabbit --name rabbitmq --restart always -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin -v /etc/localtime:/etc/localtime:ro -v /usr/local/rabbitmq/data:/var/lib/rabbitmq -p 15672:15672 -p 5672:5672 -p 25672:25672 -p 61613:61613 -p 1883:1883 rabbitmq:management 说明： –hostname：指定容器主机名称 –name：指定容器名称 -p：将mq端口号映射到本地，15672为控制台端口号（用于管理rabbitmq），5672为应用访问端口号（应用程序访问）。 4、查看rabbitmq日志，检查运行状况1#docker logs rabbit 部署RabbitMQ集群RabbitMQ集群概念RabbitMQ有三种模式： 单机模式 普通集群模式 镜像集群模式 单机模式单独运行一个rabbitmq实例，而集群模式需要创建多个rabbitmq实例。 普通集群模式概念： 默认的集群模式。需要创建多个RabbitMQ节点。但对于Queue和消息来说，只存在于其中一个节点，其他节点仅同步元数据，即队列的结构信息。 当消息进入Queue后，如果Consumer从创建Queue的这个节点消费消息时，可以直接取出来；但如果consumer连接的是其他节点，那rabbitmq会把queue中的消息从创建它的节点中取出并经过连接节点转发后再发送给consumer。 所以consumer应尽量连接每一个节点。并针对同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连接哪个节点，都会从创建queue的节点获取消息，会产生瓶颈。 特点： 1）Exchange的元数据信息在所有节点上是一致的，而Queue（存放消息的队列）的完整数据则只会存在于创建它的那个节点上。其他节点只知道这个queue的 metadata信息和一个指向queue的owner node的指针； 2）RabbitMQ集群会始终同步四种类型的内部元数据（类似索引）： 队列元数据：队列名称和它的属性 交换器元数据：交换器名称、类型和属性 绑定元数据：一张简单的表格展示了如何将消息路由到队列 vhost元数据：为vhost内的队列、交换器和绑定提供命名空间和安全属性 因此，当用户访问其中任何一个RabbitMQ节点时，通过rabbitmqctl查询到的元数据信息都是相同的。 3）无法实现高可用性，当创建queue的节点故障后，其他节点是无法取到消息实体的。如果做了消息持久化，那么得等创建queue的节点恢复后，才可以被消费。如果没有持久化的话，就会产生消息丢失的现象。 镜像集群模式概念： 把队列做成镜像队列，让各队列存在于多个节点中，属于RabbitMQ的高可用性方案。镜像模式和普通模式的不同在于，queue和message会在集群各节点之间同步，而不是在consumer获取数据时临时拉取。 特点： 1）实现了高可用性。部分节点挂掉后，不会影响rabbitmq的使用 2）降低了系统性能。镜像队列数量过多，大量的消息同步也会加大网络带宽开销 3）适合对可用性要求较高的业务场景 RabbitMQ普通集群部署1、拉镜像1#docker pull rabbitmq:management 2、运行容器12345#docker run -d --hostname rabbit_host1 --name rabbitmq1 -p 15672:15672 -p 5672:5672 -e RABBITMQ_ERLANG_COOKIE=&#x27;rabbitmq_cookie&#x27; rabbitmq:management#docker run -d --hostname rabbit_host2 --name rabbitmq2 -p 5673:5672 --link rabbitmq1:rabbit_host1 -e RABBITMQ_ERLANG_COOKIE=&#x27;rabbitmq_cookie&#x27; rabbitmq:management#docker run -d --hostname rabbit_host3 --name rabbitmq3 -p 5674:5672 --link rabbitmq1:rabbit_host1 --link rabbitmq2:rabbit_host2 -e RABBITMQ_ERLANG_COOKIE=&#x27;rabbitmq_cookie&#x27; rabbitmq:management 主要参数： -p 15672:15672 management界面管理访问端口 -p 5672:5672 amqp访问端口 –link 容器之间连接 Erlang Cookie值必须相同，也就是一个集群内RABBITMQ_ERLANG_COOKIE参数的值必须相同。因为RabbitMQ是用Erlang实现的，Erlang Cookie相当于不同节点之间通讯的密钥，Erlang节点通过交换Erlang Cookie获得认证。 3、加入节点到集群设置节点1： 12345#docker exec -it myrabbit1 bash#rabbitmqctl stop_app#rabbitmqctl reset#rabbitmqctl start_app#exit 设置节点2，加入到集群： 123456#docker exec -it myrabbit2 bash#rabbitmqctl stop_app#rabbitmqctl reset#rabbitmqctl join_cluster --ram rabbit@rabbitmq_host1#rabbitmqctl start_app#exit 设置节点3，加入到集群： 123456#docker exec -it myrabbit3 bash#rabbitmqctl stop_app#rabbitmqctl reset#rabbitmqctl join_cluster --ram rabbit@rabbitmq_host1#rabbitmqctl start_app#exit 主要参数： –ram 表示设置为内存节点，忽略次参数默认为磁盘节点。该配置启动了3个节点，1个磁盘节点和2个内存节点。 设置好之后，使用http://ip:15672进行访问，默认账号密码：`guest/guest` 可以看到，已经有多个节点了。 RabbitMQ镜像集群部署1、策略policy概念使用RabbitMQ镜像功能，需要基于RabbitMQ策略来实现，策略policy是用来控制和修改群集范围的某个vhost队列行为和Exchange行为。策略policy就是要设置哪些Exchange或者queue的数据需要复制、同步，以及如何复制同步。 为了使队列成为镜像队列，需要创建一个策略来匹配队列，设置策略有两个键“ha-mode和ha-params（可选）”。ha-params根据ha-mode设置不同的值，下表说明这些key的选项。 2、添加策略登录rabbitmq管理页面 ——&gt; Admin ——&gt; Policies ——&gt; Add &#x2F; update a policy name：随便取，策略名称 Pattern：^匹配符，只有一个^代表匹配所有 Definition：ha-mode=all为匹配类型，分为3种模式：all（表示所有的queue） 或者使用命令： 1#rabbitmqctl set_policy ha-all &quot;^&quot; &#x27;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&#x27; 3、查看效果此策略会同步所在同一VHost中的交换器和队列数据。设置好policy之后，使用http://ip:15672再次进行访问，可以看到队列镜像同步。 Springboot配置RabbitMQ集群1、配置RabbitMQ单机123456spring: rabbitmq: host: localhost port: 5672 username: username password: password 或者使用addresses 12345spring: rabbitmq: addresses:ip1:port1 username: username password: password 2、配置RabbitMQ集群addresses节点用逗号分隔 12345spring: rabbitmq: addresses:ip1:port1,ip2:port2,ip3:port3 username: username password: password","categories":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://imalan6.github.io/hexo_blog/tags/rabbitmq/"}]},{"title":"mysql和redis的数据一致性问题","slug":"mysql/mysql和redis的数据一致性问题","date":"2019-04-22T14:16:11.000Z","updated":"2024-02-14T11:24:48.120Z","comments":false,"path":"2019/04/22/mysql/mysql和redis的数据一致性问题/","permalink":"https://imalan6.github.io/hexo_blog/2019/04/22/mysql/mysql%E5%92%8Credis%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/","excerpt":"","text":"mysql和redis的数据一致性问题简介在现如今的系统架构中，缓存的地位是非常重要的。当请求并发量比较高时，直接访问数据库是不现实的，可能直接拖垮数据库。所以，必须在数据库之上加一个缓存，方便请求快速读取数据。 不过，由此产生的问题也是很多的，其中一个就是如何保证数据库和缓存之间的数据一致性。 常见缓存方案 在读取缓存的方式中，上图这种方式可以说是最为广泛使用的了。读本身是没有什么问题的，但是，写入缓存的方式，就是保证数据一致性的关键了。 这里不考虑定时刷新缓存的方式，也就是类似下面这种方式： 写入数据库和写入缓存是独立的，写入数据库操作后，需要等待定时服务执行，执行完成后缓存数据才会刷新。这种方式会导致数据的不一致时间较长，数据刷新时，不管有没有改变的数据，都会重新加载，效率差。 更新缓存方案方案一：先更新数据库，再更新缓存这套方案是最简单的一种缓存双写方案，流程如下： 使用这种双写的方案，只要在数据成功写入数据库后，刷新缓存就可以了，代码简单，维护也很简单。但是，简单的前提下，带来的问题也是很直接的。 首先，线程数据安全无法保证 例如：同时有两个请求会操作同一条数据，一个是请求A，一个是请求B。请求A需要先执行，请求B后执行，那么数据库的记录就是请求B执行后的记录。 但是，由于一些网络原因或者其他情况，最终执行的顺序可能就变成了： 请求A Update 数据库 -&gt; 请求B Update 数据库 -&gt; 请求B Update 缓存 -&gt; 请求A Update 缓存。 这样会导致： 数据库和缓存中的数据不一致，从而缓存中的数据就成为了脏数据。 写入操作多于读操作，就会频繁的刷新缓存，但是这些数据根本没有被读过，浪费服务器资源。 方案二：先更新缓存，再更新数据库 同样地，仍然可能出现方案一中的问题，即 请求A更新缓存 -&gt; 请求B更新缓存 -&gt; 请求B更新数据库 -&gt; 请求A更新数据库。 最后，导致数据库和缓存数据不一致。 优化方案给数据库和缓存分别加入version版本号字段，并规定更新操作时，只有version值更大才更新。 1、针对先更新数据库，再更新缓存的方案： 1）更新数据库时，db-version值+1，然后取出db-version值； 2）再更新缓存时，将取出的数据库db-version值和缓存redis-version值作比较； 3）如果db-version值更大则更新缓存，如果redis-version值更小则不更新缓存； 2、针对先更新缓存，再更新数据库的方案: 1）更缓存时，redis-version值+1，然后取出redis-version值； 2）再更新数据库时，将取出的缓存redis-version值和数据库db-version值作比较； 3）如果redis-version值更大则更新数据库，如果db-version值更小则不更新数据库； 问题：针对以上两种优化方案，存在这样的问题，如果更新数据库失败时，如何处理？更新缓存失败时，又如何处理？ 如果更新数据库失败： 对于优化方案1，如果更新数据库失败，不再更新缓存，数据一致；对于优化方案2，如果更新数据库失败，需要回滚缓存，这操作比较麻烦，需要额外处理。 如果更新缓存失败： 对于优化方案1，如果更新缓存失败，数据库回滚，数据一致。对于优化方案2，如果更新缓存失败，不再更新数据库，数据一致。 以上可以看出，优化方案1相比优化方案2更好。但其实都存在一定缺陷，即引入了version字段，增加了业务复杂度。所以，不采用更新缓存，而采用删除缓存的方案会更方便。 删除缓存方案方案三：先删除缓存，再更新数据库先删除缓存，再更新数据库。这样，在更新数据库的前后，由于缓存中没有数据了，请求会穿透缓存到数据库直接读取数据再放入缓存。这样，缓存不会被频繁刷新。一次查询数据库操作也能接受，对性能影响不会太大。 不过，这样也会出现问题。假如有两个请求，一个请求A，一个请求B，请求A执行更新操作，请求B读取数据。当并发量高的时候，就会出现以下情况： 请求A进行写操作，删除缓存 -&gt; 请求B查询缓存没有数据 -&gt; 请求B查询数据库得到旧值 -&gt; 请求B将旧值写入缓存 -&gt; 请求A再将新值写入数据库 这时，数据库和缓存的数据又不一致了。 方案四：先更新数据库，再删除缓存 先更新数据库再删除缓存，可以避免方案三中出现的问题，但是可能导致短暂的数据库和缓存不一致，即更新了数据库，但是缓存中仍然是旧值。因此，最好采用双删策略。 方案五：双删先删除缓存，再更新数据库，最后再删除一次缓存。 方案四和方案五看似可以的，但是如果数据库采用的是主从复制模式，又会产生问题。假如出现这样一种情况：请求A删除了缓存，请求A更新了主数据库，请求A也再次删除了缓存，请求A完成了所有的步骤。但是数据库集群中发生了延时，主从数据库的同步没有完成。而恰巧这时，请求B去查询缓存没有获得数据，然后请求B访问从数据库获得了旧值，请求B将旧值写入缓存，最后，当主从数据库同步完成时，数据库和缓存的数据就不一致了。如下图所示： 针对这种情况，可以考虑第二次删除缓存操作适当延迟一段时间，等主从同步完成后，再删除缓存。这也就有了延时双删策略。 方法六：延时双删 使用延时双删的策略，可以解决主从同步延迟引起的数据不一致的情况。但是又会出现另外两个问题： 1、第二次删除缓存的时间该延迟多久呢？如果延迟时间短了，可能主从同步仍然没有完成，如果延迟时间长了，必然会影响任务的执行； 2、如果第二次删除缓存失败了，那又可能出现数据不一致的情况； 方案七：延时双删 + 队列 针对可能出现第二次删除缓存失败的情况，可以把第二次删除缓存的消息加入到队列中，如果队列执行失败，就再次回到队列执行，直到成功为止。 这样，既可以保证第二次删除缓存操作执行成功，同时也实现异步执行删除缓存的操作，防止请求等待延迟而阻塞。当然，可以使用延迟队列，让消息在指定时间（比如2秒）后被消费。 方案八：双删 + 订阅从库Binlog + 队列针对延时双删的另外一个问题，假如延迟一段时间后，主从同步还是没有完成，那么仍然可能出现数据不一致的情况。这时，可以采用订阅从库Binlog的方式来处理。当从库完成同步后，Binlog发生变化，这时候再考虑删除缓存就很安全了。方案如下图： 当然，订阅从库的Binlog方式处理起来比较重，可以根据实际的应用场景采用不同的方案。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"mysql","slug":"mysql","permalink":"https://imalan6.github.io/hexo_blog/tags/mysql/"}]},{"title":"基于Redis的分布式限流","slug":"distributed_component/基于Redis的分布式限流","date":"2019-03-11T15:35:09.000Z","updated":"2024-02-14T10:08:01.876Z","comments":false,"path":"2019/03/11/distributed_component/基于Redis的分布式限流/","permalink":"https://imalan6.github.io/hexo_blog/2019/03/11/distributed_component/%E5%9F%BA%E4%BA%8ERedis%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/","excerpt":"","text":"基于Redis的分布式限流简介在开发服务接口时，为了保护服务器的资源，防止客户端对接口的滥用， 通常来说会限制服务接口的调用次数。比如限制用户在一段时间内，比如1分钟，调用服务接口的次数不能大于某个值，比如说100次。如果用户调用接口的次数超过上限的话，就直接拒绝用户请求，返回错误信息。 服务接口的流量控制策略包括：分流、降级、限流等。限流策略，虽然降低了服务接口的访问频率和并发量，却换回了服务接口和业务应用系统的高可用。 常用限流算法漏桶算法漏桶(Leaky Bucket)算法思路很简单，水(请求)先进入到漏桶里，漏桶以一定的速度出水(接口有响应速率)。当水流入速度过大会直接溢出(访问频率超过接口响应速率)，然后拒绝请求，可以看出漏桶算法能强行限制数据的传输速率。如下图所示： 包括两个变量： 桶的大小，支持流量突发增多时可以存多少的水(burst) 水桶漏洞的大小(rate) 因为漏桶的漏出速率是固定的参数，所以，即使网络中不存在资源冲突(没有发生拥塞)，漏桶算法也不能使流突发(burst)到端口速率。因此，漏桶算法不适合存在突发流量特性的应用场景。 令牌桶算法令牌桶算法(Token Bucket)是和漏桶算法效果一样，但方向相反的算法。令牌桶算法：随着时间流逝，系统会按恒定1&#x2F;QPS时间间隔(比如QPS&#x3D;100，则间隔为10ms)往桶里加入Token(想象和漏洞漏水相反，有个水龙头不断地往里面加水)。如果桶满了就不再添加了。新请求来临时，会各自拿走一个Token，如果没有Token可拿就阻塞或拒绝服务。 令牌桶的好处是可以方便的改变速度，一旦需要提高速率，则按需提高放入桶中的令牌的速率。一般会定时(比如100毫秒)往桶中增加一定数量的令牌，有些变种算法则实时计算应该增加的令牌的数量。 分布式限流组件一般限流方案只能针对于单个JVM有效，也就是单机方案。而对于分布式应用需要一个分布式限流的方案。针对分布式限流，写了这个组件： https://gitee.com/shuimenjian/ala-distributed-ratelimit 主要原理 假设一个用户（用IP判断）每秒访问某服务接口的次数不能超过10次，那么可以在Redis中创建一个键，并设置键的过期时间为60秒。当一个用户对此服务接口发起一次访问就把值加1，在单位时间（此处为1s）内当键值增加到10的时候，就禁止访问服务接口。 核心代码Lua脚本脚本作用 减少网络开销: 不使用Lua的代码需要向Redis发送多次请求, 而脚本只需一次即可, 减少网络传输 原子操作: Redis将整个脚本作为一个原子执行, 无需担心并发, 也就无需事务 复用: 脚本会永久保存Redis中, 其他客户端可继续使用 Redis添加了对Lua的支持，能够很好的满足原子性、事务性的支持，免去了很多的异常逻辑处理 脚本内容 是整个限流操作的核心，通过执行Lua脚本进行限流的操作。脚本内容如下： 123456789101112131415161718192021222324252627--获取KEYlocal key1 = KEYS[1]local val = redis.call(&#x27;incr&#x27;, key1)local ttl = redis.call(&#x27;ttl&#x27;, key1)--获取ARGV内的参数并打印local expire = ARGV[1]local times = ARGV[2]redis.log(redis.LOG_DEBUG,tostring(times))redis.log(redis.LOG_DEBUG,tostring(expire))redis.log(redis.LOG_NOTICE, &quot;incr &quot;..key1..&quot; &quot;..val);if val == 1 then redis.call(&#x27;expire&#x27;, key1, tonumber(expire))else if ttl == -1 then redis.call(&#x27;expire&#x27;, key1, tonumber(expire)) endendif val &gt; tonumber(times) then return 0endreturn 1 首先脚本获取Java代码中传递而来的要限流的模块的key，不同的模块key值一定不能相同，否则会覆盖 redis.call(&#39;incr&#39;, key1)对传入的key做incr操作，如果key首次生成，设置超时时间ARGV[1]（初始值为1） ttl是为防止某些key在未设置超时时间并长时间已经存在的情况下做的保护的判断 每次请求都会做+1操作，当限流的值大于注解的阈值，则返回0，表示已经超过请求限制，触发限流，否则为正常请求 脚本调用 调用并执行Lua脚本代码： 123456789getRedisScript = new DefaultRedisScript&lt;&gt;();getRedisScript.setResultType(Long.class);getRedisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(&quot;alaRateLimit.lua&quot;))); // 调用Lua脚本Long result = (Long) redisTemplate.execute(getRedisScript, keyList, expireTime, limitTimes);if (result == 0) &#123; //表示需要限流&#125; 自定义注解定义一个方法注解@AlaRateLimit： 123456789101112131415161718192021222324252627282930313233343536@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface AlaRateLimit &#123; /** * 限流key，区分不同的方法 * @return */ String key() default &quot;&quot;; /** * 限流次数 * @return */ long limit() default 100; /** * 限流间隔时间 * @return */ long interval() default 60; /** * 限流返回，消息形式 * @return */ String message() default &quot;rate limit error&quot;; /** * 限流返回，对象形式，优先级高于message * @return */ Class&lt;?&gt; fallback() default void.class;&#125; 使用AOP处理注解，核心代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@Aspect@Componentpublic class RateLimitHandler &#123; @Pointcut(&quot;@annotation(com.alan6.distributed.ratelimit.annotation.AlaRateLimit)&quot;) public void rateLimit() &#123; &#125; @Around(&quot;@annotation(rateLimit)&quot;) public Object around(ProceedingJoinPoint proceedingJoinPoint, AlaRateLimit rateLimit) throws Throwable &#123; Signature signature = proceedingJoinPoint.getSignature(); if (!(signature instanceof MethodSignature)) &#123; throw new IllegalArgumentException(&quot;the Annotation @AlaRateLimit must be used on method&quot;); &#125; // 限流模块key String limitKey = rateLimit.key(); if (StringUtils.isBlank(limitKey)) &#123; // 如果没有设置key，key的默认值=方法包名+方法名 limitKey = proceedingJoinPoint.getSignature().getDeclaringType().getPackage().getName() + &quot;.&quot; + proceedingJoinPoint.getSignature().getName(); &#125; // 限流阈值 long limitTimes = rateLimit.limit(); // 限流超时时间 long expireTime = rateLimit.interval(); // 限流提示语 String message = rateLimit.message(); // 获取降级对象 Object fallback = rateLimit.fallback().newInstance(); List&lt;String&gt; keyList = new ArrayList(); // 设置key值为注解中的值 keyList.add(limitKey); // 调用Lua脚本 Long result = (Long) redisTemplate.execute(getRedisScript, keyList, expireTime, limitTimes); if (result == 0) &#123; // 指定了降级 if (fallback != null) &#123; // 检查降级方法是否实现AlaRateLimitFallback接口 Assert.isTrue( !rateLimit.fallback().getSuperclass().isInterface(), &quot;Rate limit fallback class must implement the interface AlaRateLimitFallback&quot; ); // 反射调用降级方法 Method m = fallback.getClass().getMethod(&quot;fallbackResult&quot;, null); // 反射执行方法 return m.invoke(fallback, null); &#125;else &#123; return message; &#125; &#125; return proceedingJoinPoint.proceed(); &#125;&#125; 主要逻辑就是：解析注解，获取注解参数，调用Lua脚本对key进行incr操作，如果interval时间内，数量达到限制阈值，则调用降级方法处理或返回error消息。 降级方法定义一个降级接口： 123public interface AlaRateLimitFallback &#123; public Object fallbackResult();&#125; 降级方法需要实现降级接口，实现fallbackResult()方法，给出一个demo： 123456public class RatelimitFallback implements AlaRateLimitFallback &#123; @Override public Object fallbackResult() &#123; return new BaseResult(888, &quot;rate limit error&quot;); &#125;&#125; 使用方法注解说明在需要限流的方法上添加@AlaRateLimit注解，注解参数含义如下： key：限流key，用于区分需要限流的不同方法。没有指定的话，默认为注解所在包名 + ‘.’ + 方法名 limit：限流次数，默认100次 interval：限流间隔时间，默认60s message：限流后返回字符串形式的error消息，默认”rate limit error“ fallback： 限流后返回对象形式，优先级高于message，需要实现AlaRateLimitFallback接口 使用示例1、实现降级处理接口 123456public class RatelimitFallback implements AlaRateLimitFallback &#123; @Override public Object fallbackResult() &#123; return new BaseResult(888, &quot;rate limit error&quot;); &#125;&#125; 2、在方法上添加注解 12345678910@RestController@RequestMapping(&quot;/test&quot;)public class TestController &#123; @AlaRateLimit(limit = 10, interval = 10, fallback = RatelimitFallback.class) @GetMapping(&quot;/limit&quot;) public Object testRateLimit()&#123; return &quot;ok&quot;; &#125;&#125; 测试在10s秒内，连续请求/test/limit接口，当次数小于等于10次时，接口正常返回String消息“ok” 在10s秒内，连续请求&#x2F;test&#x2F;limit接口，当次数大于10次时，调用次数超过限制，触发降级处理，接口返回json消息”&#123;&quot;code&quot;:888,&quot;message&quot;:&quot;rate limit error&quot;&#125;“","categories":[{"name":"分布式","slug":"分布式","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"分布式限流","slug":"分布式限流","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/"}]},{"title":"基于Redis的分布式锁","slug":"distributed_component/基于Redis的分布式锁","date":"2019-02-22T13:18:11.000Z","updated":"2024-02-14T10:08:01.850Z","comments":false,"path":"2019/02/22/distributed_component/基于Redis的分布式锁/","permalink":"https://imalan6.github.io/hexo_blog/2019/02/22/distributed_component/%E5%9F%BA%E4%BA%8ERedis%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"基于Redis的分布式锁简介分布式锁，或者称为“全局锁”，在分布式环境中，保证锁只能被一个对象获取，经常出现在“避免数据重复处理”、“接口幂等”等应用场景。 分布式锁一般有三种实现方式： 基于数据库的分布式锁 基于Redis的分布式锁 基于ZooKeeper的分布式锁 本篇主要研究基于Redis实现分布式锁。虽然网上已经有各种介绍Redis分布式锁实现的博客，然而却有着各种各样的问题，这里做个研究探讨。 可靠性首先，为了确保分布式锁可用，至少要确保锁的实现同时满足以下四个条件： 互斥性。在任意时刻，只有一个客户端能持有锁。 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。 高性能。由于分布式系统，难免出现高并发环境，因此分布式锁不能成为性能瓶颈。 Jedis实现添加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; 加锁操作正确示例123456789101112131415161718192021222324public class RedisTool &#123; private static final String LOCK_SUCCESS = &quot;OK&quot;; private static final String SET_IF_NOT_EXIST = &quot;NX&quot;; private static final String SET_WITH_EXPIRE_TIME = &quot;PX&quot;; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125; 可以看到，加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有5个参数： key，使用key作为锁标识，因为key是唯一的。 value，传入请求的唯一标识，比如requestId，线程id等，用于区分不同的请求。但有key作为锁就够了，为什么还要用到value？因为在删除锁时，可以通过value作为判断加锁和删锁是否为同一请求，避免错误删除。 nx，参数传入NX，意思是SET IF NOT EXIST，即当key不存在时，进行set操作；若key已经存在，不做任何操作； px，参数传入PX，给key设置一个过期的时间，具体时间由第5个参数决定。 time，key的过期时间。 以上的set()方法就只会导致两种结果：1. 当前没有锁（key不存在），那么就进行加锁操作，并给锁设置个有效时间，同时value保存请求的唯一标识。2. 已有锁存在，不做任何操作。 错误示例1常见的错误操作是使用jedis.setnx()和jedis.expire()组合实现加锁，代码如下： 12345678public static void getLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; Long result = jedis.setnx(lockKey, requestId); if (result == 1) &#123; // 若在这里程序突然崩溃，则无法设置过期时间，锁将永远存在，导致死锁 jedis.expire(lockKey, expireTime); &#125;&#125; 由于setnx和expire是两条Redis命令，不具有原子性，如果线程在执行完setnx()之后突然崩溃，导致锁没有设置过期时间，那么将会发生死锁。以前这样实现，是因为低版本的jedis不支持多参数的set()方法。 错误示例212345678910111213141516171819202122232425public static boolean getLock(Jedis jedis, String lockKey, int expireTime) &#123; long expires = System.currentTimeMillis() + expireTime; String expiresStr = String.valueOf(expires); // 如果当前锁不存在，返回加锁成功 if (jedis.setnx(lockKey, expiresStr) == 1) &#123; return true; &#125; // 如果锁存在，获取锁的过期时间 String currentValueStr = jedis.get(lockKey); if (currentValueStr != null &amp;&amp; Long.parseLong(currentValueStr) &lt; System.currentTimeMillis()) &#123; // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间 String oldValueStr = jedis.getSet(lockKey, expiresStr); if (oldValueStr != null &amp;&amp; oldValueStr.equals(currentValueStr)) &#123; // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才有权利加锁 return true; &#125; &#125; // 其他情况，一律返回加锁失败 return false;&#125; 这一种错误示例比较难以发现问题，实现也比较复杂。实现思路：使用jedis.setnx()命令实现加锁，其中key是锁，value是锁的过期时间。执行过程： 通过setnx()方法尝试加锁，如果锁不存在，返回加锁成功 如果锁已经存在，则获取锁的过期时间和当前时间比较，如果锁已经过期，则设置新的过期时间，返回加锁成功。 这段代码的问题： 由于是客户端自己生成过期时间，所以需要强制要求分布式下每个客户端的时间必须同步。 当锁过期的时候，如果多个客户端同时执行jedis.getSet()方法，那么虽然最终只有一个客户端可以加锁，但是这个客户端的锁的过期时间可能被其他客户端覆盖。 锁不具有处理线程的标识，任何客户端都可以解锁。 解锁操作正确示例12345678910111213141516171819202122public class RedisTool &#123; private static final Long RELEASE_SUCCESS = 1L; /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; String script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125; 解锁只需要两行代码就搞定了，首先写了一个简单的Lua脚本代码，并将Lua代码传到jedis.eval()方法里，使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行。 Lua代码的功能：首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。 之所以使用Lua脚本，是因为：在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。这就保证了解锁操作是原子性的，不会出现线程安全问题。 错误示例1最常见的解锁代码就是直接使用jedis.del()方法删除锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。 123public static void getLock(Jedis jedis, String lockKey) &#123; jedis.del(lockKey);&#125; 错误示例2这种解锁代码把解锁操作分成两条命令执行： 1234567public static void getLock(Jedis jedis, String lockKey, String requestId) &#123; // 判断加锁与解锁是不是同一个客户端 if (requestId.equals(jedis.get(lockKey))) &#123; // 若在此时，这把锁突然不是这个客户端的，则会误解锁 jedis.del(lockKey); &#125;&#125; 问题在于如果调用jedis.del()方法的时候，这把锁已经不属于当前客户端了，那执行后会解除他人加的锁。比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前，锁过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。 问题1.锁超时释放锁，如果超时时间设置太长，可能导致大量请求阻塞，降低系统效率；如果超时时间设置太短，获得锁的线程可能因为某些原因卡住（GC）还没有执行完任务，锁就自动释放了，导致其他线程获得锁成功，从而出现数据不一致的情况。这种情况可以考虑增加一个后台线程时刻检查锁是否超时，如果还没有，则增加超时时间。redission的分布式锁就是采用这种方式，通过增加看门狗添加超时时间。 2.针对redis集群环境，如果针对某个redis master，客户端1写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例。但是这个过程中一旦发生redis master宕机，主备切换，redis slave变为了redis master。接着就会导致，客户端2来尝试加锁的时候，在新的redis master上完成了加锁，而客户端1也以为自己成功加了锁。此时就会导致多个客户端对一个分布式锁完成了加锁，从而出现问题。这个可以使用redission的redlock解决。 Redission普通分布式锁Redission简介Redisson是架设在Redis基础上的一个Java驻内存数据网格框架，充分利用Redis键值数据库提供的一系列优势，基于Java使用工具包中常用接口，为使用者提供了一系列具有分布式特性的常用工具类。 Redisson使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度。同时结合各富特色的分布式服务, 更进一步简化了分布式环境中程序相互之间的协作。 Redission分布式锁原理 加锁机制如果某个客户端要加锁，面对的是一个redis cluster集群，首先会根据hash节点选择一台机器去获取锁，获取成功后执行lua脚本，保存数据到redis。 如果获取失败则一直通过while循环尝试获取锁，获取成功后，执行lua脚本，保存数据到redis。 watch dog自动延期机制如果负责储存这个分布式锁的Redisson节点宕机，但锁正好处于锁住状态时，就出现锁死的状态。为了避免这种情况发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 另外，Redisson还通过加锁的方法提供了leaseTime的参数来指定加锁的时间。超过这个时间后锁便自动解开了。 可重入锁机制Redisson可以实现可重入锁，主要原理：用key保存线程信息（比如线程id），value保存加锁次数。当执行加锁操作时，通过key判定是不是同一个线程，如果是加锁成功，并且value加1，释放锁时，value减1。 Redission分布式锁使用Redis几种架构Redis几种常见的部署架构包括： 单机模式 主从模式 哨兵模式 集群模式 单机模式代码如下： 1234567891011121314151617181920// 构造redisson实现分布式锁的ConfigConfig config = new Config();config.useSingleServer().setAddress(&quot;redis://192.168.0.6:6379&quot;).setPassword(&quot;123456&quot;).setDatabase(0);// 构造RedissonClientRedissonClient redissonClient = Redisson.create(config);// 设置锁名称RLock disLock = redissonClient.getLock(&quot;mylock&quot;);boolean isLock;try &#123; // 尝试获取分布式锁 isLock = disLock.tryLock(500, 15000, TimeUnit.MILLISECONDS); if (isLock) &#123; //TODO if get lock success, do something; Thread.sleep(15000); &#125;&#125; catch (Exception e) &#123;&#125; finally &#123; // 解锁 disLock.unlock();&#125; 哨兵模式即sentinel模式，代码如下： 12345Config config = new Config();config.useSentinelServers().addSentinelAddress( &quot;redis://192.168.0.5:6379&quot;, &quot;redis://192.168.0.6:6379&quot;, &quot;redis://192.168.0.7:6379&quot;) .setMasterName(&quot;mymaster&quot;) .setPassword(&quot;123456&quot;).setDatabase(0); 集群模式代码如下： 12345Config config = new Config();config.useClusterServers().addNodeAddress( &quot;redis://192.168.0.5:6379&quot;, &quot;redis://192.168.0.6:6379&quot;, &quot;redis://192.168.0.7:6379&quot;, &quot;redis://192.168.0.8:6379&quot;, &quot;redis://192.168.0.9:6379&quot;, &quot;redis://192.168.0.10:6379&quot;) .setPassword(&quot;123456&quot;).setScanInterval(5000); 无论那种架构，普通分布式锁的实现原理就是Redis通过EVAL命令执行LUA脚本。 Redlock分布式锁以上Redission分布式锁的问题： 假如客户端1对某个master节点写入了redisson锁，此时会异步复制给对应的slave节点。但是这个过程中，master节点一旦宕机，主备切换，slave节点从变为了 master节点。这时客户端2来尝试加锁的时候，在新的master节点上也能加锁成功，此时就会导致多个客户端对同一个分布式锁完成了加锁。所以，这个是redis cluster，或者是redis master-slave架构的主从异步复制导致的Redis分布式锁的最大缺陷。 由于存在以上问题，Redis作者antirez基于分布式环境下提出了一种更高级的分布式锁的实现方式：Redlock。 Redlock原理antirez提出的redlock算法大概是这样的： 在Redis的分布式环境中，假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。然后，在N个实例上使用与在单实例下使用相同的方法获取和释放锁。假如有5个Redis master组成的cluster，为了取到锁，客户端操作的大致流程如下： 获取当前时间。 按顺序依次向5个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同。当向Redis请求获取锁时，客户端应设置一个网络超时时间，这个超时时间（毫秒级）应该远小于锁的失效时间（秒级）。如果服务器端没有在规定时间内响应，客户端应尽快尝试去另外一个Redis实例请求获取锁。 客户端使用当前时间减去开始获取锁的时间（步骤1记录的时间）得到锁使用的时间。当且仅当从大多数（N&#x2F;2+1，这里是3个节点）的Redis节点都获取到锁，并且使用的时间小于锁的失效时间时，才算加锁成功。 客户端获取锁成功后，锁的有效时间等于最初设置的有效时间减去获取锁消耗的时间。 如果客户端获取锁失败（没有在至少N&#x2F;2+1个Redis实例获取到锁，或者获取锁的时间超过了有效时间），那么客户端应立即向所有Redis节点发起释放锁的操作（即前面介绍的单机Redis Lua脚本释放锁的方法），防止某些节点获取到锁导致其他客户端不能获取锁。 Redlock加锁代码redlock的核心变化是使用了RedissonRedLock类。这个类是RedissonMultiLock的子类，调用了tryLock方法，即调用了RedissonMultiLock的tryLock方法，代码如下： 1234567891011121314151617181920212223242526272829303132public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException &#123; // 实现要点之允许加锁失败节点限制 int failedLocksLimit = failedLocksLimit(); List&lt;RLock&gt; acquiredLocks = new ArrayList&lt;RLock&gt;(locks.size()); // 实现要点之遍历所有节点通过EVAL命令执行lua加锁 for (ListIterator&lt;RLock&gt; iterator = locks.listIterator(); iterator.hasNext();) &#123; RLock lock = iterator.next(); boolean lockAcquired; try &#123; // 对节点尝试加锁 lockAcquired = lock.tryLock(awaitTime, newLeaseTime, TimeUnit.MILLISECONDS); &#125; catch (RedisConnectionClosedException|RedisResponseTimeoutException e) &#123; // 如果抛出这类异常，为了防止加锁成功，但是响应失败，需要解锁 unlockInner(Arrays.asList(lock)); lockAcquired = false; &#125; catch (Exception e) &#123; // 抛出异常表示获取锁失败 lockAcquired = false; &#125; if (lockAcquired) &#123; // 成功获取锁集合 acquiredLocks.add(lock); &#125; else &#123; // 如果达到了允许加锁失败节点限制，那么break，即此次Redlock加锁失败 if (locks.size() - acquiredLocks.size() == failedLocksLimit()) &#123; break; &#125; &#125; &#125; return true;&#125; 这段源码就是Redlock算法的实现。以sentinel模式架构为例，有sentinel-1，sentinel-2，sentinel-3总计3个sentinel模式集群，如果要获取分布式锁，那么需要向这3个sentinel集群通过EVAL命令执行LUA脚本，需要3&#x2F;2+1&#x3D;2，即至少2个sentinel集群响应成功，才算成功的以Redlock算法获取到分布式锁。 Redlock使用代码如下： 1234567891011121314151617181920Config config = new Config();config.useSentinelServers().addSentinelAddress(&quot;192.168.0.5:6379&quot;,&quot;192.168.0.6:6379&quot;, &quot;192.168.0.7:6379&quot;) .setMasterName(&quot;masterName&quot;) .setPassword(&quot;password&quot;).setDatabase(0);RedissonClient redissonClient = Redisson.create(config);// 还可以getFairLock(), getReadWriteLock()RLock redLock = redissonClient.getLock(&quot;REDLOCK_KEY&quot;);boolean isLock;try &#123; isLock = redLock.tryLock(); // 500ms拿不到锁, 就认为获取锁失败。10000ms即10s是锁失效时间。 isLock = redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS); if (isLock) &#123; //TODO if get lock success, do something; &#125;&#125; catch (Exception e) &#123;&#125; finally &#123; // 解锁 redLock.unlock();&#125; RedLock问题讨论 有redis节点发生崩溃后重启 假设一共有5个Redis节点：A, B, C, D, E。出现如下事件： 1、客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。 2、节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。 3、节点C重启后，客户端2锁住了C, D, E，获取锁成功。 4、客户端1和客户端2同时获得了锁。 为了应对这一问题，antirez又提出了延迟重启(delayed restarts)的概念。也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。 客户端长期阻塞导致锁过期 如上图，客户端1在获得锁之后发生了很长时间的GC pause，在此期间，它获得的锁过期了，而客户端2获得了锁。当客户端1从GC pause中恢复过来时，它不知道自己持有的锁已经过期了，它依然向共享资源（上图中是一个存储服务）发起了写数据请求，而这时锁实际上是被客户端2持有的，因此两个客户端的写请求就有可能冲突。 为了解决这个问题，引入了fencing token的概念： 如上图，客户端1先获取到的锁，生成一个较小的fencing token，值为33，而客户端2后获取到锁，有一个较大的fencing token，值为34。客户端1从GC pause中恢复过来之后，依然是向存储服务发送访问请求，但是带了fencing token = 33。存储服务发现它之前已经处理过34的请求，所以会拒绝掉这次值为33的请求。这样就避免了冲突。 但这已经超出了Redis实现分布式锁的范围，单纯用Redis没有命令来实现生成Token。 时钟跳跃问题 假设有5个Redis节点A, B, C, D, E。出现如下事件序列： 1、客户端1从Redis节点A, B, C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。 2、节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。 3、客户端2从Redis节点C, D, E成功获取了同一个资源的锁（多数节点）。 4、客户端1和客户端2现在都认为自己持有了锁。 这个问题用Redis实现分布式锁暂时无解，而生产环境这种情况是存在的。 总结 失效时间如何设置 这个问题的场景是，假设设置失效时间10秒，如果由于某些原因导致10秒还没执行完任务，这时候锁自动失效，导致其他线程也会拿到分布式锁。 这确实是Redis分布式最大的问题，不管是普通分布式锁，还是Redlock算法分布式锁，都没有解决这个问题。也有一些文章提出了对失效时间续租，即延长失效时间，这又提升了分布式锁的复杂度。 zookeeper&#x2F;redis选择 没有绝对的好与坏，只有更适合业务的选择。就性能而言，redis明显优于zookeeper；就分布式锁实现的健壮性而言，zookeeper很明显优于redis。如何选择，取决于业务。 Redis并不能实现严格意义上的分布式锁。但是这并不意味着上面的方案一无是处。需要结合具体的应用场景考虑，如果对数据一致性要求不高，只是为了提高效率，协调各个客户端避免做重复的工作，即使锁失效了，也不会产生严重后果。但是如果应用场景需要很强的数据正确性，那么用Redis实现分布式锁并不合适，可能各种各样的问题，且解决起来就很复杂，为了正确性，需要使用zab、raft共识算法，或者使用带有事务的数据库来实现严格意义上的分布式锁。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"分布式锁","slug":"分布式锁","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}]},{"title":"分布式缓存设计","slug":"distributed_component/分布式缓存设计","date":"2019-02-16T14:16:22.000Z","updated":"2024-02-14T10:08:01.833Z","comments":false,"path":"2019/02/16/distributed_component/分布式缓存设计/","permalink":"https://imalan6.github.io/hexo_blog/2019/02/16/distributed_component/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"分布式缓存设计目前常见的缓存方案都是分层缓存，通常可以分为以下几层： NG本地缓存，命中的话直接返回。 NG没有命中时则需要查询分布式缓存，如Redis 。 如果分布式缓存没有命中则需要回源到Tomcat在本地堆进行查询，命中之后异步写回Redis 。 以上都没有命中那就只有从DB或者是数据源进行查询，并写回到Redis中。 缓存更新的原子性在写回Redis的时候如果是Tomcat集群，多个进程同时写那很有可能出现脏数据，这时就会出现更新原子性的问题。 可以有以下解决方案: 可以将多个Tomcat中的数据写入到MQ队列中，由消费者进行单线程更新缓存。 利用分布式锁，只有获取到锁进程才能写数据。 如何写缓存写缓存时也要注意，通常来说分为以下几步： 开启事务。 写入DB。 提交事务。 写入缓存。 这里可能会存在数据库写入成功但是缓存写入失败的情况，但是也不建议将写入缓存加入到事务中。 因为写缓存的时候可能会因为网络原因耗时较长，这样会阻塞数据库事务。 如果对一致性要求不高并且数据量也不大的情况下，可以单独起一个服务来做DB和缓存之间的数据同步操作。 更新缓存时也建议做增量更新。 负载策略缓存负载策略一般有以下两种： 轮询机制。 一致哈希算法。 轮询的优点是负载到各个服务器的请求是均匀的，但是如果进行扩容则缓存命中率会下降。 一致哈希的优点是相同的请求会负载到同一台服务器上，命中率不会随着扩容而降低，但是当大流量过来时有可能把服务器拖垮。 所以建议两种方案都采用： 首先采用一致哈希算法，当流量达到一定的阈值的时候则切换为轮询，这样既能保证缓存命中率，也能提高系统的可用性。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BC%93%E5%AD%98/"},{"name":"分布式缓存","slug":"分布式缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"}]},{"title":"分布式 ID 生成器","slug":"distributed_component/分布式ID生成器","date":"2019-02-12T15:12:22.000Z","updated":"2024-02-14T10:08:01.808Z","comments":false,"path":"2019/02/12/distributed_component/分布式ID生成器/","permalink":"https://imalan6.github.io/hexo_blog/2019/02/12/distributed_component/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%94%9F%E6%88%90%E5%99%A8/","excerpt":"","text":"分布式 ID 生成器一个唯一ID在一个分布式系统中是非常重要的一个业务属性，其中包括一些如订单ID，消息ID ，会话ID，他们都有一些共有的特性： 全局唯一 趋势递增 全局唯一很好理解，目的就是唯一标识某个次请求，某个业务。 通常有以下几种方案： 基于数据库可以利用MySQL中的自增属性auto_increment来生成全局唯一 ID，也能保证趋势递增。 但这种方式太依赖DB，如果数据库挂了那就非常容易出问题。 水平扩展改进但也有改进空间，可以将数据库水平拆分，如果拆为了两个库 A 库和 B 库。 A 库的递增方式可以是 0, 2, 4, 6。B 库则是 1, 3, 5, 7。这样的方式可以提高系统可用性，并且 ID 也是趋势递增的。 但也有如下一下问题： 想要扩容增加性能变的困难，之前已经定义好了 A B 库递增的步数，新加的数据库不好加入进来，水平扩展困难。 也是强依赖与数据库，并且如果其中一台挂掉了那就不是绝对递增了。 本地UUID生成还可以采用UUID的方式生成唯一 ID，由于是在本地生成没有了网络之类的消耗，所有效率非常高。 但也有以下几个问题： 生成的 ID 是无序性的，不能做到趋势递增。 由于是字符串并且不是递增，所以不太适合用作主键。 采用本地时间这种做法非常简单，可以利用本地的毫秒数加上一些业务 ID 来生成唯一ID，这样可以做到趋势递增，并且是在本地生成效率也很高。 但有一个致命的缺点:当并发量足够高的时候唯一性就不能保证了。 Twitter雪花算法可以基于Twitter的Snowflake算法来实现。它主要是一种划分命名空间的算法，将生成的 ID 按照机器、时间等来进行标志。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式id","slug":"分布式id","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%88%86%E5%B8%83%E5%BC%8Fid/"}]},{"title":"缓存雪崩、穿透、击穿解决方案","slug":"cache/缓存雪崩穿透击穿解决方案","date":"2018-12-16T14:32:13.000Z","updated":"2024-02-14T10:02:31.800Z","comments":false,"path":"2018/12/16/cache/缓存雪崩穿透击穿解决方案/","permalink":"https://imalan6.github.io/hexo_blog/2018/12/16/cache/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E7%A9%BF%E9%80%8F%E5%87%BB%E7%A9%BF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","excerpt":"","text":"缓存雪崩、穿透、击穿解决方案缓存雪崩 问题描述 如果缓存在某一个时刻出现大规模失效(比如，设置缓存时采用了相同的过期时间，在同一时刻出现大面积缓存过期)，就会导致大量请求直接到了数据库，使得数据库压力巨大。如果并发量很高，可能会导致数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。这种情况就是缓存雪崩。 问题分析 造成缓存雪崩的关键原因在于同一时刻大规模的缓存失效，导致请求直接到了数据库。出现这种情况主要有如下原因： 1）Redis宕机，无法提供缓存查询服务。 2）缓存采用了相同的过期时间。 3）用户请求量过大。 针对以上情况，考虑如下解决方案。 解决方案 1）针对Redis宕机问题，可以搭建Redis集群环境，保证Redis缓存的高可用，防止宕机导致缓存雪崩问题。 2）针对缓存采用相同过期时间，可以如下解决： ​ ① 均匀过期。设置不同的随机过期时间，让缓存失效时间尽量均匀分布，避免相同的过期时间导致缓存雪崩，造成大量数据库访问。 ​ ② 永不过期。热点数据缓存设置为永不过期，避免了大量的数据库请求。 ​ ③ 缓存标记。给缓存加一个过期时间更快的标记，读缓存时先取标记，存在则取缓存，不存在则更新缓存。也可以把过期时间存放在Value里，读缓存时验证时间，发现快要过期时，更新缓存。 ​ ④ 分级缓存。如果第一级缓存失效，访问二级缓存，每一级缓存的失效时间设置不同。 3）针对请求量过大，可以如下解决： ​ ① 互斥访问。在缓存失效后，通过互斥锁或者队列控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。 ​ ② 熔断，限流，降级。当请求量达到一定阈值时，直接降级处理，返回“系统暂时不可用”之类的提示，防止过多请求直接访问数据库。这样至少能保证一部分用户正常访问，其他用户多刷新几次也能访问。 代码实现 1）设置均匀过期时间，伪代码如下： 1234567891011121314151617181920212223public String getRedisData(String key)&#123; ValueOperations&lt;String, String&gt; ops = redisTemplate.opsForValue(); //从缓存中读取数据 String value = ops.get(key); if(StringUtils.isEmpty(value))&#123; //模拟从数据库中读取数据 String dbData = queryFromDB(); if(StringUtils.isEmpty(dbData))&#123; //库中没有此数据，存入一个空值,过期时间为5分钟，用来解决缓存穿透问题 ops.set(key, &quot;&quot;, 5, TimeUnit.MINUTES); return null; &#125;else&#123; //将数据写入缓存，并设置一个随机的过期时间，解决缓存雪崩问题 //生成500 ~ 1500之间的一个随机数，设置缓存过期时间随机分布在500 ~ 1500分钟内 Random random = new Random(); int randomNum = random.nextInt(1500 - 500 + 1) + 500; ops.set(key, dbData, randomNum, TimeUnit.MINUTES); return dbData; &#125; &#125; //缓存中有数据，直接返回 return value;&#125; 2）并发量不高的情况下，加锁互斥访问数据库。伪代码如下： 12345678910111213141516171819202122232425262728293031323334public String getRedisData(String key) &#123; // 从缓存中读取数据 String value = redisTemplate.opsForValue().get(key); // 如果存在，直接返回 if (!StringUtils.isEmpty(value)) &#123; return value; &#125; // 如果不存在，互斥访问数据库。如果是集群环境，采用分布式锁。 synchronized (this) &#123; // 获取锁后，再次从缓存中读取数据，这样操作可以避免前面获得锁的线程已经更新缓存还请求数据库 value = redisTemplate.opsForValue().get(key); if (StringUtils.isEmpty(value)) &#123; // 模拟从数据库中读取数据 String dbData = queryFromDB(); if (StringUtils.isEmpty(dbData)) &#123; //库中没有此数据，存入一个空值，过期时间为5分钟，用来解决缓存穿透问题 redisTemplate.opsForValue().set(key, &quot;&quot;, 5, TimeUnit.MINUTES); return null; &#125; else &#123; //将数据写入缓存，并设置一个随机的过期时间，解决缓存雪崩问题 //生成500 ~ 1500之间的一个随机数，设置缓存过期时间随机分布在500 ~ 1500分钟内 Random random = new Random(); int randomNum = random.nextInt(1500 - 500 + 1) + 500; redisTemplate.opsForValue().set(key, dbData, randomNum, TimeUnit.MINUTES); return dbData; &#125; &#125; //缓存中有数据，直接返回 return value; &#125;&#125; 3）给缓存添加标记，读取缓存前先取标记，伪代码如下： 12345678910111213141516171819202122232425public String getRedisData(String key) &#123; int cacheTime = 30; // 缓存标记 String cacheSign = key + &quot;_sign&quot;; // 读取缓存标记 String sign = redisTemplate.opsForValue().get(cacheSign); // 读取缓存 String value = redisTemplate.opsForValue().get(key); // 如果缓存标记不存在 if (StringUtils.isEmpty(sign)) &#123; // 更新缓存标记 redisTemplate.opsForValue().set(cacheSign, &quot;ok&quot;, cacheTime, TimeUnit.MINUTES); new Thread(new Runnable() &#123; @Override public void run() &#123; // 模拟从数据库中读取数据 String dbData = queryFromDB(); // 更新缓存,过期时间设为标记的两倍 redisTemplate.opsForValue().set(key, dbData, cacheTime * 2, TimeUnit.MINUTES); &#125; &#125;).start(); &#125; // 返回缓存数据 return value;&#125; 缓存数据的过期时间比缓存标记的时间延长1倍，比如代码中标记缓存时间为30分钟，数据缓存为60分钟。 当缓存标记过期后，旧缓存数据还能返回使用，直到新线程在更新完缓存数据后，才会返回新缓存。这个必须允许一定的数据不一致。 缓存穿透 问题描述 缓存穿透是指用户不断请求缓存和数据库中都没有的数据。这样的请求在缓存中查不到，去数据库也查不到，相当于进行了两次无用的查询。如果是海量的这种无用查询，比如批量请求id值为-1或特别大不存在的数据，就可能导致数据库压力过大，严重会宕机。这样请求绕过缓存直接查数据库，可能是缓存命中率问题，也可能是恶意攻击问题。 解决方案 针对缓存穿透问题，主要有两种解决方案： 1）采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap过滤掉，从而避免了查询缓存和数据库。 2）缓存空数据，如果一个查询返回的数据为空，仍然把这个空结果进行缓存，但把它的过期时间设置很短，比如 5 分钟。这样，再次请求就能获取到数据，而不会再访问数据库，这样可以有效地避免网络攻击。 3）接口校验，正常情况下很少会出现访问不存在key的情况，即使有也不会大量出现，如果是大量出现很可能遭到了网络攻击。这种情况，可以在网关做下安全校验：包括用户身份校验、数据合法性校验等，比如对于负数、特殊字符等请求参数直接过滤掉等等。 布隆过滤器 布隆过滤器（Bloom Filter）是由布隆（Burton Howard Bloom）在1970年提出的。它实际上是由一个很长的二进制向量（位向量）和一系列随机映射函数组成的。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的假阳性（False Positive）和数据删除困难，比如Bloom Filter报告某一元素存在于某集合中，但是实际上该元素可能并不在集合中。但是它没有假阴性（False Negative）的情形，即如果Bloom Filter报告某个元素没有在该集合中，那说明该元素确实不在集合中，不会出现反向漏报。Bloom Filter不适合那些“零错误”的应用场合，但在能容忍低错误率的应用场合下，Bloom Filter具有很高的效率，并通过极少的错误换取了极大的存储空间节省。 BloomFilter在判断数据是否时，如果判断的数据存在那有可能不存在，如果不存在那就是真的不存在。因为，Bloom Filter本身是用一个很长的二进制位来表示数据是否存在。在标记一个数据时是通过 N 个Hash函数来计算当前的值，每一个hash函数将对应的值进行计算会得到一个整数，然后就把对应的整数位设置为1。所以当你通过 N 个Hash函数计算后返回数据存在，那有可能是不存在的，因为有可能某一个二进制位是其它某个数据计算后设置为1的。如果二进制位足够长，使用的Hash函数比较多，那错误率就相对比较少，当然效率也会相应降低。 下图是一个 m&#x3D;18, k&#x3D;3 的BloomFilter示例。集合中的 x、y、z 三个元素通过3个不同的哈希函数散列到bitmap数组中。当查询元素 w 时，因为有一个比特为0，所以 w 不在该集合中。 布隆过滤器优缺点1）优点 和其他数据结构相比，布隆过滤器在空间效率和时间效率上都有巨大优势。布隆过滤器的存储空间和插入&#x2F;查询时间都是常数级别，这取决于Hash函数的个数k(O(k))。另外，Hash函数相互之间没有关系，方便并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求比较高的应用场景有优势。 2）缺点 布隆过滤器的缺点主要是假阳性（False Positive）和删除元素困难。随着存入的元素数量增加，误算率也随之增加。但是如果元素数量太少，使用散列表就可以了。 代码实现 1）使用guava提供的布隆过滤器，伪代码如下： 1234567891011121314151617181920212223242526272829303132@Componentpublic class BloomFilterCache &#123; public static BloomFilter&lt;Integer&gt; bloomFilter = null; @Autowired private RedisTemplate redisTemplate; /** * 初始化 */ @PostConstruct public void init()&#123; // 获取redis中所有的key Set&lt;String&gt; keys = redisTemplate.keys(&quot;*&quot;); // 创建一个布隆过滤器，具体实现方式有guava实现 bloomFilter = BloomFilter.create(Funnels.integerFunnel(), keys.size()); // 将redis中的key映射到布隆过滤器上 keys.forEach(key -&gt;bloomFilter.put(Integer.parseInt(key))); &#125; /** * 判断key是否存在 * @param key * @return */ public static boolean mightContain(String key)&#123; return bloomFilter.mightContain(Integer.parseInt(key)); &#125;&#125; 以上是使用guava提供的布隆过滤器，在服务初始化时把redis所有的key映射到布隆过滤器上。另外，在向redis添加缓存的时候也应该把key映射上去。 2）缓存空数据，设置较短的过期时间，5分钟，伪代码如下： 123456789101112131415161718public String getRedisData(String key) &#123; //从缓存中读取数据 String value = redisTemplate.opsForValue().get(key); if(StringUtils.isEmpty(value))&#123; // 模拟从数据库中读取数据 String dbData = queryFromDB(); if (StringUtils.isEmpty(dbData)) &#123; //库中没有此数据，存入一个空值，过期时间为5分钟，用来解决缓存穿透问题 redisTemplate.opsForValue().set(key, &quot;&quot;, 5, TimeUnit.MINUTES); return null; &#125;else&#123; redisTemplate.opsForValue().set(key, dbData); return dbData; &#125; &#125; //缓存中有数据，直接返回 return value;&#125; 缓存击穿问题描述在高并发情况下，某一个热点key，在缓存过期的一瞬间，可能有大量的请求进来，由于此时缓存过期，所以请求直接访问了数据库，造成瞬时数据库请求量过大，可能导致数据库宕机。击穿和雪崩有点类似，不过击穿主要针对热点key过期，而雪崩是针对大面积key同时过期。 解决方案1）加锁互斥访问，在海量请求中，只有一个请求线程拿到锁并执行数据库查询操作，其他的线程阻塞等待，当第一个线程将数据写入缓存后，其余线程直接访问缓存返回数据，避免了访问数据库，和雪崩中的互斥访问类似。 2）设置热点数据不过期。直接将缓存设置为不过期，然后由定时任务异步加载数据，更新缓存。这种方式由于异步线程更新数据可能延迟，部分线程可能获取到脏数据，所以必须结合业务考虑。 代码实现1）如果是分布式环境，可以考虑Redis分布式锁。如果服务部署不是特别多，对性能要求不是特别高，也可以直接使用JVM互斥锁，JVM锁已经可以大大减少访问数据库的线程数量了。 使用redis分布式锁的伪代码如下： 12345678910111213141516171819202122232425public Object getData(String key) throws InterruptedException &#123; Object value = redis.get(key); // 缓存值过期 if (value == null) &#123; // lockRedis：专门用于加锁的redis； // 使用key加锁，防止不同key阻塞，提高性能，&quot;empty&quot;：加锁的值随便设置都可以 if (lockRedis.set(key, &quot;empty&quot;, &quot;PX&quot;, lockExpire, &quot;NX&quot;)) &#123; try &#123; // 查询数据库，并写到缓存，让其他线程可以直接走缓存 value = getDataFromDb(key); redis.set(key, value, &quot;PX&quot;, expire); &#125; catch (Exception e) &#123; &#125; finally &#123; // 释放锁 lockRedis.delete(key); &#125; &#125; else &#123; // 等待100ms后重试，可能第一个线程已经更新了缓存 Thread.sleep(100); return getRedisData(key); &#125; &#125; return value;&#125; 加锁时可以使用key加锁，这样可以防止请求不同key的线程阻塞，提高性能。 前面已经有synchronized实现的伪代码，这里使用ReentrantLock锁实现一下，基本类似： 1234567891011121314151617181920212223242526272829public String getRedisData(String key) &#123; //从缓存中读取数据 String value = redisTemplate.opsForValue().get(key); if(StringUtils.isEmpty(value))&#123; try&#123; if(reenLock.tryLock())&#123; // 模拟从数据库中读取数据 value = queryFromDB(); if (StringUtils.isEmpty(value)) &#123; //库中没有此数据，存入一个空值，过期时间为5分钟，用来解决缓存穿透问题 redisTemplate.opsForValue().set(key, &quot;&quot;, 5, TimeUnit.MINUTES); return null; &#125;else&#123; redisTemplate.opsForValue().set(key, value); &#125; &#125;else&#123; // 等待100ms后重试，可能第一个线程已经更新了缓存 Thread.sleep(100); return getRedisData(key); &#125; &#125; finally &#123; //释放锁 reenLock.unlock(); &#125; &#125; //缓存中有数据，直接返回 return value;&#125;","categories":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"缓存","slug":"缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"Java回调机制","slug":"java_others/Java回调机制","date":"2018-12-03T14:06:19.000Z","updated":"2024-02-14T11:14:56.449Z","comments":false,"path":"2018/12/03/java_others/Java回调机制/","permalink":"https://imalan6.github.io/hexo_blog/2018/12/03/java_others/Java%E5%9B%9E%E8%B0%83%E6%9C%BA%E5%88%B6/","excerpt":"","text":"Java回调机制调用关系模块之间的调用的方式分为如下几种： 1）同步调用 同步调用是最基本且最简单的一种调用方式，类A的方法a()调用类B的方法b()，一直等待b()方法执行完毕，a()方法继续往下执行。这种调用方式适用于方法b()执行时间不长的情况，因为b()方法执行时间一长或者直接阻塞的话，a()方法的剩余代码是无法执行的，这样会导致整个流程的阻塞。 2）异步调用 异步调用是为了解决同步调用可能出现的阻塞，导致整个流程卡住而产生的一种调用方式。类A的方法a()开启一个新线程调用类B的方法b()，方法a()继续往下执行，这样无论方法b()执行多久，都不会阻塞方法a()的执行。但这种方式，由于方法a()不等待方法b()的执行完成，在方法a()需要方法b()执行结果的情况下，必须通过一定的方式对方法b()的执行结果进行监听，可以使用Future+Callable的方式实现。 3）回调机制 回调的思想是： 类A的a()方法调用类B的b()方法 类B的b()方法执行完毕主动调用类A的callback()方法 这样形成了一种双向的调用方式。 回调机制接下来看一下回调的代码示例，代码模拟一个主服务开始执行任务，然后调用计算服务进行计算，计算服务完成后将结果回调给主服务。 首先定义一个回调接口ServiceCallback，一个getResult方法用于获取计算结果： 1234public interface ServiceCallback &#123; // 用于获取计算结果 public void getResult(int result);&#125; 定义一个主服务，实现ServiceCallback回调接口： 1234567891011121314151617181920public class MainService implements ServiceCallback &#123; public void task()&#123; System.out.println(&quot;主服务调用计算服务&quot;); CalculateService calculateService = new CalculateService(); calculateService.add(1, 5, this); System.out.println(&quot;主服务继续执行其他任务&quot;); &#125; @Override public void getResult(int result) &#123; System.out.println(&quot;主服务获取了计算结果:&quot; + result); &#125; public static void main(String[] args) &#123; MainService mainService = new MainService(); mainService.task(); &#125;&#125; 定义一个计算服务： 123456789101112131415161718public class CalculateService &#123; public void add(int x, int y, ServiceCallback callback)&#123; int result = x + y; try &#123; Thread.sleep(3000); // 模拟耗时计算 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;计算任务完成了计算&quot;); // 调用主服务的回调接口，回送计算结果 callback.getResult(result); &#125;&#125; 定义一个测试类： 1234567public class CalculateTest&#123; public static void main(String[] args) &#123; MainService mainService = new MainService(); // 执行任务 mainService.task(); &#125;&#125; 输出结果： 1234主服务调用计算服务计算任务完成了计算主服务获取到了计算结果:6主服务继续执行其他任务 回调机制实现步骤： 1）定义一个回调接口，里面方法用于传输执行结果； 2）调用方实现回调接口，将自己(this)传给被调用方； 3）被调用方执行完任务，通过调用回调接口callback将结果返回给调用方。 总之，回调的核心就是调用方将本身即this传递给被调用方，这样被调用方就可以在调用完毕之后返回调用方结果。回调是一种思想、是一种机制，至于具体如何实现，可以根据不同业务做不同地处理。 异步回调从上面回调实例的运行结果可以看出，主服务调用了计算服务后，并没有继续执行后面的代码，而是等待计算服务执行完毕返回结果后，才开始继续向下执行的，这是同步回调。而要实现异步回调的话，需要开启一个新线程来执行计算任务，其他并无差异。 首先，定义一个Task类实现Runnable接口，代码如下： 1234567891011121314class Task implements Runnable&#123; private ServiceCallback callback; public Task(ServiceCallback callback)&#123; this.callback = callback; &#125; @Override public void run() &#123; CalculateService calculateService = new CalculateService(); calculateService.add(1, 5, callback); &#125;&#125; 然后，主服务调用计算服务的task方法改为开启新线程调用，代码如下： 12345public void task()&#123; System.out.println(&quot;主服务调用计算服务&quot;); new Thread(new Task(this)).start(); System.out.println(&quot;主服务继续执行其他任务&quot;);&#125; 再次执行后，输出结果： 1234主服务调用计算服务主服务继续执行其他任务计算任务完成了计算主服务获取到了计算结果:6 由结果可以看出，主服务调用计算服务后，并不是等待执行结果，而是继续向下执行。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"自定义注解","slug":"java_others/自定义注解","date":"2018-11-23T14:06:21.000Z","updated":"2024-02-14T09:59:33.162Z","comments":false,"path":"2018/11/23/java_others/自定义注解/","permalink":"https://imalan6.github.io/hexo_blog/2018/11/23/java_others/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3/","excerpt":"","text":"自定义注解注解定义Java 注解又称 Java 标注，是 JDK 5.0 版本开始支持加入源代码的特殊语法元数据。Java 注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。 Java 语言中的类、方法、变量、参数和包等都可以被标注。和Javadoc不同，Java 标注可以通过反射获取标注内容。在编译器生成类文件时，标注可以被嵌入到字节码中。Java 虚拟机可以保留标注内容，在运行时可以获取到标注内容。 当然，它也支持自定义 Java 标注。Java 注解包含在java.lang.annotation包中。 使用场景1）生成文档。这是最常见的，也是 Java 最早提供的注解。常用的有@param、@return等； 2）代码分析。实现替代配置文件功能。比如Dagger 2依赖注入，Java 开发将大量注解配置，具有很大用处; 3）编译检查。如@override放在方法前，如果这个方法并不是覆盖了超类方法，则编译时就能检查出； 4）自定义注解+拦截器或者AOP。使用自定义注解来设计框架，使得代码更简单、优雅。 元注解元注解的作用就是负责注解其他注解，也就是说如果要自定义注解的话，就得使用元注解来修饰说明。Java 5.0 定义了4个标准的meta-annotation类型，它们被用来提供对其它annotation类型作说明。Java5.0 定义的元注解： @Target，描述注解的使用范围； @Retention，描述注解的生命周期； @Documented，描述生成到Javadoc文档中； @Inherited，描述可以被子类继承； 这些类型和它们所支持的类在java.lang.annotation包中可以找到。 @Target 注解 @Target 说明了Annotation所修饰的对象范围。Annotation可被用于packages、types（类、接口、枚举、Annotation类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch参数）。在Annotation类型的声明中使用了@target可以更加明确修饰的目标。 作用：用于描述注解的使用范围，ElementType取值有： ElementType.TYPE：类或接口； ElementType.FIELD：字段； ElementType.METHOD：方法； ElementType.CONSTRUCTOR：构造方法； ElementType.PARAMETER：方法参数； ElementType.LOCAL_VARIABLE：局部变量； ElementType.PACKAGE：包。 实例代码： 12345678910111213@Target(ElementType.TYPE)public @interface Table &#123; /** * 数据表名称注解，默认值为类名称 * @return */ public String tableName() default &quot;className&quot;;&#125;@Target(ElementType.FIELD)public @interface NoDBColumn &#123;&#125; 注解Table可以用于注解类、接口(包括注解类型) 或enum声明，而注解NoDBColumn仅可用于注解类的成员变量。 @Retention注解 @Retention定义了该Annotation被保留的时间长短。某些Annotation仅出现在源代码中，而被编译器丢弃；而另一些却被编译在class文件中；编译在class文件中的Annotation可能会被虚拟机忽略；还有一些在class被装载时将被读取（并不影响class的执行，因为Annotation与class在使用上是分离的）。使用这个meta-Annotation可以对Annotation的生命周期进行限制。 作用：用于描述注解的生命周期（即：被描述的注解在什么阶段有效），RetentionPoicy取值有： RetentionPoicy.SOURCE：在源文件中有效（即源文件保留） RetentionPoicy.CLASS：在class文件中有效（即 class 保留） RetentionPoicy.RUNTIME：在运行时有效（即运行时保留） 如果@Retention不存在，则该Annotation 默认为CLASS。通常我们自定义的Annotation都是RUNTIME。所以，使用时务必要加上@Retention(RetentionPolicy.RUNTIME)元注解。 实例代码： 12345678@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface Column &#123; public String name() default &quot;fieldName&quot;; public String setFuncName() default &quot;setField&quot;; public String getFuncName() default &quot;getField&quot;; public boolean defaultDBValue() default false;&#125; Column注解的RetentionPolicy的属性值是RUTIME。这样可以通过反射，获取到该注解的属性值，去做一些运行时需要处理的业务逻辑。 @Documented注解 @Documented用于描述应该被作为被标注的程序成员的公共API，是被用来指定自定义注解是否能随着被定义的Java文件生成到JavaDoc文档当中。@Documented是一个标记注解，没有成员。 123456789@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Column &#123; public String name() default &quot;fieldName&quot;; public String setFuncName() default &quot;setField&quot;; public String getFuncName() default &quot;getField&quot;; public boolean defaultDBValue() default false;&#125; @Inherited注解 @Inherited元注解是一个标记注解，@Inherited阐述了某个被标注的类型是可以被继承的。如果一个使用了@Inherited修饰的annotation类型被用于一个class，则这个annotation将被用于该class的子类。 注意：@Inherited annotation类型是被标注过的class的子类所继承。类并不从它所实现的接口继承annotation，方法也不从它所重载的方法继承annotation。@Inherited仅针对@Target(ElementType.TYPE)类型的annotation有效，并且仅针对class的继承，对interface的继承无效。 实例代码： 1234567@Inherited@Target(ElementType.TYPE)public @interface Report &#123; int type() default 0; String level() default &quot;info&quot;; String value() default &quot;&quot;;&#125; 自定义注解使用@interface自定义注解时，自动继承了java.lang.annotation.Annotation接口，由编译程序自动完成其他细节。在定义注解时，不能继承其他的注解或接口。@interface用来声明一个注解，其中的每一个方法实际上是声明了一个配置参数。方法的名称就是参数的名称，返回值类型就是参数的类型（返回值类型只能是基本类型、Class、String、Enum）。可以通过default来声明参数的默认值。 自定义注解格式： public @interface 注解名 {定义体} 自定义注解参数数据类型： 1）所有基本数据类型（int，float，boolean，byte，double，char，long，short) 2）String类型 3）Class类型 4）enum类型 5）Annotation类型 6）以上所有类型的数组 自定义注解参数设定： 1）只能用public或默认(default) 这两个访问权修饰。例如，String value()；这里把方法设为default默认类型； 2）参数成员只能用八种基本数据类型和String，Enum，Class，annotations等数据类型，以及这一些类型的数组。例如，String value(); 这里的参数成员就为String； 3）如果只有一个参数成员，最好把参数名称设为”value()“。 使用实例 先自定义一个注解，代码如下： 123456@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface MyField &#123; String description(); int length();&#125; 通过反射获取注解信息，代码如下： 12345678910111213141516171819202122public class MyFieldTest &#123; //使用自定义注解 @MyField(description = &quot;用户名&quot;, length = 12) private String username; @Test public void testMyField()&#123; // 获取类模板 Class c = MyFieldTest.class; // 获取所有字段 for(Field f : c.getDeclaredFields())&#123; // 判断这个字段是否有MyField注解 if(f.isAnnotationPresent(MyField.class))&#123; MyField annotation = f.getAnnotation(MyField.class); System.out.println(&quot;字段:[&quot; + f.getName() + &quot;], 描述:[&quot; + annotation.description() + &quot;], 长度:[&quot; + annotation.length() +&quot;]&quot;); &#125; &#125; &#125;&#125; 这个例子简单地说明了自定义注解使用方法。但是在实际项目中，可能有很多类都使用了自定义注解，而我们不知道是具体哪个类或者哪个方法使用了自定义注解。所以，一般可以通过SpringMVC的拦截器或者Spring AOP方式获取添加了注解的方法，在拦截器或者AOP的通知里对注解进行处理。 应用实例 实例一：自定义注解 + 拦截器实现登陆校验 使用springmvc拦截器实现这样一个功能，如果方法上加了@LoginRequired注解，则提示用户该接口需要登录才能访问，否则正常访问。 首先定义一个LoginRequired注解。 12345@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface LoginRequired &#123; boolean value() default true;&#125; 然后写一个拦截器，负责拦截用户请求，进行登录判断，代码如下： 1234567891011121314151617181920212223242526272829303132public class LoginIntercepter implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println(&quot;开始登陆校验...&quot;); if (handler instanceof HandlerMethod) &#123; // 反射获取方法上的LoginRequred注解 HandlerMethod handlerMethod = (HandlerMethod) handler; LoginRequired loginRequired = handlerMethod.getMethod().getAnnotation(LoginRequired.class); // 有LoginRequired注解 if (loginRequired != null) &#123; // 需要登录，提示用户登录 response.setContentType(&quot;application/json; charset=utf-8&quot;); response.getWriter().print(&quot;请先登陆！&quot;); // 返回false，流程中断 return false; &#125; &#125; // 返回true，继续流程 return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 创建配置类将拦截器注册到拦截器链中，代码如下： 12345678@Configurationpublic class IntercepterConfigurer implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LoginIntercepter()).addPathPatterns(&quot;/**&quot;); &#125;&#125; 再写一个测试用的Controller，有 3 个方法，分别如下： testA()方法不加@LoginRequired注解； testB()方法加@LoginRequired注解，但value = false； testC()方法加@LoginRequired注解，但value = true。 12345678910111213141516171819@RestControllerpublic class TestController &#123; @GetMapping(&quot;/testa&quot;) public String testA()&#123; return &quot;test A&quot;; &#125; @LoginRequired(value = false) @GetMapping(&quot;/testb&quot;) public String testB()&#123; return &quot;test B&quot;; &#125; @LoginRequired(value = true) @GetMapping(&quot;/testc&quot;) public String testC()&#123; return &quot;test C&quot;; &#125;&#125; 启动服务，打开浏览器分别访问 A、B、C 三个接口，结果如下： testA方法没有加@LoginRequired注解，所以正常返回； testB方法加了@LoginRequired 注解，但value值为false，所以正常返回； testC方法加了@LoginRequired 注解，value值设为true，所以提示登录验证； 实例二：自定义注解 + AOP 实现日志打印 导入切面编程需要的依赖包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 定义一个注解@MyLog 12345@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface MyLog &#123; &#125; 定义一个切面类，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738@Aspect // 切面类@Componentpublic class MyLogAspect &#123; // PointCut表示这是一个切点，@annotation表示这个切点定义到一个注解上，后面带该注解的全类名 // 切面最重要的就是切点，所有的都围绕切点发生 // logPointCut()代表切点名称 @Pointcut(&quot;@annotation(com.alanotes.demo.annotation.aop.MyLog)&quot;) public void logPointCut()&#123;&#125;; // 环绕通知 @Around(&quot;logPointCut()&quot;) public Object logAround(ProceedingJoinPoint joinPoint)&#123; // 获取方法名称 String methodName = joinPoint.getSignature().getName(); // 获取入参 Object[] param = joinPoint.getArgs(); StringBuilder sb = new StringBuilder(); for(Object o : param)&#123; sb.append(o + &quot;; &quot;); &#125; System.out.println(&quot;执行：&quot; + methodName + &quot;方法，参数：&quot; + sb.toString()); // 继续执行方法 Object result = null; try &#123; result = joinPoint.proceed(); &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); &#125; System.out.println(methodName + &quot;方法执行结束&quot;); return result; &#125;&#125; 创建一个Controller，定义一个testD方法测试，代码如下： 12345678@RestControllerpublic class TestAopController &#123; @MyLog @GetMapping(&quot;/testd/&#123;param&#125;&quot;) public String testD(@PathVariable(&quot;param&quot;) String param)&#123; return &quot;test D&quot;; &#125;&#125; 启动springboot服务，访问接口 接口正常返回，查看控制台，打印日志如下：","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"深拷贝与浅拷贝","slug":"java_others/深拷贝与浅拷贝","date":"2018-11-12T14:42:21.000Z","updated":"2024-02-14T09:59:33.144Z","comments":false,"path":"2018/11/12/java_others/深拷贝与浅拷贝/","permalink":"https://imalan6.github.io/hexo_blog/2018/11/12/java_others/%E6%B7%B1%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B5%85%E6%8B%B7%E8%B4%9D/","excerpt":"","text":"深拷贝与浅拷贝对象拷贝对象拷贝(Object Copy)是将一个对象的属性拷贝到另一个有着相同类类型的对象中去。在程序中拷贝对象是很常见的，主要是为了在新的上下文环境中复用对象的部分或全部数据。 浅拷贝对于基本数据类型，拷贝它的值，而对于引用数据类型，拷贝的它的引用，也就是内存地址，并没有创建一个新的对象，即没有分配新的内存空间，这样的拷贝就称作浅拷贝。浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。 由于浅拷贝拷贝的是引用，因此如果其中一个对象改变了引用地址，会影响到另一个对象。 实例 123456789101112131415public class Goods &#123; private String goodsId; public Subject(String goodsId) &#123; this.goodsId = goodsId; &#125; public String getGoodsId() &#123; return this.goodsId; &#125; public void setGoodsId(String goodsId) &#123; this.goodsId = goodsId; &#125; &#125; 123456789101112131415161718192021222324public class Order implements Cloneable &#123; // 对象引用 private Goods goods; private String orderId; public Order(String orderId, String goodsId) &#123; this.orderId = orderId; this.goods = new Goods(goodsId); &#125; /** * 重写clone()方法 * @return */ public Object clone() &#123; //浅拷贝 try &#123; // 直接调用父类的clone()方法 return super.clone(); &#125; catch (CloneNotSupportedException e) &#123; return null; &#125; &#125; &#125; 让拷贝类Student实现了Clonable接口并重写Object类的clone()方法，然后在方法内部直接调用super.clone()方法，就是浅拷贝。 深拷贝深拷贝会拷贝所有的属性，且不仅仅拷贝属性的引用地址，还会拷贝属性指向的动态分配的内存。当对象和它所引用的对象一起被拷贝时，即称为深拷贝。深拷贝相比于浅拷贝速度较慢并且花销较大。 实例 同样是上述浅拷贝的例子，将Order的clone方法进行修改，保证拷贝后的新Order对象里面的Goods对象是一个new出来的新对象即可实现深拷贝。 12345678910111213141516171819202122232425public class Order implements Cloneable &#123; // 对象引用 private Goods goods; private String orderId; public Order(String orderId, String goodsId) &#123; this.orderId = orderId; this.goods = new Goods(goodsId); &#125; /** * 重写clone()方法 * @return */ public Object clone() &#123; //浅拷贝 try &#123; // 深拷贝，创建拷贝类的一个新对象，这样就和原始对象相互独立 Order order = new Order(this.OrderId, goods.getGoodsId()); return s; &#125; catch (CloneNotSupportedException e) &#123; return null; &#125; &#125; &#125;","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"动态代理详解","slug":"java_others/动态代理","date":"2018-11-06T05:30:21.000Z","updated":"2024-02-14T09:59:33.094Z","comments":false,"path":"2018/11/06/java_others/动态代理/","permalink":"https://imalan6.github.io/hexo_blog/2018/11/06/java_others/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"动态代理详解动态代理在Java中有广泛的应用，比如Spring AOP、Hibernate数据查询、RPC远程调用、Java注解对象获取、日志、用户鉴权、全局性异常处理、性能监控，事务处理等都有动态代理的应用。 代理模式代理模式：提供了对目标对象额外的访问方式，即通过代理对象访问目标对象，这样可以在不修改原目标对象的前提下，提供额外的功能操作，以扩展目标对象的功能。代理模式就是设置一个中间代理来控制访问原目标对象，以达到增强原对象的功能和简化访问方式。代理模式是一种结构型设计模式，详见 代理模式。 代理模式角色分为三种： Subject（抽象主题角色）：定义代理类和真实主题的公共对外方法，也是代理类代理真实主题的方法； RealSubject（真实主题角色）：真正实现业务逻辑的类； Proxy（代理主题角色）：用来代理和封装真实主题； 代理模式的结构比较简单，其核心是代理类，为了让客户端能够一致性地对待真实对象和代理对象，在代理模式中引入了抽象层。如果根据字节码的创建时机来分类，可以分为静态代理和动态代理： 静态代理就是在程序运行前就已经存在代理类的字节码文件，代理类和真实主题角色的关系在运行前就已经确定了。 而动态代理的源码是在程序运行期间由JVM根据反射等机制动态生成的，所以在运行前并不存在代理类的字节码文件。 静态代理 实例 创建一个接口，然后创建被代理的类实现该接口并且实现该接口中的抽象方法。再创建一个代理类，同时使其也实现这个接口。在代理类中持有一个被代理对象的引用，而后在代理类方法中调用该对象的方法。 接口： 123public interface HelloInterface &#123; void sayHello();&#125; 被代理类： 123456public class Hello implements HelloInterface&#123; @Override public void sayHello() &#123; System.out.println(&quot;Hello Alan6!&quot;); &#125;&#125; 代理类： 123456789public class HelloProxy implements HelloInterface&#123; private HelloInterface helloInterface = new Hello(); @Override public void sayHello() &#123; System.out.println(&quot;Before invoke sayHello&quot; ); helloInterface.sayHello(); System.out.println(&quot;After invoke sayHello&quot;); &#125;&#125; 代理类调用： 被代理类被传递给了代理类HelloProxy，代理类在执行具体方法时通过所持用的被代理类完成调用。 1234public static void main(String[] args) &#123; HelloProxy helloProxy = new HelloProxy(); helloProxy.sayHello();&#125; 结果输出： 123Before invoke sayHelloHello Alan6!After invoke sayHello 静态代理方式需要代理对象和目标对象实现一样的接口。 优缺点 优点：可以在不修改目标对象的前提下扩展目标对象的功能。 缺点： 1）冗余。由于代理对象要实现与目标对象一致的接口，会产生过多的代理类。 2）不易维护。一旦接口增加、删除方法，目标对象与代理对象都要进行修改。 动态代理代理类在程序运行时创建的代理方式称为动态代理。 也就是说，代理类并不是在 Java 代码中定义的，而是在运行时根据我们在 Java 代码中的要求动态生成的。相比于静态代理，动态代理可以很方便地对代理类的方法进行统一处理，而不用去修改每个代理类的方法。 JDK动态代理动态代理类不仅简化了编程工作，而且提高了软件系统的可扩展性，因为 Java 反射机制可以生成任意类型的动态代理类。java.lang.reflect包中的Proxy类和InvocationHandler接口提供了生成动态代理类的功能。继续用上面的例子实现动态代理。 InvocationHandler接口 创建一个中介类，实现InvocationHandler接口，作为调用处理器拦截对代理类方法的调用，对代理对象的所有接口方法调用都会转发到InvocationHandler.invoke()方法，在invoke()方法里可以加入处理逻辑，比如修改方法参数，加入日志功能、安全检查功能等。代码如下： 123456789101112131415public class ProxyHandler implements InvocationHandler&#123; private Object object; public ProxyHandler(Object object)&#123; this.object = object; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;Before invoke &quot; + method.getName()); method.invoke(object, args); // 调用目标方法 System.out.println(&quot;After invoke &quot; + method.getName()); return null; &#125;&#125; Proxy类 调用Proxy类的newProxyInstance方法来获取一个代理类实例。这个代理类实现了指定的接口并且会把方法调用分发到指定的调用处理器。 123456789101112131415public static void main(String[] args) &#123; // 创建被代理对象 HelloInterface hello = new Hello(); // 创建中介类实例 ProxyHandler handler = new ProxyHandler(hello); // 使用proxy类 使用被代理对象的classloader，创建代理类实例 HelloInterface proxyHello = (HelloInterface) Proxy.newProxyInstance(hello.getClass().getClassLoader(), hello.getClass().getInterfaces(), handler); // 通过代理类对象调用被代理类的方法，实际上会转到invoke方法调用 proxyHello.sayHello();&#125; 程序输出： 123Before invoke sayhello Alan6!After invoke say 由结果可见，JDK动态代理不需要单独创建静态的代理类即可实现动态代理功能，底层实现原理详见 JDK动态代理底层原理。 cglib动态代理JDK动态代理有一个限制，就是使用动态代理的对象必须实现一个或多个接口。如果想代理没有实现接口的类，则可以使用cglib实现，从而达到代理类无侵入。 cglib有如下特点： 1）cglib是一个强大的高性能代码生成包，它可以在运行期扩展Java类与实现 Java接口。它在许多AOP框架中有广泛使用，例如Spring AOP，为它们提供了对方法的拦截。 2）cglib包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。不鼓励直接使用ASM，因为它需要你对JVM内部结构包括class文件的格式和指令集都很熟悉。 使用cglib需要引入cglib的jar包，如果项目已经有spring-core的jar包，则无需引入，因为spring中包含了cglib。 MethodInterceptor 实现methodInterceptor接口，实现方式类似上述的InvocationHandler。 123456789101112public class ProxyInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object object, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;Before invoke &quot;); Object result = methodProxy.invokeSuper(object, objects); System.out.println(&quot;After invoke &quot;); return result; &#125;&#125; Enhancer类 Enhancer是cglib中最常用的一个类，和JDK动态代理中引入的Proxy类相似。和Proxy不同的是，Enhancer既能够代理普通的类，也能够代理接口。Enhancer创建一个被代理对象的子类并且拦截所有的方法调用（包括从Object中继承的toString和hashCode方法）。Enhancer不能够拦截final方法，例如Object.getClass()方法，这是由于Java final方法语义决定的。同样，Enhancer也不能对final类进行代理操作。 123456789101112131415public static void main(String[] args) &#123; // 创建一个ProxyInterceptor中介类对象 ProxyInterceptor proxy = new ProxyInterceptor(); // 创建enhancer类对象，并设置回调 Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Hello.class); enhancer.setCallback(proxy); // 通过enhancer对象创建代理类对象 Hello hello = (Hello) enhancer.create(); hello.say();&#125; 程序输出： 123Before invoke sayHello Alan6!After invoke say 定义不同的拦截策略 比如说，我可能会遇到这样一种复杂场景：对某个类的A方法使用一种拦截策略，对这个类的B方法又使用另外一种拦截策略。如果是这样情况，就需要先定义不同的拦截策略，然后再定义一个过滤策略。首先在Hello类中再添加一个sayBye方法，代码如下： 12345678public class Hello&#123; public void sayHello() &#123; System.out.println(&quot;Hello Alan6!&quot;); &#125; public void sayBye() &#123; System.out.println(&quot;Bye Alan6!&quot;); &#125;&#125; 然后针对不同的拦截策略定义一个拦截器，代码如下： 12345678910111213public class ProxyInterceptorOther implements MethodInterceptor &#123; @Override public Object intercept(Object object, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;Before invoke other&quot;); Object result = methodProxy.invokeSuper(object, objects); System.out.println(&quot;After invoke other&quot;); return result; &#125;&#125; 定义一个filter，对不同的策略进行不同的过滤，代码如下： 123456789public class ProxyFilter implements CallbackFilter &#123; @Override public int accept(Method method) &#123; if (&quot;sayBye&quot;.equals(method.getName())) &#123; return 1; // 返回的数值表示调用的策略顺序 &#125; return 0; //返回的数值表示调用的策略顺序 &#125;&#125; 最后是测试类： 12345678910111213141516public class ReflectTest &#123; public static void main(String[] args) &#123; ProxyInterceptor proxy = new ProxyInterceptor(); ProxyInterceptorOther proxyOther = new ProxyInterceptorOther(); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Hello.class); enhancer.setCallbacks(new Callback[]&#123;proxy, proxyOther&#125;); // 使用setCallbacks定义callbacks数组 enhancer.setCallbackFilter(new ProxyFilter()); // 添加filter Hello hello = (Hello) enhancer.create(); hello.say(); hello.sayBye(); &#125;&#125; 以上代码中CallbackFilter里面的accept方法返回的数值表示的是策略顺序，这个顺序和setCallbacks里面定义的Proxy的顺序是一致的。比如，代码中的Callback数组中有两个callback，那么： 1）方法名为 “sayBye“ 的方法返回的顺序为1，即使用Callback数组中的1位callback，即ProxyInterceptorOther 2）方法名不为 “sayBye“ 的方法返回的顺序为0，即使用Callback数组中的0位callback，即ProxyInterceptor 运行测试代码，输出结果： 123456Before invoke Hello Alan6!After invoke Before invoke otherBye Alan6!After invoke other 可以看到，不同的方法会根据filter里面设置的不同策略定义，调用不同的处理方式。 小结1）静态代理实现较简单，只要代理对象对目标对象进行包装，即可实现增强功能，但静态代理只能为一个目标对象服务，如果目标对象过多，则需要定义很多代理类。 2）JDK动态代理需要目标对象实现业务接口，代理类实现InvocationHandler接口。 3）JDK动态代理生成的类为class com.sun.proxy.\\$Proxy4，cglib代理生成的类为class com.cglib.Hello\\$\\$EnhancerByCGLIB\\$\\$552188b6。 4）静态代理在编译时产生 class 字节码文件，可以直接使用，效率高。JDK动态代理必须实现InvocationHandler接口，通过反射代理方法，比较消耗性能，但可以减少代理类的数量，更方便灵活。cglib动态代理无需实现接口，通过生成类字节码实现代理，比反射稍快，不存在性能问题，但cglib会继承目标对象，需要重写方法，所以目标对象不能为final类。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"SpringBoot整合Redis及常用工具类","slug":"cache/SpringBoot整合Redis及常用工具类","date":"2018-10-26T13:46:32.000Z","updated":"2024-02-14T10:02:31.778Z","comments":false,"path":"2018/10/26/cache/SpringBoot整合Redis及常用工具类/","permalink":"https://imalan6.github.io/hexo_blog/2018/10/26/cache/SpringBoot%E6%95%B4%E5%90%88Redis%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/","excerpt":"","text":"SpringBoot整合Redis及常用工具类spring-data-redis功能spring-data-redis针对jedis提供了如下功能： 1）连接池自动管理，提供了一个高度封装的“RedisTemplate”类 2）针对jedis客户端中大量api进行了归类封装,将同一类型操作封装为operation接口 ValueOperations：简单K-V操作 SetOperations：set类型数据操作 ZSetOperations：zset类型数据操作 HashOperations：针对map类型的数据操作 ListOperations：针对list类型的数据操作 3）提供了对key的“bound”(绑定)便捷化操作API，可以通过bound封装指定的key，然后进行一系列的操作而无须“显式”的再次指定Key，即BoundKeyOperations： BoundValueOperations BoundSetOperations BoundListOperations BoundSetOperations BoundHashOperations 4）将事务操作封装，有容器控制。 5）针对数据的“序列化&#x2F;反序列化”，提供了多种可选择策略(RedisSerializer) JdkSerializationRedisSerializer：POJO对象的存取场景，使用JDK本身序列化机制，将pojo类通过ObjectInputStream&#x2F;ObjectOutputStream进行序列化操作，最终redis-server中将存储字节序列。是目前最常用的序列化策略。 StringRedisSerializer：Key或者value为字符串的场景，根据指定的charset对数据的字节序列编码成string，是“new String(bytes, charset)”和“string.getBytes(charset)”的直接封装。是最轻量级和高效的策略。 JacksonJsonRedisSerializer：jackson-json工具提供了javabean与json之间的转换能力，可以将pojo实例序列化成json格式存储在redis中，也可以将json格式的数据转换成pojo实例。因为jackson工具在序列化和反序列化时，需要明确指定Class类型，因此此策略封装起来稍微复杂。【需要jackson-mapper-asl工具支持】 OxmSerializer：提供了将javabean与xml之间的转换能力，目前可用的三方支持包括jaxb，apache-xmlbeans；redis存储的数据将是xml工具。不过使用此策略，编程将会有些难度，而且效率最低；不建议使用。 如果数据需要被第三方工具解析，那么应该使用StringRedisSerializer而不是JdkSerializationRedisSerializer。 SpringBoot集成Redis添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件1234567891011121314151617spring: redis: database: 0 #Redis数据库索引（默认为0） host: 127.0.0.1 # Redis服务器地址 port: 6379 # Redis服务器连接端口 password: 123456 # Redis服务器连接密码（默认为空） lettuce: pool: # 连接池最大连接数（使用负值表示没有限制） max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） max-wait: -1 # 连接池中的最大空闲连接 max-idle: 8 # 连接池中的最小空闲连接 min-idle: 0 # 连接超时时间（毫秒） timeout: 0 redisTemplate配置类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106@Configuration@EnableCachingpublic class RedisConfig extends CachingConfigurerSupport &#123; /** * 选择redis作为默认缓存工具 * @param redisTemplate * @return */ @Bean public CacheManager cacheManager(RedisTemplate redisTemplate) &#123; RedisCacheManager rcm = new RedisCacheManager(redisTemplate); return rcm; &#125; /** * retemplate相关配置 * @param factory * @return */ @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); // 配置连接工厂 template.setConnectionFactory(factory); //使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值（默认使用JDK的序列化方式） Jackson2JsonRedisSerializer jacksonSeial = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常 om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jacksonSeial.setObjectMapper(om); // 值采用json序列化 template.setValueSerializer(jacksonSeial); //使用StringRedisSerializer来序列化和反序列化redis的key值 template.setKeySerializer(new StringRedisSerializer()); // 设置hash key 和value序列化模式 template.setHashKeySerializer(new StringRedisSerializer()); template.setHashValueSerializer(jacksonSeial); template.afterPropertiesSet(); return template; &#125; /** * 对hash类型的数据操作 * * @param redisTemplate * @return */ @Bean public HashOperations&lt;String, String, Object&gt; hashOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForHash(); &#125; /** * 对redis字符串类型数据操作 * * @param redisTemplate * @return */ @Bean public ValueOperations&lt;String, Object&gt; valueOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForValue(); &#125; /** * 对链表类型的数据操作 * * @param redisTemplate * @return */ @Bean public ListOperations&lt;String, Object&gt; listOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForList(); &#125; /** * 对无序集合类型的数据操作 * * @param redisTemplate * @return */ @Bean public SetOperations&lt;String, Object&gt; setOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForSet(); &#125; /** * 对有序集合类型的数据操作 * * @param redisTemplate * @return */ @Bean public ZSetOperations&lt;String, Object&gt; zSetOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForZSet(); &#125;&#125; spring-redis对redis的五种数据类型的操作分别为： HashOperations：对hash类型的数据操作ValueOperations：对redis字符串类型数据操作ListOperations：对链表类型的数据操作SetOperations：对无序集合类型的数据操作ZSetOperations：对有序集合类型的数据操作 spring-redis中使用了RedisTemplate操作redis，通过泛型的 K 和 V 设置键值对的对象类型。这里使用了key采用String，值采用Object。 对于Object，spring-redis默认使用了jdk自带的序列化，不推荐使用默认的。配置类中使用了json格式序列化，并配置了Jackson，当然也可以配置为fastjson，配置方式如下： fastjson依赖： 1234 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt;&lt;/dependency&gt; 自定义fastjson序列化类： 123456789101112131415161718192021222324252627282930/** * 自定义序列化类 * @param &lt;T&gt; */public class FastJsonRedisSerializer&lt;T&gt; implements RedisSerializer&lt;T&gt; &#123; public static final Charset DEFAULT_CHARSET = Charset.forName(&quot;UTF-8&quot;); private Class&lt;T&gt; clazz; public FastJsonRedisSerializer(Class&lt;T&gt; clazz) &#123; super(); this.clazz = clazz; &#125; @Override public byte[] serialize(T t) throws SerializationException &#123; if (null == t) &#123; return new byte[0]; &#125; return JSON.toJSONString(t, SerializerFeature.WriteClassName).getBytes(DEFAULT_CHARSET); &#125; @Override public T deserialize(byte[] bytes) throws SerializationException &#123; if (null == bytes || bytes.length &lt;= 0) &#123; return null; &#125; String str = new String(bytes, DEFAULT_CHARSET); return (T) JSON.parseObject(str, clazz); &#125;&#125; 自定义的配置类改为： 1234567891011121314151617@Configurationpublic class RedisConfiguration &#123; @Bean public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); //使用fastjson序列化 FastJsonRedisSerializer fastJsonRedisSerializer = new FastJsonRedisSerializer(Object.class); // value值的序列化采用fastJsonRedisSerializer template.setValueSerializer(fastJsonRedisSerializer); template.setHashValueSerializer(fastJsonRedisSerializer); // key的序列化采用StringRedisSerializer template.setKeySerializer(new StringRedisSerializer()); template.setHashKeySerializer(new StringRedisSerializer()); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125; Redis操作工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112@Componentpublic class RedisService &#123; @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; /** * 默认过期时长，单位：秒 */ public static final long DEFAULT_EXPIRE = 60 * 60 * 24; /** * 不设置过期时长 */ public static final long NOT_EXPIRE = -1; public boolean existsKey(String key) &#123; return redisTemplate.hasKey(key); &#125; /** * 重名名key，如果newKey已经存在，则newKey的原值被覆盖 * * @param oldKey * @param newKey */ public void renameKey(String oldKey, String newKey) &#123; redisTemplate.rename(oldKey, newKey); &#125; /** * newKey不存在时才重命名 * * @param oldKey * @param newKey * @return 修改成功返回true */ public boolean renameKeyNotExist(String oldKey, String newKey) &#123; return redisTemplate.renameIfAbsent(oldKey, newKey); &#125; /** * 删除key * * @param key */ public void deleteKey(String key) &#123; redisTemplate.delete(key); &#125; /** * 删除多个key * * @param keys */ public void deleteKey(String... keys) &#123; Set&lt;String&gt; kSet = Stream.of(keys).map(k -&gt; k).collect(Collectors.toSet()); redisTemplate.delete(kSet); &#125; /** * 删除Key的集合 * * @param keys */ public void deleteKey(Collection&lt;String&gt; keys) &#123; Set&lt;String&gt; kSet = keys.stream().map(k -&gt; k).collect(Collectors.toSet()); redisTemplate.delete(kSet); &#125; /** * 设置key的生命周期 * * @param key * @param time * @param timeUnit */ public void expireKey(String key, long time, TimeUnit timeUnit) &#123; redisTemplate.expire(key, time, timeUnit); &#125; /** * 指定key在指定的日期过期 * * @param key * @param date */ public void expireKeyAt(String key, Date date) &#123; redisTemplate.expireAt(key, date); &#125; /** * 查询key的生命周期 * * @param key * @param timeUnit * @return */ public long getKeyExpire(String key, TimeUnit timeUnit) &#123; return redisTemplate.getExpire(key, timeUnit); &#125; /** * 将key设置为永久有效 * * @param key */ public void persistKey(String key) &#123; redisTemplate.persist(key); &#125;&#125; redis的key工具类 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.util;/** * redisKey设计 */public class RedisKeyUtil &#123; /** * redis的key * 形式为： * 表名:主键名:主键值:列名 * * @param tableName 表名 * @param majorKey 主键名 * @param majorKeyValue 主键值 * @param column 列名 * @return */ public static String getKeyWithColumn(String tableName,String majorKey,String majorKeyValue,String column)&#123; StringBuffer buffer = new StringBuffer(); buffer.append(tableName).append(&quot;:&quot;); buffer.append(majorKey).append(&quot;:&quot;); buffer.append(majorKeyValue).append(&quot;:&quot;); buffer.append(column); return buffer.toString(); &#125; /** * redis的key * 形式为： * 表名:主键名:主键值 * * @param tableName 表名 * @param majorKey 主键名 * @param majorKeyValue 主键值 * @return */ public static String getKey(String tableName,String majorKey,String majorKeyValue)&#123; StringBuffer buffer = new StringBuffer(); buffer.append(tableName).append(&quot;:&quot;); buffer.append(majorKey).append(&quot;:&quot;); buffer.append(majorKeyValue).append(&quot;:&quot;); return buffer.toString(); &#125;&#125; 注解使用@Cacheable 表明在Spring调用之前，首先应该在缓存中查找方法的返回值，如果这个值能够找到，就会返回缓存的值，否则这个方法会被调用，返回值会放到缓存中@CachePut 表明Spring应该将该方法返回值放到缓存中，在方法调用前不会检查缓存，方法始终会被调用@CacheEvict 表明Spring应该在缓存中清楚一个或多个条目@Caching 分组注解，能够同时应用多个其他的缓存注解@CacheConfig 可以在类层级配置一些共有的缓存配置","categories":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"缓存","slug":"缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"JDK动态代理原理分析","slug":"java_others/JDK动态代理原理分析","date":"2018-10-12T13:21:22.000Z","updated":"2024-02-14T09:59:33.069Z","comments":false,"path":"2018/10/12/java_others/JDK动态代理原理分析/","permalink":"https://imalan6.github.io/hexo_blog/2018/10/12/java_others/JDK%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","excerpt":"","text":"JDK动态代理原理分析动态代理使用步骤1、实现InvocationHandler接口创建调用处理器； 2、为Proxy类指定ClassLoader对象和一组interface来创建动态代理类； 3、通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型； 4、构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。 Proxy类既生成代理对象是用的Proxy类的静态方法newProxyInstance，如下是它的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; //生成代理类对象 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); //使用指定的调用处理程序获取代理类的构造函数对象 try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; //如果Class作用域为私有，通过 setAccessible 支持访问 if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; //获取Proxy Class构造函数，创建Proxy代理实例。 return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125; 利用getProxyClass0(loader, intfs)生成代理类Proxy的Class对象。 123456789101112private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; //如果接口数量大于65535，抛出非法参数错误 if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(&quot;interface limit exceeded&quot;); &#125; //如果指定接口的代理类已经存在与缓存中，则不用新创建，直接从缓存中取即可； //如果缓存中没有指定代理对象，则通过ProxyClassFactory来创建一个代理对象。 return proxyClassCache.get(loader, interfaces);&#125; ProxyClassFactory内部类创建、定义代理类，返回给定ClassLoader和interfaces的代理类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990 private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt;&#123; // 代理类的名字的前缀统一为“$Proxy” private static final String proxyClassNamePrefix = &quot;$Proxy&quot;; // 每个代理类前缀后面都会跟着一个唯一的编号，如$Proxy0、$Proxy1、$Proxy2 private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; //验证类加载器加载接口得到对象是否与由apply函数参数传入的对象相同 Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + &quot; is not visible from class loader&quot;); &#125; //验证这个Class对象是不是接口 if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + &quot; is not an interface&quot;); &#125; if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( &quot;repeated interface: &quot; + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * Record the package of a non-public proxy interface so that the * proxy class will be defined in the same package. Verify that * all non-public proxy interfaces are in the same package. */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf(&#x27;.&#x27;); String pkg = ((n == -1) ? &quot;&quot; : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( &quot;non-public interfaces from different packages&quot;); &#125; &#125; &#125; if (proxyPkg == null) &#123; // if no non-public proxy interfaces, use com.sun.proxy package proxyPkg = ReflectUtil.PROXY_PACKAGE + &quot;.&quot;; &#125; /* * Choose a name for the proxy class to generate. */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * * 生成指定代理类的字节码文件 */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125; &#125;&#125; 一系列检查后，调用ProxyGenerator.generateProxyClass来生成字节码文件。 123456789101112131415161718192021222324252627282930public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) &#123; ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); // 真正用来生成代理类字节码文件的方法在这里 final byte[] var4 = var3.generateClassFile(); // 保存代理类的字节码文件 if(saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if(var1 &gt; 0) &#123; Path var3 = Paths.get(var0.substring(0, var1).replace(&#x27;.&#x27;, File.separatorChar), new String[0]); Files.createDirectories(var3, new FileAttribute[0]); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + &quot;.class&quot;); &#125; else &#123; var2 = Paths.get(var0 + &quot;.class&quot;, new String[0]); &#125; Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError(&quot;I/O exception saving generated file: &quot; + var4x); &#125; &#125; &#125;); &#125; return var4; &#125; 生成代理类字节码文件的generateClassFile方法: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111private byte[] generateClassFile() &#123; //下面一系列的addProxyMethod方法是将接口中的方法和Object中的方法添加到代理方法中(proxyMethod) this.addProxyMethod(hashCodeMethod, Object.class); this.addProxyMethod(equalsMethod, Object.class); this.addProxyMethod(toStringMethod, Object.class); Class[] var1 = this.interfaces; int var2 = var1.length; int var3; Class var4; //获得接口中所有方法并添加到代理方法中 for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; Method[] var5 = var4.getMethods(); int var6 = var5.length; for(int var7 = 0; var7 &lt; var6; ++var7) &#123; Method var8 = var5[var7]; this.addProxyMethod(var8, var4); &#125; &#125; Iterator var11 = this.proxyMethods.values().iterator(); List var12; while(var11.hasNext()) &#123; var12 = (List)var11.next(); checkReturnTypes(var12); &#125; Iterator var15; try &#123; //生成代理类的构造函数 this.methods.add(this.generateConstructor()); var11 = this.proxyMethods.values().iterator(); while(var11.hasNext()) &#123; var12 = (List)var11.next(); var15 = var12.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.ProxyMethod var16 = (ProxyGenerator.ProxyMethod)var15.next(); this.fields.add(new ProxyGenerator.FieldInfo(var16.methodFieldName, &quot;Ljava/lang/reflect/Method;&quot;, 10)); this.methods.add(var16.generateMethod()); &#125; &#125; this.methods.add(this.generateStaticInitializer()); &#125; catch (IOException var10) &#123; throw new InternalError(&quot;unexpected I/O Exception&quot;, var10); &#125; if(this.methods.size() &gt; &#x27;\\uffff&#x27;) &#123; throw new IllegalArgumentException(&quot;method limit exceeded&quot;); &#125; else if(this.fields.size() &gt; &#x27;\\uffff&#x27;) &#123; throw new IllegalArgumentException(&quot;field limit exceeded&quot;); &#125; else &#123; this.cp.getClass(dotToSlash(this.className)); this.cp.getClass(&quot;java/lang/reflect/Proxy&quot;); var1 = this.interfaces; var2 = var1.length; for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; this.cp.getClass(dotToSlash(var4.getName())); &#125; this.cp.setReadOnly(); ByteArrayOutputStream var13 = new ByteArrayOutputStream(); DataOutputStream var14 = new DataOutputStream(var13); try &#123; var14.writeInt(-889275714); var14.writeShort(0); var14.writeShort(49); this.cp.write(var14); var14.writeShort(this.accessFlags); var14.writeShort(this.cp.getClass(dotToSlash(this.className))); var14.writeShort(this.cp.getClass(&quot;java/lang/reflect/Proxy&quot;)); var14.writeShort(this.interfaces.length); Class[] var17 = this.interfaces; int var18 = var17.length; for(int var19 = 0; var19 &lt; var18; ++var19) &#123; Class var22 = var17[var19]; var14.writeShort(this.cp.getClass(dotToSlash(var22.getName()))); &#125; var14.writeShort(this.fields.size()); var15 = this.fields.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.FieldInfo var20 = (ProxyGenerator.FieldInfo)var15.next(); var20.write(var14); &#125; var14.writeShort(this.methods.size()); var15 = this.methods.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.MethodInfo var21 = (ProxyGenerator.MethodInfo)var15.next(); var21.write(var14); &#125; var14.writeShort(0); return var13.toByteArray(); &#125; catch (IOException var9) &#123; throw new InternalError(&quot;unexpected I/O Exception&quot;, var9); &#125; &#125;&#125; 字节码生成后，调用defineClass0来解析字节码，生成了Proxy的Class对象。在了解完代理类动态生成过程后，生产的代理类是怎样的，谁来执行这个代理类。 其中，在ProxyGenerator.generateProxyClass函数中saveGeneratedFiles定义如下，其指代是否保存生成的代理类class文件，默认false不保存。 动态代理流程图如下：","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"线程池使用","slug":"concurrency/线程池的使用","date":"2018-09-12T14:59:32.000Z","updated":"2024-02-14T09:52:19.228Z","comments":false,"path":"2018/09/12/concurrency/线程池的使用/","permalink":"https://imalan6.github.io/hexo_blog/2018/09/12/concurrency/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"线程池的使用线程池作用 池化技术 池化技术就是提前保存大量资源，以备不时之需。在机器资源有限的情况下，使用池化技术可以大大提高资源利用率，提升性能等。在程序设计领域，比较典型的池化技术有：线程池、连接池、内存池、对象池等。 线程池作用 1）降低系统资源消耗。通过重用已存在的线程，降低线程创建和销毁造成的消耗； 2）提高系统响应速度。当有任务到达时，通过复用已存在的线程，无需等待新线程的创建便能立即执行； 3）提高线程的管控性。如果线程无限制的创建，可能会导致内存占用过多而产生OOM，并且会造成 cpu 过度切换，浪费 cpu 资源； 4）提供更强大灵活的功能。比如延时、定时线程池等。 使用场景在项目中我们可能需要多线程来处理一些业务，创建多线程可以通过继承Thread类或者实现Runnable接口实现，但不建议直接这样创建，容易造成资源浪费，也不方便线程管理。所以，我们需要通过线程池来创建多线程应用。 快速响应用户请求 针对快速响应用户请求的业务场景，我们应该从用户体验角度看，结果响应越快越好，如果一个页面半天都刷不出，用户可能就放弃查看这个商品了。另外，使用线程池也是有考量的，这种场景最重要的就是获取最大的响应速度去满足用户，所以应该不设置队列去缓冲并发任务，调高corePoolSize和maxPoolSize去尽可能创造多的线程快速执行任务。 快速处理批量任务 这种场景需要执行大量的任务，也应该使用多线程策略，进行并行计算。但与响应速度优先的场景区别在于，这类场景任务量巨大，不需要瞬时的完成，而是关注如何使用有限的资源，尽可能在单位时间内处理更多的任务，也就是吞吐量优先的问题。所以可以设置队列去缓冲并发任务，调整合适的corePoolSize设置处理任务的线程数。但设置的线程数过多可能会引发线程上下文切换频繁的问题，从而降低吞吐量。 使用方法 线程池中几个重要参数： 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 1）核心线程数 （corePoolSize）：线程池的基本大小，即在没有任务需要执行的时候线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。这里需要注意的是：在刚刚创建ThreadPoolExecutor的时候，线程并不会立即启动，而是要等到有任务提交时才会启动。 2）最大线程数 （maximumPoolSize）：线程池中的当前线程数目不会超过该值。如果队列中任务已满，并且当前线程个数小于maximumPoolSize，那么会创建新的线程来执行任务。 3）阻塞队列（workQueue）：线程池中的线程数量大于核心线程的数量，则将新建的任务加入到阻塞队列。 4）空闲线程的存活时间 (keepAliveTime)：线程空闲下来之后，线程的存活时间，超过这个时间还没有任务执行，则结束该线程。注意，这个回收是线程数大于核心线程数后回收，将多余的线程回收。 5）拒绝策略 (RejectedExecutionHandler)：当等待队列已满，线程数也达到最大线程数时，线程池会根据拒绝策略来执行后续操作，默认的策略是抛弃要加入的任务。 参数设置方案： 高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换。 并发不高、任务执行时间长的业务要区分开： 1）IO 密集型的任务，因为 IO 操作并不占用CPU，可以加大线程池中的线程数目，让CPU处理更多的业务。 2）CPU 密集型任务，线程池中的线程数设置得少一些，减少线程上下文的切换。 并发高、业务执行时间长，在于整体架构的设计，能否使用中间件对任务进行拆分和解耦。 四种简单的线程池： Java 通过 Executors 提供四种线程池，分别为： 1）newSingleThreadExecutor，创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序 (FIFO, LIFO, 优先级) 执行。 2）newFixedThreadPool，创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 3）newScheduledThreadPool，创建一个可定期或者延时执行任务的定长线程池，支持定时及周期性任务执行。 4）newCachedThreadPool，创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 其实看这几种线程池的源码就会发现： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 其实还是利用ThreadPoolExecutor类实现的。但是在实际项目开发中是推荐使用手动创建线程池的方式，而不采用 jdk 提供的默认方式，理由如下： 线程池创建实例 创建一个可缓存的线程池 1234567891011121314151617/** * 1.创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程&lt;br&gt; * 2.当任务数增加时，此线程池又可以智能的添加新线程来处理任务&lt;br&gt; * 3.此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小&lt;br&gt; */public static void cacheThreadPool() &#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 1; i &lt;= 10; i++) &#123; final int ii = i; try &#123; Thread.sleep(ii * 1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cachedThreadPool.execute(()-&gt;out.println(&quot;线程名称：&quot; + Thread.currentThread().getName() + &quot;，执行&quot; + ii)); &#125;&#125; 运行结果如下： 12345678910线程名称：pool-1-thread-1，执行1线程名称：pool-1-thread-1，执行2线程名称：pool-1-thread-1，执行3线程名称：pool-1-thread-1，执行4线程名称：pool-1-thread-1，执行5线程名称：pool-1-thread-1，执行6线程名称：pool-1-thread-1，执行7线程名称：pool-1-thread-1，执行8线程名称：pool-1-thread-1，执行9线程名称：pool-1-thread-1，执行10 基本工作原理 工作方式： 1）当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程； 2）当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行； 3）当workQueue已满，且maximumPoolSize &gt; corePoolSize时，新提交任务会创建新线程执行任务； 4）当提交任务数超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理； 5）当线程池中超过corePoolSize线程，空闲时间达到keepAliveTime时，释放空闲线程； 6）当设置allowCoreThreadTimeOut(true)时，该参数默认 false，线程池中corePoolSize线程空闲时间达到keepAliveTime也将关闭。 springboot 使用线程池目前，主流项目开发都是使用springboot了，如下是在springboot中使用线程池。 123456789101112@Configurationpublic class ThreadPoolConfig &#123; @Bean(value = &quot;threadPoolInstance&quot;) public ExecutorService createThreadPoolInstance() &#123; // 通过guava类库的 ThreadFactoryBuilder 来实现线程工厂类并设置线程名称 ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat(&quot;thread-pool-%d&quot;).build(); ExecutorService threadPool = new ThreadPoolExecutor(10, 16, 60L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(100), threadFactory, new ThreadPoolExecutor.AbortPolicy()); return threadPool; &#125;&#125; 主要是创建了一个线程池的bean，在使用时直接从Spring中取出使用即可，如下： 123456789101112131415//通过name=threadPoolInstance引用线程池实例@Resource(name = &quot;threadPoolInstance&quot;)private ExecutorService executorService;@Overridepublic void task() &#123; //TODO executorService.execute(new Runnable() &#123; @Override public void run() &#123; // 业务处理 &#125;&#125;);&#125; 使用 Callable与Task任务Runnable和Callable都可以理解为任务，里面封装这任务的具体逻辑，用于提交给线程池执行，区别在于Runnable任务执行没有返回值，且Runnable任务逻辑中不能通过throws抛出cheched异常(但是可以try catch)，而Callable可以获取到任务的执行结果返回值且抛出checked异常。 @FunctionalInterfacepublic interface Runnable { public abstract void run();} @FunctionalInterfacepublic interface Callable { V call() throws Exception;}Future和FutureTaskFuture接口用来表示执行异步任务的结果存储器，当一个任务的执行时间过长就可以采用这种方式：把任务提交给子线程去处理，主线程不用同步等待，当向线程池提交了一个Callable或Runnable任务时就会返回Future，用Future可以获取任务执行的返回结果。Future的主要方法包括： get()方法：返回任务的执行结果，若任务还未执行完，则会一直阻塞直到完成为止，如果执行过程中发生异常，则抛出异常，但是主线程是感知不到并且不受影响的，除非调用get()方法进行获取结果则会抛出ExecutionException异常；get(long timeout, TimeUnit unit)：在指定时间内返回任务的执行结果，超时未返回会抛出TimeoutException，这个时候需要显式的取消任务；cancel(boolean mayInterruptIfRunning)：取消任务，boolean类型入参表示如果任务正在运行中是否强制中断；isDone()：判断任务是否执行完毕，执行完毕不代表任务一定成功执行，比如任务执行失但也执行完毕、任务被中断了也执行完毕都会返回true，它仅仅表示一种状态说后面任务不会再执行了；isCancelled()：判断任务是否被取消；下面来实际演示Future和FutureTask的用法： public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService executorService &#x3D; Executors.newFixedThreadPool(10); Future future &#x3D; executorService.submit(new Task()); Integer integer &#x3D; future.get(); System.out.println(integer); executorService.shutdown(); } static class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(&quot;子线程开始计算&quot;); int sum = 0; for (int i = 0; i &lt;= 100; i++) &#123; sum += i; &#125; return sum; &#125; &#125; public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService executorService &#x3D; Executors.newFixedThreadPool(10); FutureTask futureTask &#x3D; new FutureTask&lt;&gt;(new Task()); executorService.submit(futureTask); Integer integer &#x3D; futureTask.get(); System.out.println(integer); executorService.shutdown(); } static class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(&quot;子线程开始计算&quot;); int sum = 0; for (int i = 0; i &lt;= 100; i++) &#123; sum += i; &#125; return sum; &#125; &#125;","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"LinkedList 底层分析","slug":"collections/LinkedList","date":"2018-09-01T05:11:06.000Z","updated":"2024-02-14T09:43:17.410Z","comments":false,"path":"2018/09/01/collections/LinkedList/","permalink":"https://imalan6.github.io/hexo_blog/2018/09/01/collections/LinkedList/","excerpt":"","text":"LinkedList 底层分析 如图所示 LinkedList 底层是基于双向链表实现的，也是实现了 List 接口，所以也拥有 List 的一些特点(JDK1.7&#x2F;8 之后取消了循环，修改为双向链表)。 新增方法123456789101112131415161718public boolean add(E e) &#123; linkLast(e); return true;&#125; /** * Links e as last element. */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; 可见每次插入都是移动指针，和 ArrayList 的拷贝数组来说效率要高上不少。 查询方法1234567891011121314151617181920public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 上述代码，利用了双向链表的特性，如果index离链表头比较近，就从节点头部遍历。否则就从节点尾部开始遍历。使用空间（双向链表）来换取时间。 node()会以O(n/2)的性能去获取一个结点 如果索引值大于链表大小的一半，那么将从尾结点开始遍历 这样的效率是非常低的，特别是当 index 越接近 size 的中间值时。 总结： LinkedList 插入，删除都是移动指针效率很高。 查找需要进行遍历查询，效率较低。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"volatile 关键字","slug":"concurrency/volatile关键字","date":"2018-08-16T05:22:32.000Z","updated":"2024-02-14T09:52:19.205Z","comments":false,"path":"2018/08/16/concurrency/volatile关键字/","permalink":"https://imalan6.github.io/hexo_blog/2018/08/16/concurrency/volatile%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"volatile 关键字原子性、可见性和有序性Java 内存模型主要是围绕着线程并发过程中如何处理原子性、可见性和顺序性这三个特征来设计的。 原子性 原子性表示任意时刻只有一个线程可以执行某一段功能代码，以防止多个线程同时访问某些共享数据时，造成错误。 可见性 可见性是指一个线程修改了某个共享变量后，其他线程能够立刻访问到被修改后的最新数据，也就是共享数据对其他线程都是可见的。volatile修饰的变量在修改后会立即同步到主内存，在使用时会重新从主内存中读取。volatile变量是依赖主内存为中介来保证多线程下变量对其他线程的可见性。 synchronized关键字是通过在unlock之前必须把变量同步回主内存来实现可见性的。 final关键字则是因为变量在初始化后，值就不会更改，所以只要在初始化过程中没有把this指针传递出去也能保证对其他线程的可见性。 有序性 程序在运行时，指令的执行顺序并不是严格按照从上到下顺序执行的，可能会进行指令重排。根据CPU流水线作业，一般来说，简单的操作会先执行，复杂的操作后执行。 有序性从不同的角度来看是不同的。单纯从单线程来看都是有序的，但到了多线程就不一样了。可以这么理解，如果在一个线程内部观察，所有操作都是有序的。但是如果在一个线程内观察另一个线程，操作可能是无序的。也就是CPU进行的指令重排序对单线程程序而言，不会有什么问题，但是对于多线程程序，就可能出现问题。而有序性就是防止指令重排序带来的问题。 Java 内存模型 内存模型产生原因 Java 存在一个线程可见性的问题，是由于Java内存模型的原因。 Java 是跨平台语言，可以支持不同的硬件平台，这是Java虚拟机的功劳。Java 内存模型(Java Memory Model，JMM)是 Java 虚拟机规范定义的，用来屏蔽掉 Java 程序在各种不同硬件和操作系统对内存访问的差异，这样就可以实现 Java 程序在各种不同的硬件平台上都能达到内存访问的一致性。可以避免像c、c++等直接使用物理硬件和操作系统的内存模型在不同操作系统和硬件平台下的不兼容。比如有些c/c++程序在windows平台运行正常，而在linux平台运行就会出问题。 内存模型概念 虽然 Java 程序运行在 Java 虚拟机上面，内存等是虚拟机的一部分，但实际也是使用的物理机的，只不过是Java虚拟机屏蔽了底层硬件细节，统一做了处理。Java 内存模型的主要目标是定义程序中变量的访问规则，即在 Java 虚拟机中将变量存储到主内存或将变量从主内存中取出这样的底层细节。需要注意的是这里的变量跟 Java 程序中的变量不是完全等同的。这里的变量是指实例字段，静态字段，构成数组对象的元素，但是不包括线程内部的局部变量和方法参数，因为这是线程私有的。 这里可以简单的认为，主内存是 Java 虚拟机内存区域中的堆，局部变量和方法参数是在虚拟机栈中定义的。但是在堆中的变量如果在多线程中使用，就涉及到了堆和不同虚拟机栈中变量的值的一致性问题了。 Java 内存模型概念： 主内存：Java 虚拟机规定所有的变量都必须在主内存中产生，为了方便理解，可以认为是堆区。与前面说的物理机的主内存相比，物理机的主内存是整个机器的内存，而虚拟机的主内存是虚拟机内存中的一部分。 工作内存：Java 虚拟机中每个线程都有自己的工作内存，该内存是线程私有的，为了方便理解，可以认为是虚拟机栈。线程的工作内存保存了线程需要的变量在主内存中的副本。 Java 虚拟机规定，线程对主内存共享变量的操作必须在线程的各自的工作内存中进行，不能直接读写主内存中的变量。不同的线程之间也不能相互访问对方的工作内存。如果线程之间需要传递变量的值，必须通过主内存来作为中介进行传递。这里需要说明一下，Java 内存模型是一个抽象概念，其实并不存在，它描述的是一种规范。类似下图： volatile 和 synchronized 区别 volatile volatile关键字修饰的变量可以保证可见性和有序性。volatile类型的变量在修改后会立即同步到主内存，在使用的时候会从主内存中重新读取，是依赖主内存为中介来保证多线程下变量对其他线程的可见性的。而volatile禁止了指令重排序，从而保证指令的有序性。线程访问volatile变量时，能够获取到最新值，但volatile变量并不能用于线程同步。 volatile 和 synchronized 的区别 synchronized用于线程同步，但是和volatile不一样，synchronized可以保证原子性、可见性和有序性。 使用场景 状态标识 比如用一个变量作为状态标识来控制多个线程协同工作。每个线程通过判断状态标识的值来确定是否执行相关代码。那这个状态标识的变量就可以使用volatile关键字修饰，以确保当某个线程更新了变量的值之后，其他的线程可以立即获得最新的值。 双重检查锁定 在单例模式中，对单例对象需要使用volatile关键字进行修饰。这是因为，线程缺乏同步，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。 1234567891011121314private volatile static Singleton instace; public static Singleton getInstance()&#123; //第一次null检查 if(instance == null)&#123; synchronized(Singleton.class) &#123; //第二次null检查 if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125; 一个线程写，多个线程读 volatile很适用一个线程写，多个线程读的场合。比如，类似发布订阅的机制，当一个写线程更新volatile变量值的话，其他读线程可以立即获取到最新值。 volatile 和 synchronized 实现 “ 低开销读 - 写锁 ” 如下显示的线程安全的计数器，使用synchronized确保增量操作是原子的，并使用volatile保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及volatile读操作，这通常要优于一个无竞争的锁获取的开销。 1234567891011121314public class CheesyCounter &#123; private volatile int value; //读操作，无需synchronized，提高性能 public int getValue() &#123; return value; &#125; //写操作，必须synchronized。因为x++不是原子操作 public synchronized int increment() &#123; return value++; &#125; &#125;","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"synchronized 关键字原理","slug":"concurrency/synchronized关键字原理","date":"2018-08-03T14:13:22.000Z","updated":"2024-02-14T09:52:19.158Z","comments":false,"path":"2018/08/03/concurrency/synchronized关键字原理/","permalink":"https://imalan6.github.io/hexo_blog/2018/08/03/concurrency/synchronized%E5%85%B3%E9%94%AE%E5%AD%97%E5%8E%9F%E7%90%86/","excerpt":"","text":"synchronized 关键字原理在Java中，synchronized是我们罪常使用的锁，但在 JDK1.5之前synchronized是一个重量级锁，相对于 juc 包中的Lock，显得比较笨重。在 Java 6 之后 Java 官⽅从 JVM 层⾯对synchronized进行了大量优化，使得synchronized锁效率提高了很多。 锁使用 synchronized 作用 1）原子性：所谓原子性就是指一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。被synchronized修饰的类或对象的所有操作都是原子的，因为在执行操作之前必须先获得类或对象的锁，直到执行完才能释放。 2）可见性：可见性是指多个线程访问一个资源时，该资源的状态、值信息等对于其他线程都是可见的。synchronized和volatile都具有可见性，其中synchronized对一个类或对象加锁时，一个线程如果要访问该类或对象必须先获得它的锁，而这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到共享内存当中，保证资源变量的可见性。 3）有序性：有序性是指程序执行的顺序按照代码先后执行。synchronized和volatile都具有有序性，Java 允许编译器和处理器对指令进行重排，但是指令重排并不会影响单线程的顺序，它影响的是多线程并发执行的顺序性。synchronized保证了每个时刻都只有一个线程访问同步代码块，也就确定了线程执行同步代码块是分先后顺序的，保证了有序性。 synchronized 使用方法 1）修饰实例方法：对当前对象实例加锁，进入同步方法前要获得当前对象实例的锁。 123synchronized void method() &#123; //业务代码&#125; 2）修饰静态方法：也就是对当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 当前class的锁。因为静态成员不属于任何一个实例对象，是类成员，近属于类。类对象（class）的锁和new出来的实例对象的锁是不同的。当一个线程 A 调用一个实例对象的非静态synchronized方法，而线程 B 调用这个实例对象所属类的静态synchronized方法时，这种情况是允许的，不会发生互斥现象，因为访问静态synchronized方法占用的锁是当前类的锁，而访问非静态synchronized方法占用的锁是new出来的实例对象锁，二者是不同的。 123synchronized void staic method() &#123; //业务代码&#125; 3）修饰代码块 ：指定加锁对象，对给定对象&#x2F;类加锁。synchronized(object)表示进入同步代码库前要获得指定对象object的锁。synchronized(类.class)表示进入同步代码前要获得指定类class对象的锁 123synchronized(this) &#123; //业务代码&#125; 总结 synchronized关键字加到static静态方法和synchronized(class)代码块上都是是给 class 类加锁。synchronized关键字加到实例方法上是给对象实例加锁。如下是synchronized的使用实例： 1234567891011121314151617181920public class Singleton &#123; //保证有序性，防止指令重排 private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) &#123; //类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 锁特性 可重入性 synchronized是可重入锁。当一个线程再次请求自己已经持有的对象锁的临界资源时，这种情况属于重入锁。在 java 中synchronized是基于原子性的内部锁机制的，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象的另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁时，是可以的。这就是synchronized的可重入性。 不可中断 1） 不可中断的意思是等待获取锁的时候不可中断，拿到锁之后可中断，没获取到锁的情况下，中断操作一直不会生效。如下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142public class Test &#123; private static Object obj = new Object(); public static void main(String[] args) throws InterruptedException &#123; Runnable run = () -&gt; &#123; synchronized (obj) &#123; String name = Thread.currentThread().getName(); System.out.println(name + &quot;进入同步代码块&quot;); // 保证不退出同步代码块 try &#123; Thread.sleep(100000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; // 开启两个线程执行同步代码块 Thread t0 = new Thread(run); Thread t1 = new Thread(run); t0.start(); t1.start(); Thread.sleep(1000); // t0线程获得锁，t1处于阻塞状态，向t1发送中断信号 System.out.println(&quot;直接向t1发送中断信号...&quot;); t1.interrupt(); Thread.sleep(1000); System.out.println(&quot;t0线程状态：&quot; + t0.getState()); System.out.println(&quot;t1线程状态：&quot; + t1.getState()); // 先向t0发送中断信号，再向t1发送中断信号 System.out.println(&quot;\\n先向t0发送中断信号，再向t1发送中断信号&quot;); t0.interrupt(); Thread.sleep(1000); t1.interrupt(); Thread.sleep(1000); System.out.println(&quot;t0线程状态：&quot; + t0.getState()); System.out.println(&quot;t1线程状态：&quot; + t1.getState()); &#125;&#125; 运行结果： 123456789101112131415161718192021Thread-0进入同步代码块直接向t1发送中断信号...t0线程状态：TIMED_WAITINGt1线程状态：BLOCKED先向t0发送中断信号，再向t1发送中断信号java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at com.alanotes.demo.Test.lambda$main$0(Test.java:21) at com.alanotes.demo.Test$$Lambda$1/2129789493.run(Unknown Source) at java.lang.Thread.run(Thread.java:745)Thread-1进入同步代码块java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at com.alanotes.demo.Test.lambda$main$0(Test.java:21) at com.alanotes.demo.Test$$Lambda$1/2129789493.run(Unknown Source) at java.lang.Thread.run(Thread.java:745)t0线程状态：TERMINATEDt1线程状态：TERMINATEDProcess finished with exit code 0 从上面的运行结果可以看出： 当线程 t0 拥有锁，而线程 t1 没有获得锁时，直接向线程 t1 发送中断信号，线程 t1 的状态没有改变，仍然是阻塞状态，说明线程在没有获得锁的阻塞状态下不可被中断； 当先向线程 t0 发送中断信号，再向线程 t1 发送中断信号时，线程 t0 被中断了，后面 t1 也被中断了。这是因为先获得锁的 t0 被中断了，释放了锁，t1 获得了锁，后面又接收到中断信号，也被中断了。 以上结论说明，线程等待获取锁的时候不可被中断，但是获取到锁之后可被中断。 2）我们常说synchronized不可以被中断，并不指synchronized方法不可中断，比如执行如下代码： 1234567891011121314151617181920212223242526272829public class Test &#123; public synchronized void foo() throws InterruptedException &#123; System.out.println(&quot;foo begin&quot;); for (int i =0; i &lt; 100; i++) &#123; System.out.println(&quot;foo ...&quot;); Thread.sleep(1000); &#125; &#125; public static void main(String[] args) &#123; Test it = new Test(); ExecutorService es = Executors.newCachedThreadPool(); es.execute(() -&gt; &#123; try &#123; it.foo(); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;foo is interrupted, msg=&quot; + e.getMessage()); &#125; &#125;); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; es.shutdownNow(); // 关闭线程池，会给线程池中的线程发送中断信号 System.out.println(&quot;Main end&quot;); &#125;&#125; 运行结果如下： 12345678foo beginfoo ...foo ...foo ...foo is interrupted, msg=sleep interruptedMain endProcess finished with exit code 0 从上面的运行结果可以看出，当主线程执行es.shutdownNow()代码关闭线程池时，子线程被中断了，说明synchronized方法可以被中断。但是，当修改 synchronized 方法的代码如下，去掉 throws InterruptedException 声明。 123456789101112131415161718192021222324252627282930313233public class Test &#123; public synchronized void foo() &#123; System.out.println(&quot;foo begin&quot;); for (int i =0; i &lt; 100; i++) &#123; System.out.println(&quot;foo ...&quot;); try &#123; Thread.sleep(1000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; Test it = new Test(); ExecutorService es = Executors.newCachedThreadPool(); es.execute(() -&gt; &#123; try &#123; it.foo(); &#125; catch (Exception e) &#123; System.out.println(&quot;foo is interrupted, msg=&quot; + e.getMessage()); &#125; &#125;); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; es.shutdownNow(); System.out.println(&quot;Main end&quot;); &#125;&#125; 运行结果如下： 12345678910111213141516171819foo beginfoo ...foo ...foo ...Main endjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at com.alanotes.demo.Test.foo(Test.java:16) at com.alanotes.demo.Test.lambda$main$0(Test.java:27) at com.alanotes.demo.Test$$Lambda$1/363771819.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)foo ...foo ...foo ...foo ...foo ...foo ... 当子线程接收到中断信号后，仍在继续执行。说明synchronized方法没有被中断。 根据 Java 文档，判断方法很简单：只要调用的方法抛出 InterruptedException 异常，那么它就可以被中断。不抛出 InterruptedException 的方法是不可中断的。 同步原理synchronized 锁的实现是依赖底层 JVM 的。 synchronized 同步语句块原理 1234567public class SynchronizedDemo &#123; public void sync() &#123; synchronized (this) &#123; // 业务代码 &#125; &#125;&#125; 编写如上测试代码，通过 JDK 自带的javap命令查看SynchronizedDemo类的相关字节码信息。首先切换到类的对应目录执行javac SynchronizedDemo.java命令生成编译后的 .class 类文件，然后执行javap -c -s -v -l SynchronizedDemo.class命令。得到如下指令： 从上图可以看出： synchronized同步语句块的实现是使用了monitorenter和monitorexit指令。其中monitorenter指令指向同步代码块的开始位置，monitorexit指令指向同步代码块的结束位置。当执行monitorenter指令时，线程试图获取锁，也就是获取对象监视器monitor的所有权。 在 Java 虚拟机 (HotSpot) 中，每个对象中都内置了一个monitor监视器锁。另外，wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步代码块或者同步方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException异常的原因。 在执行monitorenter时，会尝试获取对象的锁，如果锁的计数器为0，则表示锁可以被获取，获取后将锁计数器加1。在执行monitorexit指令后，将锁计数器减1，如果计数器的值变为0，表明锁被释放。 如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 另外，从上图可以看出，monitorexit指令出现了两次，第1次为同步正常退出释放锁，第2次为发生异常退出释放锁。这其实也是synchronized的优点：无论代码执行情况如何，都不会忘记主动释放锁。 synchronized 修饰方法原理 12345public class SynchronizedDemo &#123; public synchronized void sync() &#123; // 业务代码 &#125;&#125; 根据上面同样的步骤，反编译一下： synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法。JVM 通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 总结 synchronized同步语句块的实现使用的是monitorenter和monitorexit指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置。 synchronized修饰方法使用的是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法。 两者的本质都是获取对象监视器monitor的所有权。 同步概念 Java 对象头 在 JVM 中，对象在内存中的划分为三块区域：对象头、实例数据和对齐填充。synchronized用的锁就存在 Java 对象头里。 对象头由两部分组成： Mark Word：存储自身的运行时数据，例如 HashCode、GC 年龄、锁相关信息等内容。 Klass Pointer：类型指针指向它的类元数据的指针。 64 位虚拟机 Mark Word 是 64bit，在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。 监视器（monitor） 任何一个对象都有一个 monitor 与之关联，当 monitor 被获取后，它将处于锁定状态。synchronized 在 JVM 里的实现都是基于进入和退出 monitor 对象来实现方法和代码块同步的，虽然具体实现细节不一样，但是都可以通过成对的 monitorenter 和 monitorexit 指令来实现。 当使用 synchronized 获取对象锁，MarkWord 锁标识位置为10，其中指针指向的是 monitor 对象的起始地址。在 Java 虚拟机（HotSpot）中，monitor 是由ObjectMonitor 实现的。 锁优化（锁升级）因为monitor依赖操作系统的 Mutex lock 实现，是一个比较重的操作，需要切换系统至内核态，开销非常大。从 JDK6 开始，对synchronized的实现机制进行了较大调整，包括使用 JDK5 引进的 CAS 自旋之外，还增加了自适应的 CAS 自旋、锁消除、锁粗化、偏向锁、轻量级锁这些优化策略。由于synchronized关键字的优化使得性能极大提高，同时语义清晰、操作简单、无需手动释放锁，所以推荐尽量使用synchronized关键字加锁。 synchronized 有四种状态：无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁。锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。但是锁只能升级，不能降级。 无锁 没有对资源进行锁定，所有线程都能访问和修改，但同时只有一个线程能修改成功。 偏向锁 偏向锁是 JDK6 中的重要概念，因为经过实践发现，大多数情况下锁被多个线程竞争的情况不多，相反总是由同一线程多次获得，为了让线程获得锁的代价更低，引进了偏向锁。因为轻量级锁的加锁解锁操作是需要依赖多次CAS 原子指令的，而偏向锁只需要在置换 ThreadID 的时候依赖一次CAS原子指令。 当一个线程获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行 CAS 操作来加锁和解锁，只需简单地测试一下对象头的里是否存储着指向当前线程的偏向锁。如果存在，表示线程已经获得了锁。 如果不存在，则需要再测试一下 Mark Word 中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用 CAS 竞争锁；如果设置了，则尝试使用CAS 将对象头的偏向锁指向当前线程。 偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着， 如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的 Mark Word 要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。流程如下图所示： 偏向锁是在单线程执行代码块时使用的机制，如果在多线程并发的环境下（即线程A尚未执行完同步代码块，线程B发起了申请锁的申请），则一定会转化为轻量级锁或者重量级锁。偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。 因为偏向锁的撤销操作还是比较重的，在线程竞争资源比较激烈的情况下会影响性能，可以使用-XX:-UseBiasedLocking=false禁用偏向锁。 轻量级锁 引入轻量级锁的主要目的是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁。 1）轻量级锁加锁 线程在执行同步块之前，JVM 会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的 Mark Word 复制到锁记录中，官方称为 Displaced Mark Word。然后线程尝试使用 CAS 将对象头中的 Mark Word 替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 2）轻量级锁解锁 轻量级解锁时，会使用原子的 CAS 操作将 Displaced Mark Word 替换回到对象头。如果成功，则表示没有竞争发生；如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。 下图是两个线程同时争夺锁，导致锁膨胀的流程图： 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时， 都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 锁的优缺点比较 各种锁在不同场景下有不同的选择。每种锁是只能升级，不能降级，即由偏向锁 —&gt; 轻量级锁 —&gt; 重量级锁，而这个过程就是开销逐渐加大的过程。 如果是单线程使用，那偏向锁毫无疑问代价最小，并且它就能解决问题，连 CAS 都不用做，仅仅在内存中比较下对象头就可以了； 如果出现了其他线程竞争，则偏向锁就会升级为轻量级锁； 如果其他线程通过一定次数的 CAS 尝试没有成功，则进入重量级锁； 锁的优缺点如下表： 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法仅有纳米级的差距 如果线程间存在锁的竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问的同步块场景 轻量级锁 竞争的线程不会阻塞，提高了程序的相应速度 如果始终得不到锁竞争的线程，使用自旋会消耗 CPU 追求响应时间，同步响应非常快 重量级锁 线程竞争不使用自旋，不会消耗 CPU 线程阻塞，响应时间慢 追求吞吐量，同步块执行时间较长","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Redis+Token实现接口幂等性","slug":"cache/Redis实现接口幂等性方案","date":"2018-07-19T14:13:32.000Z","updated":"2024-02-14T10:02:31.759Z","comments":false,"path":"2018/07/19/cache/Redis实现接口幂等性方案/","permalink":"https://imalan6.github.io/hexo_blog/2018/07/19/cache/Redis%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7%E6%96%B9%E6%A1%88/","excerpt":"","text":"Redis+Token实现接口幂等性幂等性概念任意多次请求执行所产生的效果与一次执行的效果相同。也就是说对系统的影响只能是一次性的，不能重复执行处理。但在实际项目环境中，一个对外服务的接口可能会面临很多次重复的请求，比如： 前端重复提交。用户多次点击提交按钮，导致重复提交数据。 消息重复消费。一般指的是消息中间件，如RabbitMQ，由于网络抖动，MQ Broker将消息发送给消费端消费，消费端进行了消费，但在返回ACK给MQ Broker时网络中断，导致MQ Broker认为消费端没能正常消费消息，MQ Broker重发消息。 页面回退再次提交。比如，用户购买商品时，如果第一次下单成功，这时候用户点击浏览器返回按钮，返回上一个下单页面，再次点击下单，就会导致重复提交。 网络延迟或阻塞。微服务之间通信出现网络延迟或阻塞，导致请求失败，如feign可能触发重试机制，这就可能导致被调用服务收到多份请求数据； 为了避免以上这些情况，都要求后端接口必须实现幂等性，能够对重复的请求数据进行处理，不然可能出现业务问题。 解决方案实现接口幂等性通常有如下方案： 数据库唯一索引。在数据表中，为请求数据的唯一标识建立唯一索引，可以防止表中插入相同数据。比如：在订单表中为订单id建立唯一索引。这样，即使有重复的订单提交请求，也只能插入一条。 防重数据表。使用请求数据的唯一字段作为去重表的唯一索引，把唯一字段插入去重表后再进行业务操作，并保证操作都在同一事务中。因为去重表有唯一约束，如果是重复请求，会插入失败，解决了幂等问题。这里要注意的是，去重表和业务表应该在同一个数据库中，这样保证在同一个事务里，即使业务操作失败，也会把去重表的数据进行回滚。保证了数据的一致性。 Token机制。Token机制是目前应用较多的接口幂等性方案。每次接口请求前先获取一个Token，然后在请求业务时带上这个Token，服务端进行验证，如果验证通过删除Token，下次请求再次判断Token。详见第二部分。 Redis的SETNX防重。服务端将请求的唯一标识用SETNX方式存入Redis，并设置超时时间。如果存入成功，则继续做后续业务请求；如果存入失败，则代表已经执行过当前请求。 数据库乐观锁。数据库中增加版本号字段，每次更新通过版本号来判断。如果有线程已经更新了version字段，其余线程执行sql操作就会失败。方式如下： 12345#客户端请求服务端，首先查询当前的version版本select version from … where …#根据version版本执行操作UPDATE … SET … version=(version+1) WHERE … AND version=version 数据库悲观锁。执行select加上for update语句，其他并发线程执行时会发生互斥，需要等待行锁释放，从而防止同一条数据被重复线程处理。 1234START TRANSACTION; #开启事务SELETE * FROM TABLE WHERE ... FOR UPDATE;UPDATE TABLE SET ... WHERE ...;COMMIT; #提交事务 业务层锁机制。如果多个线程可能在同一时间处理相同的数据，比如多个线程在同一时刻都拿到了相同的数据处理，可以加锁访问（根据是否分布式系统采用JVM锁或者分布式锁），处理完成后释放锁。获取到锁的先查询数据库判断数据是否已经被处理过。 Redis+Token机制实现原理Token机制配合Redis处理接口幂等性问题是业界用的比较多的一种方式。简单理解，就是每次请求都拿着一张门票，这个门票是一次性的，用过一次就被毁掉了，不能重复利用。Token令牌就相当于门票的概念，每次请求业务接口之前先获取Token，然后访问业务接口时带上刚获取的Token令牌。服务器处理请求的时候校验Token，校验通过就继续处理业务，否则返回error。这个Token只能用一次，如果客户端使用相同的令牌再次请求，那么就不处理，直接返回。大致流程如下图所示： 主要步骤如下： 1）用户端根据业务类型，调用Token接口获取相应Token； 2）服务端生成Token，并把Token保存到redis中，然后向用户端返回Token； 3）用户端携带Token访问业务接口，Token一般在请求参数或者请求头中传递； 4）服务端判断Token是否存在Redis中，如果存在表示是第一次请求，然后删除Token，继续执行下面的业务处理； 5）用户端如果短时间内重复提交请求，因为两次请求携带的Token是一样的，所以第二次请求时，服务器校验Token时，Redis中的Token已经被删除掉，这就表示是重复操作，所以第二次请求会校验失败，这就保证了重复请求不会被执行； 注意： 不过Token方案也需要注意： 是先删除Token再处理业务，还是先处理业务再删除Token。 如果先删除Token再处理业务，可能导致删除了Token，但是业务还没有执行，服务器崩溃了。由于防重设计导致，其他请求都不能执行； 如果先处理业务再删除Token，可能导致业务处理成功，但删除Token失败，防重设计失效。其他线程可能继续执行业务，导致业务被重复执行，后果很严重； 考虑到对业务影响的严重级别，最好设计为先删除Token再处理业务。如果业务处理失败，用户端重新获取Token再次请求处理。 获取Token，比较和删除操作必须保证原子性。 redis.get(token)，token.equals()，redis.del(token)，获取&#x2F;比较&#x2F;删除，这三个操作并不是原子性的，可能导致高并发情况下，多个线程同时获取并处理到同样的数据。可以在redis中使用lua脚本保证操作的原子性。 1if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end 也可以采用锁机制，以Token字段上锁，比如synchronized(Token)，或者分布式锁。既互斥访问，同时也兼顾性能。 代码实现实现一个方法添加@Idempotent注解后自动进行幂等性处理。 1）Token服务接口 创建一个Token服务接口，包含两个方法：创建token和验证token。创建token采用随机生成的字符串，而验证token就是从请求中取出token，检查并删除redis中对应的token。代码如下： 12345678910111213141516public interface TokenService &#123; /** * 创建token * @return */ public String createToken(); /** * 检验token * @param request * @return */ public boolean checkToken(HttpServletRequest request) throws Exception;&#125; 服务实现类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Servicepublic class TokenServiceImpl implements TokenService &#123; @Autowired private RedisService redisService; /** * 创建token * * @return */ @Override public String createToken() &#123; String str = RandomUtil.randomUUID(); StrBuilder token = new StrBuilder(); try &#123; token.append(Constant.Redis.TOKEN_PREFIX).append(str); //设置过期时间为600秒,具体视业务而定 redisService.setEx(token.toString(), token.toString(), 600L); boolean notEmpty = StrUtil.isNotEmpty(token.toString()); if (notEmpty) &#123; return token.toString(); &#125; &#125;catch (Exception ex)&#123; ex.printStackTrace(); &#125; return null; &#125; /** * 检验token * * @param request * @return */ @Override public boolean checkToken(HttpServletRequest request) throws Exception &#123; String token = request.getHeader(Constant.TOKEN_NAME); if (StrUtil.isBlank(token)) &#123;// header中不存在token token = request.getParameter(Constant.TOKEN_NAME); if (StrUtil.isBlank(token)) &#123;// parameter中也不存在token throw new ServiceException(Constant.ResponseCode.ILLEGAL_ARGUMENT, 100); &#125; &#125; if (!redisService.exists(token)) &#123; throw new ServiceException(Constant.ResponseCode.REPETITIVE_OPERATION, 200); &#125; boolean remove = redisService.remove(token); if (!remove) &#123; throw new ServiceException(Constant.ResponseCode.REPETITIVE_OPERATION, 200); &#125; return true; &#125;&#125; 3）自定义注解 自定义一个注解，把它添加在需要实现幂等的方法上，凡是添加了该注解的方法，都会实现幂等性检查。 12345@Target(&#123;ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface Idempotent &#123; &#125; 4）配置SpringMVC拦截器，对添加了注解方法的请求进行拦截处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * 拦截器 */@Componentpublic class IdempotentInterceptor implements HandlerInterceptor &#123; @Autowired private TokenService tokenService; /** * 预处理 * * @param request * @param response * @param handler * @return * @throws Exception */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (!(handler instanceof HandlerMethod)) &#123; return true; &#125; HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); //检查是否存在Idempotment注解 AutoIdempotent methodAnnotation = method.getAnnotation(Idempotent.class); if (methodAnnotation != null) &#123; try &#123; // 幂等性校验, 校验通过则放行, 校验失败则抛出异常, 并通过统一异常处理返回友好提示 return tokenService.checkToken(request); &#125;catch (Exception ex)&#123; ResultVo failedResult = ResultVo.getFailedResult(101, ex.getMessage()); writeReturnJson(response, JSONUtil.toJsonStr(failedResult)); throw ex; &#125; &#125; //必须返回true,否则会被拦截一切请求 return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125; /** * 返回的json值 * @param response * @param json * @throws Exception */ private void writeReturnJson(HttpServletResponse response, String json) throws Exception&#123; PrintWriter writer = null; response.setCharacterEncoding(&quot;UTF-8&quot;); response.setContentType(&quot;text/html; charset=utf-8&quot;); try &#123; writer = response.getWriter(); writer.print(json); &#125; catch (IOException e) &#123; &#125; finally &#123; if (writer != null) writer.close(); &#125; &#125;&#125; 5）创建配置类将IdempotentInterceptor拦截器注册到拦截器链中 12345678910111213141516@Configurationpublic class WebConfiguration extends WebMvcConfigurerAdapter &#123; @Resource private IdempotentInterceptor idempotentInterceptor; /** * 添加拦截器 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(idempotentInterceptor); super.addInterceptors(registry); &#125;&#125; 6）创建一个controller类 1234567891011121314151617181920212223242526@RestController(&quot;/test&quot;)public class TestController &#123; @Resource private TokenService tokenService; @PostMapping(&quot;/token&quot;) public String getToken()&#123; String token = tokenService.createToken(); if (StrUtil.isNotEmpty(token)) &#123; ResultVo resultVo = new ResultVo(); resultVo.setCode(Constant.code_success); resultVo.setMessage(Constant.SUCCESS); resultVo.setData(token); return JSONUtil.toJsonStr(resultVo); &#125; return StrUtil.EMPTY; &#125; @Idempotent @PostMapping(&quot;/idempotence&quot;) public String testIdempotence() &#123; return &quot;success&quot;; &#125;&#125; 7）测试 首先，使用postman发送请求，访问/test/token接口获取到token。 然后，再使用postman访问/test/idempotence接口，并把上一步获取到的token放到请求的header中。可以看到返回success字符串，表示访问成功。 最后，再重复上一步，发送多次请求，提示访问失败，表示重复请求已被防重设计拦截。","categories":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"缓存","slug":"缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"过滤器和拦截器","slug":"java_others/过滤器和拦截器","date":"2018-07-18T11:56:32.000Z","updated":"2024-02-14T09:59:33.131Z","comments":false,"path":"2018/07/18/java_others/过滤器和拦截器/","permalink":"https://imalan6.github.io/hexo_blog/2018/07/18/java_others/%E8%BF%87%E6%BB%A4%E5%99%A8%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8/","excerpt":"","text":"过滤器和拦截器过滤器功能Servlet中的过滤器Filter是实现了javax.servlet.Filter接口的服务器端程序，主要的用途是过滤字符编码和做一些业务逻辑判断等。在Java web中，对传入的request、response提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者Controller进行业务逻辑操作。 Filter依赖于servlet容器。在实现上，它基于函数回调，可以对几乎所有请求进行过滤。只要在web.xml文件配置好要过滤的客户端请求，就可以对请求或响应(Request、Response)统一设置编码。Filter也可以进行逻辑判断，如用户是否已经登录，有没有权限访问页面等。Filter是随web应用启动而启动的，只初始化一次，以后就可以过滤相关的请求，只有当web应用停止或重新部署的时候才能销毁。 在javax.servlet.Filter接口中定义了3个方法： void init()：用于过滤器初始化 void destroy()：用于过滤器销毁前，完成某些资源的回收 void doFilter()：实现过滤功能，该方法对每个请求增加额外的处理 web.xml配置文件： 1234567891011121314&lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;!-- &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; --&gt; &lt;filter-class&gt;com.cn.util.FilterUtil&lt;/filter-class&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 应用场景主要是用来做一些过滤操作，获取想要获取的数据。通常用的场景是：在过滤器中修改字符编码（CharacterEncodingFilter），在过滤器中修改HttpServletRequest的一些参数（XSSFilter自定义过滤器），如：过滤低俗文字、危险字符等。 应用实例在Filter中设置编码 1234567891011121314151617181920212223242526272829public class MyFilter implements Filter&#123; @SuppressWarnings(&quot;unused&quot;) private FilterConfig filterConfig; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; this.filterConfig = filterConfig; log.info(&quot;过滤器Filter初始化&quot;); &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; if (!(request instanceof HttpServletRequest) || !(response instanceof HttpServletResponse)) &#123; throw new ServletException(&quot;just supports HTTP requests&quot;); &#125; HttpServletRequest httpRequest = (HttpServletRequest) request; HttpServletResponse httpResponse = (HttpServletResponse) response; httpRequest.setCharacterEncoding(this.filterConfig.getInitParameter(&quot;encoding&quot;)); httpResponse.setCharacterEncoding(this.filterConfig.getInitParameter(&quot;encoding&quot;)); chain.doFilter(httpRequest, httpResponse); &#125; @Override public void destroy() &#123; log.info(&quot;过滤器Filter销毁&quot;); &#125; &#125; 拦截器功能拦截器就是在service或者一个方法前调用一个方法，或者在方法后调用一个方法，比如动态代理就是拦截器的简单实现，在调用方法前打印出字符串或者做其它业务逻辑的操作。 拦截器依赖于web框架，比如SpringMVC框架。拦截器基于Java反射机制，属于一种面向切面编程AOP的应用。由于拦截器是基于web框架的调用，因此可以使用Spring的依赖注入(DI)进行一些业务操作，同时一个拦截器实例在一个controller生命周期之内可以多次调用。但是缺点是只能对controller请求进行拦截，对其他的一些比如直接访问静态资源的请求则没办法进行拦截处理。 拦截器是链式调用，一个应用中可以同时存在多个拦截器Interceptor， 一个请求也可以触发多个拦截器 ，而每个拦截器的调用会依据它的声明顺序依次执行。 拦截器是通过HandlerInterceptor来实现的，HandlerInterceptor 接口中也定义了3个方法： boolean preHandle()：进入handler方法之前执行。可以用于身份认证、身份授权。比如，如果认证没有通过表示用户没有登陆，返回false表示不再往下执行，否则返回true继续执行。 void postHandle()：只有在preHandle方法返回值为true时才会执行。会在handler中的方法调用之后，DispatcherServlet返回渲染视图modelAndView之前被调用。需要注意的是，先声明的拦截器preHandle方法先执行，而postHandle方法会后执行。 void afterCompletion()：只有在preHandle方法返回值为true时才会执行。在整个请求结束之后，执行Handler完成之后，DispatcherServlet渲染了对应的视图之后执行。 在SpringMVC中，拦截器是针对具体的HandlerMapping进行配置的，也就是说如果在某个HandlerMapping中配置拦截，经过该HandlerMapping映射成功的handler最终使用该拦截器。 spring-mvc.xml配置文件： 1234567891011&lt;!-- 拦截器配置 --&gt; &lt;mvc:interceptors&gt; &lt;!--多个拦截器,顺序执行 --&gt; &lt;!-- 登陆认证拦截器 --&gt; &lt;mvc:interceptor&gt; &lt;!-- /** 表示拦截所有url包括子url路径，/*只拦截根下的url --&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;bean class=&quot;com.test.MyInterceptor&quot;&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;!-- 其他拦截器 --&gt; &lt;/mvc:interceptors&gt; 应用场景 身份验证，权限检查：比如用户登录时身份检查，用户访问权限检查等； 日志记录：记录用户请求信息日志等； 性能检测：记录方法执行时间等； 应用实例1）身份检查 1234567891011121314151617181920212223242526public class MyInterceptor implements HandlerInterceptor&#123; //进入Handler方法之前执行，可以用于身份认证、身份授权。如果认证没有通过，在此方法拦截不再往下执行，否则放行 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // TODO Auto-generated method stub String user= (String) request.getSession().getAttribute(&quot;user&quot;); if(user != null)&#123; return true; &#125; request.getRequestDispatcher(&quot;/WEB-INF/jsp/index.jsp&quot;).forward(request, response); //true表示放行，false表示不放行 return false; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; // TODO Auto-generated method stub &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; // TODO Auto-generated method stub &#125; &#125; 2）性能检测 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 实现统计应用性能 * 拦截器的实现是单例的，因此不管用户请求多少次都只访问一个拦截器实例，即线程不安全 * 解决方案：使用ThreadLocal,它是线程绑定的变量，提供线程局部变量 (一个线程一个ThreadLocal) * */public class TimeInterceptor implements HandlerInterceptor &#123; public static final Logger logger = LoggerFactory.getLogger(TimeInterceptor.class); // 统计应用性能 private NamedThreadLocal&lt;Long&gt; startTimeThreadLocal = new NamedThreadLocal&lt;&gt;(&quot;StopWatch-StartTime&quot;); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // 开始时间 long startTime = System.currentTimeMillis(); // 线程绑定变量(该数据只有当前请求的线程可见) startTimeThreadLocal.set(startTime); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; // 2.结束时间 long endTime = System.currentTimeMillis(); // 得到线程绑定的局部 变量(开始时间) long beginTime = startTimeThreadLocal.get(); // 3.计算消耗时间 long consumeTime = endTime - beginTime; logger.debug(&quot;监控==========================： &quot; + String.format(&quot;%s consume %d millis&quot;, request.getRequestURI(), consumeTime)); startTimeThreadLocal.remove(); &#125;&#125; 监听器功能Servlet的监听器Listener，它是实现了javax.servlet.ServletContextListener接口的服务器端程序，它也是随web应用的启动而启动，只初始化一次，随web应用的停止而销毁。主要作用是：做一些初始化的内容添加工作，设置一些基本内容，比如：参数或者是某些固定对象等等。项目启动时，先启动监听器，再启动过滤器。 在javax.servlet.ServletContextListener接口中定义了2种方法： void contextInitialized()：监听器的初始化 void contextDestroyed()：监听器销毁 应用实例1234567891011121314public class MyListener implements ServletContextListener&#123; //监听器的初始化 @Override public void contextInitialized(ServletContextEvent sce) &#123; log.info(&quot;监听器初始化&quot;); &#125; //监听器销毁 @Override public void contextDestroyed(ServletContextEvent sce) &#123; log.info(&quot;监听器销毁&quot;); &#125; &#125; 总结过滤器和拦截器主要区别如下： 过滤器依赖于servlet容器，而拦截器不依赖与servlet容器，它是SpringMVC框架自带的； 拦截器是基于java的反射机制的，而过滤器是基于函数回调； 拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用； 拦截器可以访问controller上下文、值栈里的对象，而过滤器不能访问； 拦截器可以获取ioc容器中的各个bean，而过滤器不行，在拦截器里可以注入一个service，调用业务逻辑处理； 原因：拦截器属于SprinMVC框架，而过滤器是属于servlet。servlet先于spring启动。 过滤器和拦截器执行时间不一样； 拦截器的preHandle方法在进入controller前执行，而拦截器的postHandle方法在执行完controller业务流程后，在视图解析器解析ModelAndView对象之前执行，可以操控Controller的ModelAndView内容。而afterCompletion是在视图解析器解析渲染ModelAndView完成之后执行的。 过滤器是在请求进入容器之后，进入servlet之前进行处理的。请求结束返回也是在servlet处理完后，返回给前端之前。 过滤器是在服务器启动时就会创建的，只会创建一个实例，常驻内存，也就是说服务器启动就会执行Filter的init()方法。当Filter被移除或服务器正常关闭时，会执行destroy方法。 过滤器主要做一些编码处理、字符过滤、安全校验（比较简单的）等工作，其他更细致的处理，比如身份验证、安全校验，日志处理等，建议用拦截器。 过滤器和拦截器的执行顺序如下图： 过滤器、servlet容器、拦截器、aop、controller之间的关系如下图： 附带：SpringMVC的执行流程图","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"Redis底层数据结构","slug":"cache/Redis底层数据结构","date":"2018-07-16T15:13:23.000Z","updated":"2024-02-14T10:02:31.730Z","comments":false,"path":"2018/07/16/cache/Redis底层数据结构/","permalink":"https://imalan6.github.io/hexo_blog/2018/07/16/cache/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"","categories":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"缓存","slug":"缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"ThreadLocal 本地局部变量","slug":"concurrency/ThreadLocal本地局部变量","date":"2018-07-16T13:13:26.000Z","updated":"2024-02-14T09:52:19.180Z","comments":false,"path":"2018/07/16/concurrency/ThreadLocal本地局部变量/","permalink":"https://imalan6.github.io/hexo_blog/2018/07/16/concurrency/ThreadLocal%E6%9C%AC%E5%9C%B0%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F/","excerpt":"","text":"ThreadLocal 本地局部变量作用在涉及到多线程需要共享某一资源，但又不能相互影响，必须实现互斥访问时，可以有两种解决思路： 1）使用互斥锁，互斥访问资源。比如synchronized关键字，那么在每个时刻只能有一个线程使用该资源，用完后让出位置，其他线程继续使用。这种方式的缺点在于增加了线程间的竞争，降低了效率。 2）为每个线程创建一份资源，访问相互不干预。这样的思路就是将资源进行复制，每个线程使用自己的，各个线程相互不影响，比如使用ThreadLocal为每个线程保存一份资源。 如果说synchronized是以“时间换空间”，那么ThreadLocal就是 “以空间换时间” 。因为ThreadLocal的原理就是：对于要在线程间共享的资源或变量，为每个线程都提供一份，从而不同线程之间各自使用各自的，互不影响，从而达到并发访问而不出现问题。 当使用ThreadLocal维护变量的时候，为每一个使用该变量的线程提供一个独立的变量副本，即每个线程内部都会有一个该变量，这样同时多个线程访问该变量并不会彼此相互影响，因此他们使用的都是自己从内存中拷贝过来的变量的副本，这样就不存在线程安全问题，也不会影响程序的执行性能。 应用实例这里有个问题，直接看局部变量和ThreadLocal起到的作用似乎是一样的，都是保证了并发环境下线程数据的安全性。那是不是完全可以用局部变量来代替ThreadLocal？其实不是这样的。ThreadLocal提供的是一种线程局部变量，这些变量不同于其它变量的点在于每个线程在获取变量的时候，都拥有它自己相对独立的变量初始化拷贝。 ThreadLocal不是为了满足多线程安全而开发出来的，因为局部变量已经足够安全。ThreadLocal是为了方便线程处理自己的某种状态。可以看到ThreadLocal实例化所处的位置，是一个线程共有区域。好比一个银行和个人，我们可以把钱存在银行，也可以把钱存在家。存在家里的钱是局部变量，仅供个人使用；存在银行里的钱也不是说任何人都可以随便取，也只有我们以个人身份才能取。 关于数据库连接的例子 如下是一个数据库链接管理类代码： 12345678910111213141516class ConnectionManager &#123; private static Connection connect = null; public static Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public static void closeConnection() &#123; if(connect != null) connect.close(); &#125;&#125; 以上这段代码在单线程中运行使用是没有任何问题的，但是如果在多线程中使用会存在线程安全问题： 1）这里面的2个方法都没有进行同步，很可能在openConnection方法中会多次创建connection对象； 2）connection对象是共享变量，那么在调用connection对象的地方需要使用互斥锁来保障线程安全，因为很可能一个线程在使用connect进行数据库操作，而另外一个线程调用closeConnection关闭了连接。 所以出于线程安全的考虑，可以将这段代码的两个方法进行同步处理。但这样将会大大影响程序执行效率，因为一个线程在使用connect进行数据库操作的时候，其他线程只有等待。当然解决这个问题可以有好几种方式： 1）每次调用openConnection都创建新的connection对象，比如在ConnectionManager类中去掉if(connect == null)的判断，这样每个线程每次操作都会创建新的connection对象，也就不存在线程间共享使用connection的问题了。 2）在每个需要使用数据库连接的方法中具体使用时才创建数据库链接，然后在方法调用完毕再释放这个连接。比如下面这样： 12345678public void insert() &#123; ConnectionManager connectionManager = new ConnectionManager(); Connection connection = connectionManager.openConnection(); //使用connection进行操作 connectionManager.closeConnection();&#125; 这样每次都是在方法内部创建连接，方法运行完就关闭，不同connection对象使用的周期仅限于方法内，那么线程之间自然也不存在线程安全问题了。但这种方式需要在方法中频繁地开启和关闭数据库连接，这不仅严重影响程序执行效率，还可能导致数据库服务器压力过大。 3）使用ThreadLocal为每个线程保存一个connection对象的副本，线程之间使用互不影响，这样就不存在线程安全问题，也不会严重影响程序执行性能。 123456789101112131415161718192021222324252627class ConnectionManager &#123; // 定义一个用于放置数据库连接的局部线程变量（使每个线程都拥有自己的连接） private static ThreadLocal&lt;Connection&gt; connContainer = new ThreadLocal&lt;Connection&gt;(); public static Connection openConnection() &#123; Connection conn = connContainer.get(); try &#123; if (conn == null) &#123; conn = DriverManager.getConnection(); &#125; &#125; finally &#123; connContainer.set(conn); &#125; return conn; &#125; public static void closeConnection() &#123; Connection conn = connContainer.get(); try &#123; if (conn != null) &#123; conn.close(); &#125; &#125; finally &#123; connContainer.remove(); &#125; &#125;&#125; 实现原理ThreadLocal的主要作用是做数据隔离，填充的数据只属于当前线程，变量的数据对别的线程而言是相对隔离的，在多线程环境下，可以防止自己的变量被其它线程篡改。ThreadLocal又被叫做线程局部变量，在每个线程中都创建了一个ThreadLocalMap对象，每个线程可以访问自己内部ThreadLocalMap对象内的value。这里需要注意ThreadLocalMap，虽然带有Map这个词，但是它并没有实现Map接口，仅仅是个类名而已，可以说跟Map没有半毛钱关系。 那么ThreadLocal是如何实现为每个线程创建变量副本的呢？首先我们来看下ThreadLocal的set方法。set方法在初始化变量值的时候会被调用。 123456789101112131415public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; map.set(this, value); &#125;else &#123; //创建ThreadLocalMap createMap(t, value); &#125;&#125;void createMap(Thread t, T firstValue) &#123; //当前线程的成员变量threadLocals持有ThreadLocalMap的引用，而ThreadLocal对象（this）仅用来作为key保存和获取值 t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 当前线程的ThreadLocal在第一次调用set方法的时候会创建ThreadLocalMap并设置上相应的值。每个线程都有一个threadLocals成员，引用类型是ThreadLocalMap，以ThreadLocal和变量值作为参数。这样，我们所使用的ThreadLocal变量的实际数据，通过get方法取值的时候，就是通过取出Thread中threadLocals引用的ThreadLocalMap，然后从这个ThreadLocalMap中根据当前ThreadLocal对象作为参数，取出数据。 也就是说其实不同线程取到的变量副本都是由线程本身保存了，只是借助ThreadLocal去获取，不是存放于ThreadLocal中。其实也可以这么理解，每个线程各自维护了一个保存有变量副本的ThreadLocalMap，而ThreadLocal其实只是个符号意义，本身不存储变量副本，仅仅是用来索引各个线程中保存的变量副本数据而已。 注意事项 内存泄露问题 1234567static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; ThreadLocal在保存的时候会把自己当做 Key 存在线程的ThreadLocalMap中，正常情况应该是key和value都应该被外界强引用才对，但是key被设计成WeakReference弱引用了。这就导致了一个问题，ThreadLocal在没有外部强引用时，发生GC时会被回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。 在ThreadLocal中内存泄漏是指ThreadLocalMap中的Entry中 的key为null，而value不为null。因为key为null导致value一直访问不到，而根据可达性分析，始终有threadRef -&gt; currentThread -&gt; threadLocalMap -&gt; entry -&gt; valueRef -&gt; valueMemory，导致在垃圾回收的时候进行可达性分析的时候，value可达从而不会被回收掉，但是该value永远不能被访问到，这样就存在了内存泄漏。 因为Entry的key是弱引用，所以在gc的时候key会被回收，而value是强引用，导致value不会被回收。 如果不使用弱引用也会可能会发生内存泄漏，只要在业务代码里，将ThreadLocal的引用置为null，也会导致Entry中value访问不到，但又因为可达，所以gc时候不会被回收，相当于这部分内存资源被浪费了。 那为什么Entry的key使用弱引用呢？ 假设ThreadLocal使用的是强引用，在业务代码中执行ThreadLocal Instance = null操作，以清理掉ThreadLocal实例的目的，但是因为ThreadLocalMap的Entry强引用ThreadLocal，因此在gc的时候进行可达性分析，ThreadLocal依然可达，对ThreadLocal并不会进行垃圾回收，这样就无法真正达到业务逻辑的目的，出现逻辑错误。假设Entry弱引用ThreadLocal，尽管会出现内存泄漏的问题，但是在ThreadLocal的生命周期里（set，getEntry，remove）里，都会针对key为null的脏entry进行处理。ThreadLocal源码中其实已经对内存泄漏问题做了很多优化，在set，get，remove方法中都会对key为null的但是value不为null的Entry进行value置null操作，使得value的引用为null，可达性失败，在gc是可以回收value的内存。 在日常使用中，最后用完ThreadLocal后，记得调用remove方法。因为如果不调用remove方法，当一次gc执行，这个value就会造成内存泄漏直到当前线程结束（线程结束，ThreaLocalMap会被置为null，而ThreaLocalMap中的Entry也就不可达会被回收，一切都被回收） 线程结束时会执行Thread.exit方法 1234567891011121314private void exit() &#123; if (group != null) &#123; group.threadTerminated(this); group = null; &#125; /* Aggressively null out all reference fields: see bug 4006245 */ target = null; /* Speed the release of some of these resources */ threadLocals = null; inheritableThreadLocals = null; inheritedAccessControlContext = null; blocker = null; uncaughtExceptionHandler = null;&#125; 重写initialValue方法初始化变量值 先看一个简单的例子，覆盖ThreadLocal的initialValue方法初始化变量值，如下代码： 123456789101112131415161718192021222324252627282930313233public class Test &#123; //创建一个 Integer 型的线程本地变量 public static final ThreadLocal&lt;Integer&gt; local = new ThreadLocal&lt;Integer&gt;() &#123; @Override protected Integer initialValue() &#123; return 0; &#125; &#125;; public static void main(String[] args) throws InterruptedException &#123; Thread[] threads = new Thread[5]; for (int j = 0; j &lt; 5; j++) &#123; threads[j] = new Thread(new Runnable() &#123; @Override public void run() &#123; //获取当前线程的本地变量，然后累加5次 int num = local.get(); for (int i = 0; i &lt; 5; i++) &#123; num++; &#125; //重新设置累加后的本地变量 local.set(num); System.out.println(Thread.currentThread().getName() + &quot; : &quot;+ local.get()); &#125; &#125;, &quot;Thread-&quot; + j); &#125; for (Thread thread : threads) &#123; thread.start(); &#125; &#125;&#125; 运行后结果： 12345Thread-0 : 5Thread-2 : 5Thread-3 : 5Thread-1 : 5Thread-4 : 5 我们看到，每个线程累加后的结果都是5，各个线程处理自己的本地变量值，线程之间互不影响。现在，我们对initialValue方法的返回值稍作改动如下： 123456789101112131415161718192021222324252627282930313233343536373839public class ThreadLocalTest &#123; private static Index num = new Index(); //创建一个Index类型的本地变量 private static ThreadLocal&lt;Index&gt; local = new ThreadLocal&lt;Index&gt;() &#123; @Override protected Index initialValue() &#123; return num; &#125; &#125;; public static void main(String[] args) throws InterruptedException &#123; Thread[] threads = new Thread[5]; for (int j = 0; j &lt; 5; j++) &#123; threads[j] = new Thread(new Runnable() &#123; @Override public void run() &#123; //取出当前线程的本地变量，并累加1000次 Index index = local.get(); for (int i = 0; i &lt; 1000; i++) &#123; index.increase(); &#125; System.out.println(Thread.currentThread().getName() + &quot; : &quot;+ index.num); &#125; &#125;, &quot;Thread-&quot; + j); &#125; for (Thread thread : threads) &#123; thread.start(); &#125; &#125; static class Index &#123; int num; public void increase() &#123; num++; &#125; &#125;&#125; 执行后我们发现结果如下（每次运行还都不一样）： 12345Thread-0 : 1390Thread-3 : 2390Thread-4 : 4390Thread-2 : 3491Thread-1 : 1390 上面代码中，我们通过覆盖initialValue方法来给我们的ThreadLocal提供初始值，每个线程都会获取这个初始值的一个副本。而现在我们的初始值是num，num是这个对象的引用。也就是说我们的初始值是一个引用，引用的副本和引用指向的是同一个对象。 如果我们想给每一个线程都保存一个Index对象，就应该创建对象的副本而不是对象引用的副本，比如： 123456private static ThreadLocal&lt;Index&gt; local = new ThreadLocal&lt;Index&gt;() &#123; @Override protected Index initialValue() &#123; return new Index(); //注意这里 &#125;&#125;; 对象的拷贝图示： 如此运行，结果就正确了。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"ReentrantLock 实现原理","slug":"concurrency/ReentrantLock实现原理","date":"2018-07-03T14:11:26.000Z","updated":"2024-02-14T09:52:19.139Z","comments":false,"path":"2018/07/03/concurrency/ReentrantLock实现原理/","permalink":"https://imalan6.github.io/hexo_blog/2018/07/03/concurrency/ReentrantLock%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","excerpt":"","text":"ReentrantLock 实现原理使用synchronized来做同步处理时，锁的获取和释放都是隐式的，实现的原理是通过编译后加上不同的机器指令来实现。 而ReentrantLock就是一个普通的类，它是基于AQS(AbstractQueuedSynchronizer)来实现的。 是一个重入锁：一个线程获得了锁之后仍然可以反复的加锁，不会出现自己阻塞自己的情况。 AQS是Java并发包里实现锁同步的一个重要的基础框架。 锁类型ReentrantLock分为公平锁和非公平锁，可以通过构造方法来指定具体类型： 123456789//非公平锁，默认public ReentrantLock() &#123; sync = new NonfairSync();&#125;//公平锁public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 默认使用非公平锁，它的效率和吞吐量都比公平锁高很多。 锁使用通常的使用方式如下: 1234567891011private ReentrantLock lock = new ReentrantLock();public void run() &#123; lock.lock(); try &#123; // 业务处理 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125;&#125; 特别注意，lock不同于synchronized关键字，需要手动释放。为了防止发生异常导致锁无法释放，通常在finally代码块中释放锁。如果要指定公平锁，只需要在构造方法参数中传入true即可。 公平锁 1、获取锁 12345678910111213141516171819202122232425262728293031static final class FairSync extends Sync &#123; final void lock() &#123; acquire(1); &#125; // AbstractQueuedSynchronizer.acquire(int arg) public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 和非公平锁相比，这里多了一个判断：是否有线程在等待 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125;&#125; 实现步骤： 1）调用 tryAcquire(arg)尝试获取锁，判断AQS中的锁状态state是否等于 0。当state &gt; 0时，表示锁已经被获取；当state == 0时，表示锁已经释放。 2）如果state == 0，表示目前没有线程获得锁，那当前线程就可以尝试获取锁； 3）尝试之前会利用hasQueuedPredecessors()方法判断AQS的队列中是否有其他线程，如果有则不会尝试获取锁，这是公平锁特有的情况。 4）如果队列中没有线程就利用CAS（compareAndSetState(0, acquires)方法）来将AQS中的state置为1，也就是获取锁，获取成功则调用setExclusiveOwnerThread(current)将当前线程置为获得锁的独占线程。 如果第 2）步中的state &gt; 0时，说明锁已经被获取了，则判断获取锁的线程是否为当前线程(ReentrantLock支持重入)，如果是则将state + 1。 6）如果获取锁失败，则将当前线程写入队列。 2、写入队列 如果tryAcquire(arg)获取锁失败，则调用addWaiter(Node.EXCLUSIVE)将当前线程封装一个Node对象(addWaiter(Node.EXCLUSIVE)) 并写入队列中。 AQS 中的队列是由 Node 节点组成的双向链表实现的。 node 节点封装代码如下： 1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 首先判断队列是否为空，不为空时则将封装好的Node利用CAS写入队尾，如果出现并发写入失败就需要调用enq(node)来写入。 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 这个处理方式就相当于CAS加上自旋操作（循环等待）保证一定能写入队列。 3、挂起等待线程 写入队列之后，调用acquireQueued(addWaiter(Node.EXCLUSIVE), arg)将当前线程挂起。 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 首先会根据node.predecessor()获取到上一个节点是否为头节点，如果是则再尝试获取一次锁。如果不是头节点，则会根据上一个节点的waitStatus状态来处理shouldParkAfterFailedAcquire(p, node)。 非公平锁 公平锁与非公平锁的差异主要在获取锁上。公平锁会让线程依次排队获取锁，而非公平锁则没有这些规则，属于抢占模式，每来一个线程，都会直接先尝试获取锁。 1234567891011121314151617181920212223242526272829303132333435363738394041static final class NonfairSync extends Sync &#123; final void lock() &#123; // 和公平锁相比，这里会直接先进行一次CAS，成功就返回了 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; // AbstractQueuedSynchronizer.acquire(int arg) public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;/** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 这里也是直接CAS，没有判断前面是否还有节点。 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 非公平锁的实现在刚进入lock方法时会直接使用一次CAS去尝试获取锁，不成功才会到acquire方法中，当进入到非公平锁的nonfairTryAcquire方法中也并没有判断是否有前驱节点在等待锁，直接CAS尝试获取锁。由此实现了非公平锁。 小结 非公平锁和公平锁的不同处： 1、非公平锁在调用lock后，首先就会调用CAS进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。 2、非公平锁在CAS失败后，和公平锁一样都会进入到tryAcquire方法，在tryAcquire方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接CAS抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，排到队列后面。 公平锁和非公平锁就这两点区别，如果这两次CAS都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。 相对来说，非公平锁会有更好的性能，但可能导致阻塞队列中的等待线程长期处于饥饿状态。 锁释放公平锁和非公平锁的释放流程都是一样的： 12345678910111213141516171819202122232425262728public void unlock() &#123; sync.release(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒被挂起的线程 unparkSuccessor(h); return true; &#125; return false;&#125;// 尝试释放锁protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 首先会判断当前线程是否为获得锁的线程，由于是重入锁所以需要将state减到 0 才认为完全释放锁。释放之后需要调用unparkSuccessor(h)来唤醒被挂起的线程。 线程同步（与Condition）在使用synchronized锁时，我们可以使用notify()和wait()方法实现线程同步。但是当使用ReentrantLock锁时，线程同步操作需要借助Condition来实现。Condition必须和Lock配合使用，其提供的await()方法和signal()方法，作用类似于Object对象的wait()和notify()方法，用来实现线程间的通信。 Condition的作用是对锁进行更加精确的控制，Condition中的await() / signal() / signalAll()和 Object 中的wait() / notify() / notifyAll()方法相似，不同的是Object中的三个方法是基于synchronized关键字，而Condition中的三个方法则需要和Lock配合使用。针对一个Lock对象可以有多个Condition对象，这使得Condition对象更加灵活。 一个经典的生产者 - 消费者模型例子，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128public class Repository &#123; /* * 仓库的容量 */ private int capacity; /* * 仓库的实际量 */ private int size; /* * 独占锁 */ private Lock lock; /* * 仓库满时的条件 */ private Condition fullCondition; /* * 仓库空时的条件 */ private Condition emptyCondition; public Repository(int capacity) &#123; this.capacity = capacity; this.size = 0; lock = new ReentrantLock(); fullCondition = lock.newCondition(); emptyCondition = lock.newCondition(); &#125; class Producer implements Runnable &#123; @SneakyThrows @Override public void run() &#123; while (true) &#123; //上锁 lock.lock(); try &#123; // 随机生成1~10个 int num = new Random().nextInt(10) + 1; if (size &gt;= capacity) &#123; System.out.println(&quot;repository fulled!&quot;); // 仓库满了，相当于wait()操作，只有当fullCondition.signalAll()才能继续执行 fullCondition.await(); &#125; /* * 获取实际的生产量 */ int actNum = (size + num) &gt; capacity ? capacity - size : num; size += actNum; System.out.println(&quot;produced: +&quot; + actNum + &quot;, the size is:&quot; + size); // 通知消费者来消费，相当于notifyAll()操作 emptyCondition.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; //释放锁一般放在finally中 lock.unlock(); &#125;// Thread.sleep(1000); &#125; &#125; &#125; class Consumer implements Runnable &#123; @SneakyThrows @Override public void run() &#123; while (true) &#123; //上锁 lock.lock(); try &#123; // 随机生成1~10个 int num = new Random().nextInt(10) + 1; if (size &lt; 1) &#123; System.out.println(&quot;repository emptied!&quot;); // 仓库空了，相当于wait()操作，emptyCondition.signalAll()才能继续执行 emptyCondition.await(); &#125; /* * 获取实际的消费量 */ int actNum = (size &lt; num) ? size : num; size -= actNum; System.out.println(&quot;consumed: -&quot; + actNum + &quot;, the size is:&quot; + size); // 通知生产者生产，相当于notifyAll()操作 fullCondition.signalAll(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; //释放锁一般放在finally中 lock.unlock(); &#125;// Thread.sleep(1000); &#125; &#125; &#125; public static void main(String[] args)&#123; Repository repository = new Repository(10); new Thread(repository.new Producer()).start(); new Thread(repository.new Consumer()).start(); &#125; 以上代码，首先定义了一个仓库类repository，类中定义了一个锁对象lock，为生产和消费操作上锁，相当于synchronized的作用。然后，由一个锁对象创建出两个条件对象：fullCondition（仓库满）和emptyCondition（仓库空）。 当生产者生产数据时，调用lock.lock()为生产操作上锁，当仓库满了时，执行fullCondition.await()，相当于wait()作用，只有执行fullCondition.signalAll()才能让当前生产线程继续执行。当生产数量没有达到仓库最大容量时，会调用emptyCondition.signalAll()通知消费者消费数据。 当消费者消费数据时，同样调用lock.lock()为消费操作上锁，当仓库为空时，会执行emptyCondition.await()，让消费者线程阻塞，只有生产线程调用emptyCondition.signalAll()才能让当前线程继续执行。当消费，会调用fullCondition.signalAll()通知生产者产生数据； 最后，当线程的任务执行完毕后，需要调用lock.unlock()释放对象锁。 代码运行结果如下： 123456789101112131415161718192021222324252627282930313233343536produced: +6, the size is:6produced: +4, the size is:10repository fulled!consumed: -6, the size is:4consumed: -4, the size is:0repository emptied!produced: +7, the size is:7produced: +3, the size is:10repository fulled!consumed: -3, the size is:7consumed: -6, the size is:1consumed: -1, the size is:0repository emptied!produced: +9, the size is:9produced: +1, the size is:10repository fulled!consumed: -6, the size is:4consumed: -2, the size is:2consumed: -2, the size is:0repository emptied!produced: +3, the size is:3produced: +6, the size is:9produced: +1, the size is:10repository fulled!consumed: -6, the size is:4consumed: -4, the size is:0repository emptied!produced: +7, the size is:7produced: +3, the size is:10repository fulled!consumed: -7, the size is:3consumed: -3, the size is:0repository emptied!produced: +1, the size is:1produced: +8, the size is:9produced: +1, the size is:10","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"LinkedHashMap","slug":"collections/LinkedHashMap","date":"2018-07-03T12:21:07.000Z","updated":"2024-02-14T09:44:31.287Z","comments":false,"path":"2018/07/03/collections/LinkedHashMap/","permalink":"https://imalan6.github.io/hexo_blog/2018/07/03/collections/LinkedHashMap/","excerpt":"","text":"LinkedHashMap众所周知HashMap是一个无序的Map，因为每次根据 key 的 hashcode 映射到 Entry 数组上，所以遍历出来的顺序并不是写入的顺序。 因此 JDK 推出一个基于 HashMap 但具有顺序的 LinkedHashMap 来解决有排序需求的场景。 它的底层是继承于 HashMap 实现的，由一个双向链表所构成。 LinkedHashMap 的排序方式有两种： 根据写入顺序排序。 根据访问顺序排序。 其中根据访问顺序排序时，每次 get 都会将访问的值移动到链表末尾，这样重复操作就能得到一个按照访问顺序排序的链表。 数据结构1234567891011@Testpublic void test()&#123; Map&lt;String, Integer&gt; map = new LinkedHashMap&lt;String, Integer&gt;(); map.put(&quot;1&quot;,1) ; map.put(&quot;2&quot;,2) ; map.put(&quot;3&quot;,3) ; map.put(&quot;4&quot;,4) ; map.put(&quot;5&quot;,5) ; System.out.println(map.toString());&#125; 调试可以看到 map 的组成： 打开源码可以看到： 123456789101112131415161718192021/** * The head of the doubly linked list. */private transient Entry&lt;K,V&gt; header;/** * The iteration ordering method for this linked hash map: &lt;tt&gt;true&lt;/tt&gt; * for access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order. * * @serial */private final boolean accessOrder;private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; &#123; // These fields comprise the doubly linked list used for iteration. Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 其中 Entry 继承于 HashMap 的 Entry，并新增了上下节点的指针，也就形成了双向链表。 还有一个 header 的成员变量，是这个双向链表的头结点。 上边的 demo 总结成一张图如下： 第一个类似于 HashMap 的结构，利用 Entry 中的 next 指针进行关联。 下边则是 LinkedHashMap 如何达到有序的关键。 就是利用了头节点和其余的各个节点之间通过 Entry 中的 after 和 before 指针进行关联。 其中还有一个 accessOrder 成员变量，默认是 false，默认按照插入顺序排序，为 true 时按照访问顺序排序，也可以调用: 123456public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; 这个构造方法可以显示的传入 accessOrder 。 构造方法LinkedHashMap 的构造方法: 1234public LinkedHashMap() &#123; super(); accessOrder = false;&#125; 其实就是调用的 HashMap 的构造方法: HashMap 实现： 123456789101112131415public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; //HashMap 只是定义了改方法，具体实现交给了 LinkedHashMap init();&#125; 可以看到里面有一个空的 init()，具体是由 LinkedHashMap 来实现的： 12345@Overridevoid init() &#123; header = new Entry&lt;&gt;(-1, null, null, null); header.before = header.after = header;&#125; 其实也就是对 header 进行了初始化。 put() 方法看 LinkedHashMap 的 put() 方法之前先看看 HashMap 的 put 方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; //空实现，交给 LinkedHashMap 自己实现 e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // LinkedHashMap 对其重写 addEntry(hash, key, value, i); return null;&#125;// LinkedHashMap 对其重写void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;// LinkedHashMap 对其重写void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 主体的实现都是借助于 HashMap 来完成的，只是对其中的 recordAccess(), addEntry(), createEntry() 进行了重写。 LinkedHashMap 的实现： 123456789101112131415161718192021222324252627282930313233343536373839 //就是判断是否是根据访问顺序排序，如果是则需要将当前这个 Entry 移动到链表的末尾 void recordAccess(HashMap&lt;K,V&gt; m) &#123; LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) &#123; lm.modCount++; remove(); addBefore(lm.header); &#125; &#125; //调用了 HashMap 的实现，并判断是否需要删除最少使用的 Entry(默认不删除) void addEntry(int hash, K key, V value, int bucketIndex) &#123; super.addEntry(hash, key, value, bucketIndex); // Remove eldest entry if instructed Entry&lt;K,V&gt; eldest = header.after; if (removeEldestEntry(eldest)) &#123; removeEntryForKey(eldest.key); &#125;&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old); //就多了这一步，将新增的 Entry 加入到 header 双向链表中 table[bucketIndex] = e; e.addBefore(header); size++;&#125; //写入到双向链表中 private void addBefore(Entry&lt;K,V&gt; existingEntry) &#123; after = existingEntry; before = existingEntry.before; before.after = this; after.before = this; &#125; get 方法LinkedHashMap 的 get() 方法也重写了： 1234567891011121314151617181920212223public V get(Object key) &#123; Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); if (e == null) return null; //多了一个判断是否是按照访问顺序排序，是则将当前的 Entry 移动到链表头部。 e.recordAccess(this); return e.value;&#125;void recordAccess(HashMap&lt;K,V&gt; m) &#123; LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) &#123; lm.modCount++; //删除 remove(); //添加到头部 addBefore(lm.header); &#125;&#125; clear() 清空就要比较简单了： 12345//只需要把指针都指向自己即可，原本那些 Entry 没有引用之后就会被 JVM 自动回收。public void clear() &#123; super.clear(); header.before = header.after = header;&#125; 总结总的来说 LinkedHashMap 其实就是对 HashMap 进行了拓展，使用了双向链表来保证了顺序性。 因为是继承与 HashMap 的，所以一些 HashMap 存在的问题 LinkedHashMap 也会存在，比如不支持并发等。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"HashSet","slug":"collections/HashSet","date":"2018-07-03T11:22:31.000Z","updated":"2024-02-14T09:43:29.588Z","comments":false,"path":"2018/07/03/collections/HashSet/","permalink":"https://imalan6.github.io/hexo_blog/2018/07/03/collections/HashSet/","excerpt":"","text":"HashSetHashSet 是一个不允许存储重复元素的集合，它的实现比较简单，只要理解了 HashMap，HashSet 就水到渠成了。 成员变量首先了解下 HashSet 的成员变量: 1234private transient HashMap&lt;E,Object&gt; map;// Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object(); 发现主要就两个变量: map ：用于存放最终数据的。 PRESENT ：是所有写入 map 的 value 值。 构造函数1234567public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 构造函数很简单，利用了 HashMap 初始化了 map 。 add123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 比较关键的就是这个 add() 方法。可以看出它是将存放的对象当做了 HashMap 的健，value 都是相同的 PRESENT 。由于 HashMap 的 key 是不能重复的，所以每当有重复的值写入到 HashSet 时，value 会被覆盖，但 key 不会受到影响，这样就保证了 HashSet 中只能存放不重复的元素。 总结HashSet 的原理比较简单，几乎全部借助于 HashMap 来实现的。 所以 HashMap 会出现的问题 HashSet 依然不能避免。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"java反射机制","slug":"java_others/反射机制","date":"2018-06-26T13:53:11.000Z","updated":"2024-02-14T09:59:33.110Z","comments":false,"path":"2018/06/26/java_others/反射机制/","permalink":"https://imalan6.github.io/hexo_blog/2018/06/26/java_others/%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/","excerpt":"","text":"反射机制什么是反射反射(Reflection) 是 Java 程序开发语言的特征之一，它是Java程序在运行时可以访问、检测和修改它本身状态或行为的一种能力。它允许Java程序在运行中获取自身信息，并且可以操作类或对象的内部属性。 通过反射机制，可以在运行时访问Java对象的属性，方法，构造方法等。 反射机制很重要的一点就是”运行时”，使得我们可以在程序运行时加载和使用编译期间的.class文件。换句话说，Java程序可以加载一个运行时才得知名称的.class文件，然后获悉其完整构造，并生成其对象实体、或对其属性，方法进行操作。 反射的应用场景反射的主要应用场景如下： 开发通用框架 - 反射最重要的用途就是开发各种通用框架。很多框架为了让程序更优雅更简洁，都会使用反射机制。比如Spring的配置化方式（比如通过XML文件配置JavaBean、Filter等），它们可能需要根据配置文件加载不同的类或对象，调用不同的方法，这时就需要使用反射——运行时动态加载需要加载的对象。 动态代理 - 在面向切面编程(AOP)中，需要拦截特定的方法，通常，会选择动态代理方式。而JDK原生提供的动态代理就是通过反射实现的（但动态代理的实现方式还可以是ASM(一个短小精悍的字节码操作框架)、cglib(基于ASM)等，并不局限于反射）。 注解 - 注解本身仅仅是起到标记作用，它需要利用反射机制，根据注解标记调用注解解释器去执行。 可扩展性功能 - 应用程序可以通过使用完全限定名称创建可扩展性对象实例来使用外部的用户定义类。 反射的使用在使用反射时，首先是需要获取到该类的Class对象，然后通过Class对象就可以创建实例对象，或者访问类属性、方法等操作。 为配合实例说明，先创建一个Person类，代码如下： 12345678910111213141516171819202122public class Person&#123; private int age; private String name; public Person()&#123; age = 30; name = &quot;alan6&quot;; &#125; public Person(int age, String name)&#123; this.age = age; this.name = name; &#125; public int getAge()&#123; return this.age; &#125; public String getName()&#123; return this.name; &#125;&#125; 获取Class对象 通过反射获取Class类对象有三种方法： 1）使用Class.forName静态方法。当你知道该类的全路径名时，你可以使用该方法获取Class类对象。 1Class clz = Class.forName(&quot;com.alanotes.demo.Person&quot;); 2）使用类名+.class方法。这种方法只适合在编译前就知道操作的Class。 1Class clz = Person.class; 3）使用类对象的getClass()方法。 12Person person = new Person();Class clz = person.getClass(); 创建实例对象 通过反射创建实例对象主要有两种方式： 1）通过Class对象的newInstance()方法。 12Class clz = Person.class;Person person = (Person)clz.newInstance(); 2）通过Constructor对象的newInstance()方法 123Class clz = Person.class;Constructor constructor = clz.getConstructor();Person person = (Person)constructor.newInstance(); 通过Constructor对象创建类对象可以选择特定构造方法，而通过Class对象则只能使用默认的无参数构造方法。以下代码就调用了一个有参数的构造方法进行类对象的初始化。 123Class clz = Person.class;Constructor constructor = clz.getConstructor(int.class, String.class);Person person = (Person)constructor.newInstance(28, &quot;zhangsan&quot;); 获取类属性、方法、构造器 通过Class对象的getFields()方法可以获取Class类的属性，但无法获取私有属性。 12345Class clz = Person.class;Field[] fields = clz.getFields();for (Field field : fields) &#123; System.out.println(field.getName());&#125; 输出结果是： 1name 通过Class对象的getDeclaredFields()方法可以获取包括私有属性在内的所有属性： 12345Class clz = Person.class;Field[] fields = clz.getDeclaredFields();for (Field field : fields) &#123; System.out.println(field.getName());&#125; 输出结果是： 12agename 与获取类属性一样，当需要获取类方法、类构造器时，如果要获取私有方法或私有构造器，则必须使用有declared关键字的方法。 反射的原理(部分) Class.forName(“ ”)方法 首先看看获取类对象的第一种方式 Class.forName(&quot;&quot;)，这种方式调用了java.lang.Class的静态方法forName获取类信息 1234567@CallerSensitivepublic static Class&lt;?&gt; forName(String className) throws ClassNotFoundException &#123; // 先通过反射，获取调用进来的类信息，从而获取当前的 classLoader Class&lt;?&gt; caller = Reflection.getCallerClass(); // 调用native方法进行获取class信息 return forName0(className, true, ClassLoader.getClassLoader(caller), caller);&#125; forName()首先获取调用类信息，然后获取当前调用类的ClassLoader（也就是使用当前方法所在类的ClassLoader来加载），再调用native方法获取信息。最后，JVM又会回调ClassLoader进类加载。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false); &#125; // sun.misc.Launcher public Class&lt;?&gt; loadClass(String var1, boolean var2) throws ClassNotFoundException &#123; int var3 = var1.lastIndexOf(46); if(var3 != -1) &#123; SecurityManager var4 = System.getSecurityManager(); if(var4 != null) &#123; var4.checkPackageAccess(var1.substring(0, var3)); &#125; &#125; if(this.ucp.knownToNotExist(var1)) &#123; Class var5 = this.findLoadedClass(var1); if(var5 != null) &#123; if(var2) &#123; this.resolveClass(var5); &#125; return var5; &#125; else &#123; throw new ClassNotFoundException(var1); &#125; &#125; else &#123; return super.loadClass(var1, var2); &#125; &#125; // java.lang.ClassLoader protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; // 先获取锁 synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded // 如果已经加载了的话，就不用再加载了 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; // 双亲委托加载 if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; // 父类没有加载到时，再自己加载 if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; protected Object getClassLoadingLock(String className) &#123; Object lock = this; if (parallelLockMap != null) &#123; // 使用 ConcurrentHashMap来保存锁 Object newLock = new Object(); lock = parallelLockMap.putIfAbsent(className, newLock); if (lock == null) &#123; lock = newLock; &#125; &#125; return lock; &#125; protected final Class&lt;?&gt; findLoadedClass(String name) &#123; if (!checkName(name)) return null; return findLoadedClass0(name); &#125; Class.forName 和 ClassLoader的区别 Class.forName()得到的class是已经初始化完成的，而Classloder.loaderClass()得到的class是还没有链接的。 Java 中class.forName()和ClassLoader都可用来对类进行加载。Class.forName()除了将类的.class文件加载到JVM中之外，还会对类进行解释，执行类中的static块。 而ClassLoader只是将.class文件加载到JVM中，不会执行static中的内容，只有在newInstance()方法执行才会去执行类的static代码块。 Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象。 newInstance() 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 首先肯定是 Class.newInstance@CallerSensitivepublic T newInstance() throws InstantiationException, IllegalAccessException&#123; if (System.getSecurityManager() != null) &#123; checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), false); &#125; // NOTE: the following code may not be strictly correct under // the current Java memory model. // Constructor lookup // newInstance() 其实相当于调用类的无参构造函数，所以，首先要找到其无参构造器 if (cachedConstructor == null) &#123; if (this == Class.class) &#123; // 不允许调用 Class 的 newInstance() 方法 throw new IllegalAccessException( &quot;Can not call newInstance() on the Class for java.lang.Class&quot; ); &#125; try &#123; // 获取无参构造器 Class&lt;?&gt;[] empty = &#123;&#125;; final Constructor&lt;T&gt; c = getConstructor0(empty, Member.DECLARED); // Disable accessibility checks on the constructor // since we have to do the security check here anyway // (the stack depth is wrong for the Constructor&#x27;s // security check to work) java.security.AccessController.doPrivileged( new java.security.PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; c.setAccessible(true); return null; &#125; &#125;); cachedConstructor = c; &#125; catch (NoSuchMethodException e) &#123; throw (InstantiationException) new InstantiationException(getName()).initCause(e); &#125; &#125; Constructor&lt;T&gt; tmpConstructor = cachedConstructor; // Security check (same as in java.lang.reflect.Constructor) int modifiers = tmpConstructor.getModifiers(); if (!Reflection.quickCheckMemberAccess(this, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); if (newInstanceCallerCache != caller) &#123; Reflection.ensureMemberAccess(caller, this, null, modifiers); newInstanceCallerCache = caller; &#125; &#125; // Run constructor try &#123; // 调用无参构造器 return tmpConstructor.newInstance((Object[])null); &#125; catch (InvocationTargetException e) &#123; Unsafe.getUnsafe().throwException(e.getTargetException()); // Not reached return null; &#125;&#125; newInstance()主要做了三件事： 1）权限检测，如果不通过直接抛出异常； 2）查找无参构造器，并将其缓存起来； 3）调用具体方法的无参构造方法，生成实例并返回； 反射的优缺点 反射的优点： 1）可扩展性：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。 2）类浏览器和可视化开发环境：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。 3）调试器和测试工具： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。 反射的缺点： 尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。 1）性能开销：反射涉及了动态类型的解析，所以JVM无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。 2）安全限制：使用反射要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如Applet，那么就是个问题了。 3）内部暴露：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"Redis持久化方案","slug":"cache/Redis持久化方案RDB和AOF","date":"2018-06-26T05:23:11.000Z","updated":"2024-02-14T10:02:31.700Z","comments":false,"path":"2018/06/26/cache/Redis持久化方案RDB和AOF/","permalink":"https://imalan6.github.io/hexo_blog/2018/06/26/cache/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E6%A1%88RDB%E5%92%8CAOF/","excerpt":"","text":"Redis持久化方案简介Redis是一个内存数据库，数据都是存放在内存当中的，当服务器重启或宕机时就会导致内存数据丢失。如果Redis仅做为一个缓存服务器使用的话，数据丢失不会有太大影响，重启之后再次更新缓存就可以了。但是如果Redis做为内存数据库使用的话，遇到数据丢失，问题就比较麻烦了。比如电商系统的登录信息、购物车信息、用户浏览记录等保存在Redis的话，都会丢失的，是会影响用户使用的。所以，有必要对Redis中的数据进行持久化处理，保证即使重启或者宕机，数据还可以再次找回来不会丢失。 持久化Redis提供了RDB和AOF两种持久化机制，用来解决数据丢失问题。 1）RDB方式（默认） 2）AOF方式 RDB方式RDB是Redis默认采用的持久化方式。RDB通过快照方式（snapshot）完成，当符合一定条件时，Redis会自动将内存中的数据生成快照并持久化到硬盘。触发RDB的机制又可分为手动触发与自动触发。 手动触发 有两个Redis命令可以用于生成RDB文件： 1）使用save命令，但是”save”命令将会阻塞我们的Redis服务器直到RDB完成，所以生产环境中一般不会使用该命令。 2）使用bgsave命令，Redis会fork一个子进程来负责RDB持久化，完成持久化后自动结束子进程，所以阻塞只发生在fork的阶段。 自动触发 需要在Redis的配置文件redis.conf中加上save命令，如 “save m n”，代表在m秒内数据发生了n次修改就会使用bgsave命令自动触发RDB。 命令格式：save 示例： save 900 1 ： 表示15分钟（900秒钟）内至少1个键被更改则进行快照。 save 300 10 ： 表示5分钟（300秒）内至少10个键被更改则进行快照。 save 60 10000 ：表示1分钟内至少10000个键被更改则进行快照。 这是Redis默认配置信息，可以配置多个条件（每行配置一个条件），每个条件之间是或的关系。之所以配置多条规则，是因为Redis每个时段的读写请求不是均衡的，为了平衡性能与数据安全，可以自由定制什么情况下触发持久化。所以可以根据自身业务情况进行合理配置。 实现原理 1）使用fork函数复制一份当前进程的副本(子进程)； 2）父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件； 3）当子进程写完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。 配置 修改/etc/redis/redis.conf配置文件 12345678save 900 1 # 时间策略，在900秒之内，对数据库进行了至少1次修改。save 300 10 # 时间策略，在300秒之内，对数据库进行了至少10次修改。save 60 10000 # 时间策略，在60秒之内，对数据库进行了至少1000次修改。dbfilename dump.rdb #rdb文件名称dir /var/lib/redis #rdb文件保存路径 stop-writes-on-bgsave-error yes # 如果持久化出错，主进程是否停止写入 rdbcompression yes # 是否压缩 rdbchecksum yes # 导入时是否检查 注意 Redis启动时会读取RDB快照文件，将数据加载到内存。根据数据量大小、结构和服务器性能的不同，加载的时间也不同。通常情况下，一千万个字符串类型的键，大小为 1 GB的快照文件加载到内存中大概需要 20 秒左右。 优缺点 优点 性能最高。因为在写快照文件时，父进程只需要fork出一个子进程，而无需执行任何磁盘I&#x2F;O操作，然后这个子进程会处理接下来的所有保存工作。 缺点 可能导致数据丢失。因为最后一次快照之后的操作可能还没备份Redis就退出了，或者正在备份Redis宕机或重启了，就会丢失最后一次快照以后更改的所有数据。 简而言之，RDB比较适合大规模的数据恢复，如果业务对数据完整性和一致性要求不高的话，RDB是很好的选择。 AOF方式AOF的出现是为了弥补RDB数据丢失的问题，它采用日志的形式记录每一条更改Redis数据的命令，并将该命令写入硬盘中的AOF文件。这一过程会降低Redis的性能，但大部分情况下这个影响是能接受的，可以采用较快的硬盘（比如固态硬盘）来提高AOF的性能。Redis重启会根据日志文件的内容将记录的命令从头执行一次以完成数据的恢复工作。 默认情况下Redis没有开启AOF（append only file）持久化，可以通过修改redis.conf配置文件中的appendonly参数为yes来开启。 实现原理 1）实现原理 Redis每次更改数据的时候，AOF机制都会将命令记录到AOF文件，但由于操作系统的缓存机制，数据并没有实时写入到硬盘，而是进入硬盘缓存。再通过硬盘缓存机制刷新到AOF文件中。在AOF模式打开的情况下，服务器每执行一次写命令就会以协议格式将执行的写命令追加到aof_buf缓冲区的末尾。 Redis每执行完一次事件循环，就要考虑是否将缓冲区的数据写入AOF文件，写入同步策略有配置文件的appendfsync参数决定： ① appendfsync always 每次执行写入都会进行同步，将缓冲区所有内容写入并同步AOF文件，这个是最安全但是效率比较低的方式； ② appendfsync everysec（默认） 每一秒执行 ③ appendfsync no 不主动进行同步操作，由操作系统决定，这个是最快但最不安全的方式。 Tips: wiki1为了提高文件的写入效率，在现代操作系统中，当用户调用write函数，将一些数据写入到文件的时候，操作系统通常会将写入数据暂时保存在一个内存缓冲区里面，等到缓冲区的空间被填满、或者超过了指定的时限之后，才真正地将缓冲区中的数据写入到磁盘里面。这种做法虽然提高了效率，但也为写入数据带来了安全问题，因为如果计算机发生停机，那么保存在内存缓冲区里面的写入数据将会丢失。为此，系统提供了fsync和fdatasync两个同步函数，它们可以强制让操作系统立即将缓冲区中的数据写入到硬盘里面，从而确保写入数据的安全性。 2）重写机制 ① AOF文件可能会随着Redis运行变得越来越大，可以利用AOF重写的功能，来控制AOF文件的大小。AOF重写功能会首先读取数据库中现有的键值对状态，然后使用一条命令来替代前面的多条命令，重写后的新AOF文件包含了恢复当前数据集所需的最小命令集合。 ② Redis采用子进程处理AOF重写。Redis还设置了一个AOF重写缓冲区，这个缓冲区在子进程被创建之后开始使用。在这期间，所有命令会被存两份，一份在AOF缓存空间，一份在AOF重写缓冲区，当AOF重写完成之后，子进程发送信号给主进程，通知主进程将AOF重写缓冲区的内容添加到AOF文件中。 ③ 整个重写操作是绝对安全的，因为Redis在创建新AOF文件的过程中，会继续将命令追加到现有的AOF文件里面，即使重写过程中发生宕机，现有的AOF文件也不会丢失。而一旦新AOF文件创建完毕，Redis就会从旧AOF文件切换到新AOF文件，并开始对新AOF文件进行追加操作。 ④ AOF文件有序地保存了对Redis执行的所有修改操作， 这些修改操作以Redis协议的格式保存， 因此AOF文件的内容非常容易理解。 3）AOF文件修复 当程序正在对AOF文件进行写入操作时突然宕机，就很有可能造成AOF文件出错，那么Redis在重启时会拒绝载入这个AOF文件。当出现这种情况时，可以用以下方法修复出错的AOF文件： ① 为现有的AOF文件创建一个备份； ② 使用Redis附带的redis-check-aof程序对原来的AOF文件进行修复。 ③ 重启Redis服务器，等待载入修复后的AOF文件，并进行数据恢复。 配置 12345678910111213141516171819202122#AOF 和 RDB 持久化方式可以同时启动并且无冲突。 #如果AOF开启，启动redis时会加载aof文件，这些文件能够提供更好的保证。 appendonly yes# aof文件的文件名称。（默认是appendonly.aof） # appendfilename appendonly.aof #redis支持三种不同的写入方式： # # no:不调用，等待操作系统来清空缓冲区，很快。 # always: 每次更新数据都写入仅增日志文件。慢，但是最安全。# everysec: 每秒调用一次。折中。appendfsync everysec # 设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入.官方文档建议如果你有特殊的情况可以配置为&#x27;yes&#x27;。但是配置为&#x27;no&#x27;是最为安全的选择。no-appendfsync-on-rewrite no # 自动重写只增文件。 # redis可以自动盲从的调用‘BGREWRITEAOF’来重写日志文件，如果日志文件增长了指定的百分比。 # 当前AOF文件大小是上次日志重写得到AOF文件大小的二倍时，自动启动新的日志重写过程。auto-aof-rewrite-percentage 100 # 当前AOF文件启动新的日志重写过程的最小值，避免刚刚启动Reids时由于文件尺寸较小导致频繁的重写。auto-aof-rewrite-min-size 64mb 小结一般来说，如果对数据完整性要求非常高的话，应该同时使用两种持久化功能。如果能允许几分钟数据丢失情况，可以只使用RDB方式，性能更好。 有很多用户都只使用AOF方式，不推荐这样做。因为定时生成RDB快照非常便于Redis备份，并且RDB恢复数据的速度也比AOF快 。 两种持久化策略可以同时使用，也可以只使用其中一种。如果同时使用的话，Redis重启时会优先使用AOF文件恢复数据。","categories":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"缓存","slug":"缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"Java 锁的分类和使用","slug":"concurrency/Java锁的分类和使用","date":"2018-06-18T12:32:23.000Z","updated":"2024-02-14T09:52:19.118Z","comments":false,"path":"2018/06/18/concurrency/Java锁的分类和使用/","permalink":"https://imalan6.github.io/hexo_blog/2018/06/18/concurrency/Java%E9%94%81%E7%9A%84%E5%88%86%E7%B1%BB%E5%92%8C%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Java 锁的分类和使用Java 锁的种类Java 锁的分类主要如下： 乐观锁&#x2F;悲观锁 独享锁&#x2F;共享锁 互斥锁&#x2F;读写锁 可重入锁 公平锁&#x2F;非公平锁 分段锁 偏向锁&#x2F;轻量级锁&#x2F;重量级锁 自旋锁 以上是一些锁的名词，这些分类并不是全是指锁的状态，有的指锁的特性，有的指锁的设计。 乐观锁 &#x2F; 悲观锁乐观锁与悲观锁并不是特指某两种类型的锁，是人们定义出来的概念或思想，主要是指看待并发同步的角度。 乐观锁 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，在 Java 中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式 CAS(Compare and Swap比较并交换)实现的。 乐观锁总是认为不存在并发问题，每次去取数据的时候，总认为不会有其他线程对数据进行修改，因此不会上锁。但是在更新时会判断其他线程在这之前有没有对数据进行修改，一般会使用“数据版本机制”或“CAS操作”来实现。 1）数据版本机制 实现数据版本一般有两种，第一种是使用版本号，第二种是使用时间戳。以版本号方式为例。 版本号方式：一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加1。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。比如如下SQL代码： 1update table set xxx=#&#123;xxx&#125;, version=version+1 where id=#&#123;id&#125; and version=#&#123;version&#125;; 2）CAS操作 CAS（Compare and Swap比较并交换），当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数——需要读写的内存位置(V)、进行比较的预期原值(A)和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B，否则处理器不做任何操作。 悲观锁 悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。比如Java 里面的同步原语synchronized关键字的实现就是悲观锁。 悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。 悲观锁在 Java 中的使用，就是利用各种锁。乐观锁在 Java 中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。悲观锁认为对于同一个数据的并发操作，一定会发生修改的，哪怕没有修改，也会认为修改。因此对于同一份数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁并发操作一定会出问题。 在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。具体响应方式由开发者根据实际需要决定。如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。期间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。 独享锁 &#x2F; 共享锁独享锁是指该锁一次只能被一个线程所持有。 共享锁是指该锁可被多个线程所持有。 对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读，写写的过程是互斥的。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 对于synchronized而言，当然是独享锁。 互斥锁 &#x2F; 读写锁上面讲的独享锁&#x2F;共享锁就是一种广义的说法，互斥锁&#x2F;读写锁就是具体的实现。 互斥锁在Java中的具体实现就是ReentrantLock。 读写锁在Java中的具体实现就是ReadWriteLock。 可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。说的有点抽象，下面会有一个代码的示例。 对于Java ReetrantLock而言，从名字就可以看出是一个重入锁，其名字是Re entrant Lock重新进入锁。 对于synchronized而言，也是一个可重入锁。可重入锁的一个好处是可一定程度避免死锁。 12345678synchronized void setA() throws Exception&#123; Thread.sleep(1000); setB();&#125;synchronized void setB() throws Exception&#123; Thread.sleep(1000);&#125; 上面的代码就是一个可重入锁的一个特点。如果不是可重入锁的话，setB 可能不会被当前线程执行，可能造成死锁。 公平锁 &#x2F; 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁。 非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。 对于Java ReetrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。 对于synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7和JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock）。 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在哪一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。 但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。 分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 偏向锁 &#x2F; 轻量级锁 &#x2F; 重量级锁这三种锁是指锁的状态，并且是针对synchronized。在 Java 5 通过引入锁升级的机制来实现高效synchronized。这三种锁的状态是通过对象监视器在对象头中的字段来表明的。 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。 轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。 重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让他申请的线程进入阻塞，性能降低。 自旋锁在 Java 中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。 锁的基础类 AQS AbstractQueuedSynchronized抽象队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock &#x2F; Semaphore &#x2F; CountDownLatch… AQS维护了一个volatile int state( 代表共享资源 ) 和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。 state 的访问方式有三种： 1231 getState()2 setState()3 compareAndSetState AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队&#x2F;唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： 123451 isHeldExclusively(): 该线程是否正在独占资源。只有用到condition才需要去实现它。2 tryAquire(int): 独占方式。尝试获取资源，成功则返回true，失败则返回false。3 tryRelease(int): 独占方式。尝试释放资源，成功则返回true，失败则返回false。4 tryAcquireShared(int): 共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。5 tryReleaseShared(int): 共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A 线程lock() 时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state = 0（即释放锁）为止，其他线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多少次，这样才能保证state是能回到零态的。 再以CountDownLatch为例，任务分为 N 个子线程去执行，state为初始化为 N（注意 N 要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会 CAS 减1。等到所有子线程都执行完后（即state = 0），会unpark()主调用线程，然后主调用线程就会await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 CAS CAS（Compare and Swap比较并交换）是乐观锁技术，当多个线程尝试使用 CAS 同时更新同一个变量时，只有其中一个线程能更新变量的值，而其他线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数——需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值（B）。如果内存位置 V 的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值 B，否则处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值）。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将B放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可”。这其实和乐观锁的冲突检查+数据更新的原理是一样的。 JAVA 对 CAS 的支持： 在 JDK1.5 中新增java.util.concurrent包就是建立在 CAS 之上的。相对于synchronized这种阻塞算法，CAS 是非阻塞算法的一种常见实现。所以java.util.concurrent包中的AtomicInteger为例，看一下在不使用锁的情况下是如何保证线程安全的。主要理解getAndIncrement方法，该方法的作用相当于++i操作。详见 Atomic原子类。 12345678910111213141516171819public class AtomicInteger extends Number implements java.io.Serializable&#123; private volatile int value; public final int get()&#123; return value; &#125; public final int getAndIncrement()&#123; for (;;)&#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return current; &#125; &#125; public final boolean compareAndSet(int expect, int update)&#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125;&#125; 锁的使用 synchronized synchronized 可重入锁验证，详见 synchronized 关键字原理。 1234567891011121314151617181920public class SynchronizedDemo &#123; private static Object obj = new Object(); public static void main(String[] args) &#123; Runnable sellTicket = new Runnable() &#123; @Override public void run() &#123; synchronized (SynchronizedDemo.class) &#123; log.info(&quot;i am run&quot;); test01(); &#125; &#125; public void test01() &#123; synchronized (SynchronizedDemo.class) &#123; log.info(&quot;i am test01&quot;); &#125; &#125; &#125;; new Thread(sellTicket).start(); &#125;&#125; 运行结果 12i am runi am test01 ReentrantLock ReentrantLock 既可以构造公平锁又可以构造非公平锁，默认为非公平锁。 123456789101112131415161718192021222324252627282930313233343536373839public class LockDemo &#123; private static Lock lock = new ReentrantLock(); private static CountDownLatch countDownLatch = new CountDownLatch (10); private static int num = 0; public static void inCreate() &#123; try&#123; // 获取锁 lock.lock (); num++; &#125; finally&#123; // 释放锁 lock.unlock (); &#125; &#125; public static void main(String[] args) &#123; try&#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread (() -&gt; &#123; for (int j = 0; j &lt; 10000; j++) &#123; inCreate (); &#125; // 线程执行结束执行countDown，对计数减1 countDownLatch.countDown (); &#125;).start (); &#125; countDownLatch.await(); log.info(num); &#125; catch(InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果 1100000 ReentrantLock是可重入的独占锁。比起synchronized功能更加丰富，支持公平锁实现，支持中断响应以及限时等待等等。可以配合一个或多个Condition条件方便的实现等待通知机制。 ReentrantLock类中带有两个构造函数，一个是默认的构造函数，不带任何参数；一个是带有fair参数的构造函数。 1234567public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 第二个构造函数也是判断ReentrantLock是否是公平锁的条件，如果fair为true，则会创建一个公平锁的实现，也就是new FairSync()，如果fair为false，则会创建一个 非公平锁的实现，也就是new NonfairSync()，默认的情况下创建的是非公平锁修改上面例程的代码构造方法为： 1ReentrantLock reentrantLock = new ReentrantLock(true); 对于ReentrantLock公平锁和非公平锁的原理和用法，详见 ReentrantLock 原理。 ReentrantReadWriteLock 读写锁的性能都会比排他锁要好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。Java 并发包提供读写锁的实现是ReentrantReadWriteLock。 特性 说明 公平性选择 支持非公平(默认)和公平的锁获取方式，吞吐量还是非公平优于公平 重进入 该锁支持重进入，以读写线程为例：读线程在获取了读锁之后，能够再次获取读锁。而写线程在获取了写锁之后能够再次获取写锁，同时也可以获取读锁 锁降级 遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级成为读锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import java.util.HashMap;import java.util.Map;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantReadWriteLock;public class MyLockTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; Cache.put(&quot;key&quot;, new String(Thread.currentThread().getName() + &quot; joke&quot;)); &#125; &#125;, &quot;threadW-&quot; + i).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(Cache.get(&quot;key&quot;)); &#125; &#125;, &quot;threadR-&quot; + i).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; Cache.clear(); &#125; &#125;, &quot;threadC-&quot; + i).start(); &#125; &#125;&#125;class Cache &#123; static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); static Lock r = rwl.readLock(); static Lock w = rwl.writeLock(); // 获取一个key对应的value public static final Object get(String key) &#123; r.lock(); try &#123; log.info(&quot;get &quot; + Thread.currentThread().getName()); return map.get(key); &#125; finally &#123; r.unlock(); &#125; &#125; // 设置key对应的value，并返回旧有的value public static final Object put(String key, Object value) &#123; w.lock(); try &#123; log.info(&quot;put &quot; + Thread.currentThread().getName()); return map.put(key, value); &#125; finally &#123; w.unlock(); &#125; &#125; // 清空所有的内容 public static final void clear() &#123; w.lock(); try &#123; log.info(&quot;clear &quot; + Thread.currentThread().getName()); map.clear(); &#125; finally &#123; w.unlock(); &#125; &#125;&#125; 运行结果 12345678910111213141516171819202122232425262728293031323334353637383940put threadW-0clear threadC-1put threadW-1get threadR-1threadW-1 jokeput threadW-2get threadR-0threadW-2 jokeclear threadC-0get threadR-2nullclear threadC-4clear threadC-2clear threadC-3put threadW-4put threadW-3get threadR-3threadW-3 jokeput threadW-5get threadR-4threadW-5 jokeclear threadC-5put threadW-6put threadW-7get threadR-7threadW-7 jokeget threadR-5threadW-7 jokeget threadR-6threadW-7 jokeclear threadC-6clear threadC-7put threadW-8clear threadC-8put threadW-9get threadR-9threadW-9 jokeclear threadC-9get threadR-8null 可看到普通 HashMap 在多线程中数据可见性正常。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java多线程编程","slug":"concurrency/Java多线程使用","date":"2018-06-06T13:36:26.000Z","updated":"2024-02-14T09:52:19.103Z","comments":false,"path":"2018/06/06/concurrency/Java多线程使用/","permalink":"https://imalan6.github.io/hexo_blog/2018/06/06/concurrency/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Java多线程编程 多线程好处为了解决负载均衡问题，充分利用CPU资源。为了提高CPU的使用率，采用多线程的方式去同时完成几件事情而不互相干扰。为了处理大量的IO操作时或处理的情况需要花费大量的时间等等，比如：读写文件，视频图像的采集，处理等。 使用多线程的好处： 使用线程可以把占据时间长的程序中的任务放到后台去处理。 用户界面更加吸引人，这样比如用户点击了一个按钮去触发某件事件的处理，可以弹出一个进度条来显示处理的进度。 程序的运行效率可能会提高。 在一些等待的任务实现上如用户输入，文件读取和网络收发数据等，多线程就比较有用了。 线程的生命周期线程的生命周期包含5个阶段，包括：新建、就绪、运行、阻塞、销毁。 新建：就是刚使用new方法，创建出来的线程； 就绪：就是调用线程的start()方法后，这时候线程处于等待 CPU 分配资源阶段，谁先抢到 CPU 资源，谁开始执行; 运行：当就绪的线程被调度并获得 CPU 资源时，便进入运行状态，run 方法定义了线程的操作和功能; 阻塞：在运行状态的时候，可能因为某些原因导致运行状态的线程变成了阻塞状态，比如sleep()、wait()之后线程就处于了阻塞状态，这个时候需要其他机制将处于阻塞状态的线程唤醒，比如调用notify或者notifyAll()方法。唤醒的线程不会立刻执行run方法，它们要再次等待 CPU 分配资源进入运行状态; 销毁：如果线程正常执行完毕后或线程被提前强制性的终止或出现异常导致结束，那么线程就要被销毁，释放资源; 完整的线程生命周期图如下： Java划分更细一点的线程的状态在java.lang.Thread.State定义中有6种。 New，线程被创建，未执行和运行的时候。 Runnable，不代表线程在跑，分为两种：被 cpu 执行的线程，随时可以被 cpu 执行的状态。 Blocked，线程阻塞，处于synchronized同步代码块或方法中被阻塞。 Waiting，等待的线程状态。线程当前不执行，如果被其他唤醒后会继续执行的状态。依赖另一个线程的通知。这个等待是一直等，没其他线程唤醒起不来。 Time Waiting，指定等待时间的等待线程的线程状态。带超时的方式：Thread.sleep，Object.wait，Thread.join，LockSupport.parkNanos，LockSupport.parkUntil。 Terminated，正常执行完毕或者出现异常终止的线程状态。 详细状态转换图如下： 创建线程的方式 继承 Thread 类 用户的线程类只须继承Thread类并重写其run()方法即可，通过调用用户线程类的start()方法启动用户线程 12345678910111213class MyThread extends Thread&#123; public void run()&#123; &#125;&#125;public class TestThread&#123; public static void main(String[] args）&#123; MyThread thread = new MyThread(); //创建用户线程对象 thread.start(); //启动用户线程 thread.run(); //主线程调用用户线程对象的run()方法 &#125;&#125; 实现 Runnable 接口 当使用Thread(Runnable thread)方式创建线程对象时，须为该方法传递一个实现了Runnable接口的对象，这样创建的线程将调用实现Runnable接口的对象的run()方法 12345678910111213public class TestThread&#123; public static void main(String[] args)&#123; Mythread mt = new Mythread(); Thread t = new Thread(mt); //创建用户线程 t.start(); //启动用户线程 &#125;&#125;class Mythread implements Runnable&#123; public void run()&#123; // 实现线程业务处理逻辑 &#125;&#125; 至于哪个好，肯定是后者好，因为实现接口的方式比继承类的方式更灵活，也能减少程序之间的耦合度，是面向接口编程。 线程安全指在并发的情况之下，该代码经过多线程使用，线程的调度顺序不影响任何结果。 线程安全也是有几个级别的： 不可变 像String、Integer、Long这些，都是final类型的类，任何一个线程都改变不了它们的值，要改变除非新创建一个，因此这些不可变对象不需要任何同步手段就可以直接在多线程环境下使用。 绝对线程安全 不管运行时环境如何，调用者都不需要额外的同步措施。要做到这一点通常需要付出许多额外的代价，Java中标注自己是线程安全的类，实际上绝大多数都不是线程安全的，不过绝对线程安全的类，Java中也有，比方说CopyOnWriteArrayList、CopyOnWriteArraySet。 相对线程安全 相对线程安全也就是我们通常意义上所说的线程安全，像Vector这种，add、remove方法都是原子操作，不会被打断，但也仅限于此，如果有个线程在遍历某个Vector、有个线程同时在add这个Vector，99%的情况下都会出现ConcurrentModificationException，也就是fail-fast机制。 线程非安全 这个就没什么好说的了，ArrayList、LinkedList、HashMap等都是线程非安全的类。 锁的分类死锁：死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 锁的分类： 乐观锁&#x2F;悲观锁 独享锁&#x2F;共享锁 互斥锁&#x2F;读写锁 可重入锁 公平锁&#x2F;非公平锁 分段锁 偏向锁&#x2F;轻量级锁&#x2F;重量级锁 自旋锁 以上都是一些锁的名词，这些分类并不是完全指锁的状态，有的指锁的特性，有的指锁的设计，详见 Java锁的分类和使用。 线程同步 线程间通信： 多个线程处理同一个资源，需要线程间通信解决线程对资源的占用，避免对同一资源争夺。及引入等待唤醒机制（wait()，notify()） wait 方法：线程调用wait()方法，释放它对锁的拥有权，然后等待另外的线程来通知它（通知的方式是notify()或者notifyAll()方法），这样它才能重新获得锁的拥有权和恢复执行。要确保调用wait()方法的时候拥有锁，即wait()方法的调用必须放在synchronized方法或synchronized代码块中。 notify 方法：notify()方法会唤醒一个等待当前对象的锁的线程。唤醒在此对象监视器上等待的单个线程。 notifyAll 方法：notifyAll()方法会唤醒在此对象监视器上等待的所有线程。 线程间共享数据： 方式一：当每个线程执行的代码相同时，可以使用同一个Runnable对象 1234567891011121314151617181920public class MultiThreadShareData &#123; public static void main(String[] args) &#123; ShareData task = new ShareData(); //一个类实现了Runnable接口 for(int i = 0; i &lt; 4; i ++) &#123; //四个线程来卖票 new Thread(task).start(); &#125; &#125;&#125;class ShareData implements Runnable &#123; private int data = 100; @Override public void run() &#123; //卖票，每次一个线程进来，先判断票数是否大于0 synchronized(this) &#123; if(data &gt; 0) &#123; log.info(Thread.currentThread().getName() + &quot;: &quot; + data); data--; &#125; &#125; &#125;&#125; 方式二：若每个线程执行任务不同，可以将两个任务方法放到一个类中，然后将 data 也放在这个类中，然后传到不同的 Runnable 中，即可完成数据的共享。 1234567891011121314151617181920212223242526272829303132333435public class MultiThreadShareData &#123; public static void main(String[] args) &#123; ShareData task = new ShareData(); //公共数据和任务放在task中 for(int i = 0; i &lt; 2; i ++) &#123; //开启两个线程增加data new Thread(new Runnable() &#123; @Override public void run() &#123; task.increment(); &#125; &#125;).start(); &#125; for(int i = 0; i &lt; 2; i ++) &#123; //开启两个线程减少data new Thread(new Runnable() &#123; @Override public void run() &#123; task.decrement(); &#125; &#125;).start(); &#125; &#125;&#125;class ShareData implements Runnable &#123; private int data = 0; public synchronized void increment() &#123; //增加data log.info(Thread.currentThread().getName() + &quot;: before : &quot; + data); data++; log.info(Thread.currentThread().getName() + &quot;: after : &quot; + data); &#125; public synchronized void decrement() &#123; //减少data log.info(Thread.currentThread().getName() + &quot;: before : &quot; + data); data--; log.info(Thread.currentThread().getName() + &quot;: after : &quot; + data); &#125;&#125; 线程池避免频繁地创建和销毁线程带来性能开销，从而达到线程对象的重复利用。同时，使用线程池还可以根据项目灵活地控制并发线程的数量。 ThreadPoolExecutor 类 ThreadPoolExecutor 类是线程池中最核心的一个类，它提供了四个构造方法。 1234567891011121314151617181920212223242526272829303132333435363738public class ThreadPoolExecutor extends AbstractExecutorService &#123; /** *corePoolSize：核心池的大小 *maximumPoolSize：线程池最大线程数 *keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止 *unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性 * TimeUnit.DAYS; //天 * TimeUnit.HOURS; //小时 * TimeUnit.MINUTES; //分钟 * TimeUnit.SECONDS; //秒 * TimeUnit.MILLISECONDS; //毫秒 * TimeUnit.MICROSECONDS; //微妙 * TimeUnit.NANOSECONDS; //纳秒 *workQueue：一个阻塞队列，用来存储等待执行的任务 * ArrayBlockingQueue; * LinkedBlockingQueue; * SynchronousQueue; *threadFactory：线程工厂，主要用来创建线程 *handler：表示当拒绝处理任务时的策略，有以下四种取值 * ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 * ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 * ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） * ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 */ ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125; ThreadPoolExecutor的其他方法： 1）execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 2）submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看 submit() 方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果。 3）shutdown()和shutdownNow()是用来关闭线程池的。 4）还有很多其他的方法：比如：getQueue() 、getPoolSize() 、getActiveCount()、getCompletedTaskCount()等获取与线程池相关属性的方法。 线程池使用实例 创建线程池时，并不提倡直接使用ThreadPoolExcutor类创建，而是使用Executors类中的几个静态方法来创建。而通过Executors类的源码可以看出，其实Executors 类也是调用了ThreadPoolExcutor类来创建线程池的，比如： 1231 Executors.newCachedThreadPool(int Integer.MAX_VALUE); //创建一个缓冲池，缓冲池容量大小为2 Executors.newSingleThreadExecutor(); //创建容量为1的缓冲池3 Executors.newFixedThreadPool(); //创建固定容量大小的缓冲池 12345678910public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 使用示例： 1234567891011121314151617181920212223public class Test&#123; public static void main(String[] args)&#123; // 创建一个容量为5的线程池 ExecutorService executorService = Executors.newFixedThreadPool(5); // 向线程池提交一个任务（其实就是通过线程池来启动一个线程） for( int i = 0; i&lt;15; i++)&#123; executorService.execute(new Task()); log.info(&quot;================&quot;); &#125; executorService.shutdown(); &#125;&#125;class Task extends Thread&#123; @Override public void run()&#123; try&#123; Thread.sleep(1000); &#125;catch(InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 多线程常见问题 上下文切换 多线程并不一定是要在多核处理器才支持的，就算是单核也是可以支持多线程的。 CPU 通过给每个线程分配一定的时间片，由于时间非常短通常是几十毫秒，所以 CPU 可以不停的切换线程执行任务从而达到了多线程的效果。 但是由于在线程切换的时候需要保存本次执行的信息，在该线程被 CPU 剥夺时间片后又再次运行恢复上次所保存的信息的过程就称为上下文切换。上下文切换是非常耗效率的。 通常有以下解决方案: 采用无锁编程，比如将数据按照Hash(id)进行取模分段，每个线程处理各自分段的数据，从而避免使用锁。 采用 CAS (compare and swap) 算法，如Atomic包就是采用CAS算法。 合理的创建线程，避免创建了一些线程但其中大部分都是处于waiting状态，因为每当从waiting状态切换到running状态都是一次上下文切换。 死锁 死锁的场景一般是：线程 A 和线程 B 都在互相等待对方释放锁，或者是其中某个线程在释放锁的时候出现异常如死循环之类的。这时就会导致系统不可用。 常用的解决方案如下： 尽量一个线程只获取一个锁，一个线程只占用一个资源。 尝试使用定时锁，至少能保证锁最终会被释放。 所有线程按指定顺序获取锁。 资源限制 当在带宽有限的情况下一个线程下载某个资源需要 1M&#x2F;S，当开 10 个线程时速度并不会乘 10 倍，反而还会增加时间，毕竟上下文切换比较耗时。 如果是受限于资源的话可以采用集群来处理任务，不同的机器来处理不同的数据，就类似于开始提到的无锁编程。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Callable 和 Future/FutureTask","slug":"concurrency/Callable和Future配合","date":"2018-05-18T14:15:33.000Z","updated":"2024-02-14T09:52:19.066Z","comments":false,"path":"2018/05/18/concurrency/Callable和Future配合/","permalink":"https://imalan6.github.io/hexo_blog/2018/05/18/concurrency/Callable%E5%92%8CFuture%E9%85%8D%E5%90%88/","excerpt":"","text":"Callable 和 Future&#x2F;FutureTaskCallable 接口线程的创建方式中有两种，一种是实现Runnable接口，另一种是继承Thread类，但是这两种方式都有个缺点，那就是在任务执行完成之后无法获取返回结果，于是就有了Callable接口。Callable接口类似于Runnable接口，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，可以返回值，它可以和Future接口与FutureTask类的配合使用以取得线程运行返回的结果。 Runnable接口的run()方法返回值类型为void，所以无法获取结果。 123public interface Runnable &#123; public abstract void run(); &#125; 而Callable的接口定义如下： 123public interface Callable&lt;V&gt; &#123; V call() throws Exception; &#125; 该接口声明了一个名称为call()的方法，同时这个方法可以有返回值V，也可以抛出异常。 无论是Runnable接口还是Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行，ThreadPoolExecutor或ScheduledThreadPoolExecutor都实现了ExcutorService接口，而因此 Callable 需要和Executor框架中的ExcutorService结合使用。 ExecutorService提供的方法： 123&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); //提交一个实现了Callable接口的任务，并且返回封装了异步计算结果的Future对象。&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); //提交一个实现了Runnable接口的任务，指定了在调用Future的get方法时返回的result对象。（不常用）Future&lt;?&gt; submit(Runnable task); //提交一个实现了Runnable接口的任务，并且返回封装了异步计算结果的Future。 只要创建了Callable或者Runnable对象，然后通过上面 3 个方法提交给线程池执行即可。另外，除了我们自己实现Callable对象外，还可以使用工厂类Executors把一个Runnable对象封装成Callable对象。Executors工厂类提供的方法如下： 12public static Callable&lt;Object&gt; callable(Runnable task) public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) Future 接口Future&lt;V&gt;接口可以用来获取线程异步计算结果，还可以取消，判断线程任务是否完成等操作。Future接口代码如下： 12345678public interface Future &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; get()：获取异步执行的结果，如果没有结果可用，此方法会阻塞直到异步计算完成。 get(Long timeout , TimeUnit unit)：类似get()方法，但是会有等待时间限制，如果阻塞时间超过设定的timeout值，该方法将抛出异常。 isDone()：如果任务执行结束，无论是正常结束或是中途取消还是发生异常，都返回true。 isCancelled()：如果任务完成前被取消，则返回true。 cancel (boolean mayInterruptRunning)：如果任务还没开始，执行cancel()方法将返回false；如果任务已经启动，执行cancel(true)方法将以中断执行此任务线程的方式来试图停止任务，如果停止成功，返回true；当任务已经启动，执行cancel(false)方法将不会对正在执行的任务线程产生影响，此时返回false；当任务已经完成，执行cancel()方法将返回false。mayInterruptRunning参数表示是否中断执行中的线程。 FutureTask 类FutureTask是实现了Future和Runnable接口。实现了Runnable接口，说明可以把FutureTask实例传入到 Thread 中，在一个新的线程中执行。实现Future接口，说明可以从FutureTask中通过get取到任务的返回结果，也可以执行取消任务执行等操作。 FutureTask可用于异步获取执行结果或取消执行任务的场景。通过传入Runnable或者Callable的任务给FutureTask，直接调用其run方法或者放入线程池执行，之后可以在外部通过FutureTask的 get 方法异步获取执行结果，因此，FutureTask非常适合用于耗时的计算，主线程可以在完成自己的任务后，再去获取结果。另外，FutureTask还可以确保即使调用了多次run方法，它都只会执行一次Runnable或者Callable任务，或者通过cancel取消FutureTask的执行等。 使用实例 Callable 配合 Future 使用实例 Callable类任务实现代码 1234567891011121314public class Task implements Callable&lt;Integer&gt; &#123; private int sum; @Override public Integer call() throws Exception &#123; System.out.println(&quot;Callable子线程开始计算&quot;); for(int i=0 ;i&lt;100;i++)&#123; sum += i; &#125; System.out.println(&quot;Callable子线程计算结束&quot;); return sum; &#125; &#125; 测试代码 123456789101112131415161718192021222324252627282930public class CallableTest &#123; public static void main(String[] args) &#123; //创建线程池 ExecutorService es = Executors.newSingleThreadExecutor(); //提交任务并获取执行结果 Future&lt;Integer&gt; future = es.submit(new Task()); //关闭线程池，线程执行完才关闭 es.shutdown(); try &#123; Thread.sleep(1000); System.out.println(&quot;主线程在执行其他任务&quot;); if (future.get() != null) &#123; //输出获取到的结果 System.out.println(&quot;future.get()--&gt;&quot; + future.get()); &#125; else &#123; //输出获取到的结果 System.out.println(&quot;future.get()未获取到结果&quot;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;主线程在执行完成&quot;); &#125;&#125; 运行结果： 12345Callable子线程开始计算主线程在执行其他任务Callable子线程计算结束future.get()--&gt;4950主线程在执行完成 Callable 配合 FutureTask 使用实例 只需要对上述代码做部分改动即可 1234567891011121314//创建FutureTask FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Task()); //执行任务 es.submit(futureTask); // 获取返回结果 if(futureTask.get() != null)&#123; //输出获取到的结果 System.out.println(&quot;futureTask.get()--&gt;&quot; + futureTask.get()); &#125;else&#123; //输出获取到的结果 System.out.println(&quot;futureTask.get()未获取到结果&quot;); &#125;","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java 多线程三大核心","slug":"concurrency/多线程的三大核心","date":"2018-05-17T13:02:13.000Z","updated":"2024-02-14T09:52:48.707Z","comments":false,"path":"2018/05/17/concurrency/多线程的三大核心/","permalink":"https://imalan6.github.io/hexo_blog/2018/05/17/concurrency/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%B8%89%E5%A4%A7%E6%A0%B8%E5%BF%83/","excerpt":"","text":"Java 多线程三大核心原子性Java 的原子性就和数据库事务的原子性差不多，一个操作中要么全部执行成功或者失败。 JMM 只是保证了基本的原子性，但类似于 i++ 之类的操作，看似是原子操作，其实里面涉及到: 获取 i 的值。 自增。 再赋值给 i。 这三步操作，所以想要实现 i++ 这样的原子操作就需要用到 synchronized 或者是 lock 进行加锁处理。 如果是基础类的自增操作可以使用 AtomicInteger 这样的原子类来实现(其本质是利用了 CPU 级别的 的 CAS 指令来完成的)。 其中用的最多的方法就是: incrementAndGet() 以原子的方式自增。源码如下: 12345678public final long incrementAndGet() &#123; for (;;) &#123; long current = get(); long next = current + 1; if (compareAndSet(current, next)) return next; &#125; &#125; 首先是获得当前的值，然后自增 +1。接着则是最核心的 compareAndSet() 来进行原子更新。 123public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update); &#125; 其逻辑就是判断当前的值是否被更新过，是否等于 current，如果等于就说明没有更新过然后将当前的值更新为 next，如果不等于则返回false 进入循环，直到更新成功为止。 还有其中的 get() 方法也很关键，返回的是当前的值，当前值用了 volatile 关键词修饰，保证了内存可见性。 1private volatile int value; 可见性现代计算机中，由于 CPU 直接从主内存中读取数据的效率不高，所以都会对应的 CPU 高速缓存，先将主内存中的数据读取到缓存中，线程修改数据之后首先更新到缓存，之后才会更新到主内存。如果此时还没有将数据更新到主内存其他的线程此时来读取就是修改之前的数据。 如上图所示。 volatile 关键字就是用于保证内存可见性，当线程A更新了 volatile 修饰的变量时，它会立即刷新到主线程，并且将其余缓存中该变量的值清空，导致其余线程只能去主内存读取最新值。 使用 volatile 关键词修饰的变量每次读取都会得到最新的数据，不管哪个线程对这个变量的修改都会立即刷新到主内存。 synchronized和加锁也能能保证可见性，实现原理就是在释放锁之前其余线程是访问不到这个共享变量的。但是和 volatile 相比开销较大。 顺序性以下这段代码: 123int a = 100 ; //1int b = 200 ; //2int c = a + b ; //3 正常情况下的执行顺序应该是 1&gt;&gt;2&gt;&gt;3。但是有时 JVM 为了提高整体的效率会进行指令重排导致执行的顺序可能是 2&gt;&gt;1&gt;&gt;3。但是 JVM 也不能是什么都进行重排，是在保证最终结果和代码顺序执行结果一致的情况下才可能进行重排。 重排在单线程中不会出现问题，但在多线程中会出现数据不一致的问题。 Java 中可以使用 volatile 来保证顺序性，synchronized 和 lock 也可以来保证有序性，和保证原子性的方式一样，通过同一段时间只能一个线程访问来实现的。 除了通过 volatile 关键字显式的保证顺序之外， JVM 还通过 happen-before 原则来隐式的保证顺序性。 其中有一条就是适用于 volatile 关键字的，针对于 volatile 关键字的写操作肯定是在读操作之前，也就是说读取的值肯定是最新的。 volatile 的应用双重检查锁的单例模式可以用 volatile 实现一个双重检查锁的单例模式： 123456789101112131415161718public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 这里的 volatile 关键字主要是为了防止指令重排。如果不用 volatile ，singleton = new Singleton();，这段代码其实是分为三步： 分配内存空间。(1) 初始化对象。(2) 将 singleton 对象指向分配的内存地址。(3) 加上 volatile 是为了让以上的三步操作顺序执行，反之有可能第三步在第二步之前被执行就有可能导致某个线程拿到的单例对象还没有初始化，以致于使用报错。 控制停止线程的标记123456789101112131415private volatile boolean flag ;private void run()&#123; new Thread(new Runnable() &#123; @Override public void run() &#123; while (flag) &#123; doSomeThing(); &#125; &#125; &#125;);&#125;private void stop()&#123; flag = false ;&#125; 这里如果没有用 volatile 来修饰 flag ，就有可能其中一个线程调用了 stop()方法修改了 flag 的值并不会立即刷新到主内存中，导致这个循环并不会立即停止。 这里主要利用的是 volatile 的内存可见性。 总结一下: volatile 关键字只能保证可见性，顺序性，不能保证原子性。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Atomic 原子类","slug":"concurrency/Atomic原子类","date":"2018-05-16T13:03:59.000Z","updated":"2024-02-14T09:52:19.043Z","comments":false,"path":"2018/05/16/concurrency/Atomic原子类/","permalink":"https://imalan6.github.io/hexo_blog/2018/05/16/concurrency/Atomic%E5%8E%9F%E5%AD%90%E7%B1%BB/","excerpt":"","text":"Atomic 原子类线程不安全当多个线程访问统一资源时，如果没有做线程同步，可能造成线程不安全，导致数据出错。如下代码： 12345678910111213141516171819202122232425262728293031@Slf4jpublic class ThreadUnsafe &#123; // 用于计数的统计变量 private static int count = 0; // 线程数量 private static final int Thread_Count = 10; // 线程池 private static ExecutorService executorService = Executors.newCachedThreadPool(); // 初始化值和线程数一致 private static CountDownLatch downLatch = new CountDownLatch(Thread_Count); // 测试 public static void main(String[] args) throws Exception&#123; for (int i = 0; i &lt; Thread_Count; i++) &#123; executorService.execute(() -&gt; &#123; for (int j = 0; j &lt; 1000; j++) &#123; // 每个线程执行1000次++操作 count++; &#125; // 一个线程执行完 downLatch.countDown(); &#125;); &#125; // 等待所有线程执行完 downLatch.await(); log.info(&quot;count is &#123;&#125;&quot;, count); &#125;&#125; 当多个线程对count变量计数，每个线程加1000次，10个线程理想状态下是加10000次，但实际情况并非如此。 上面的代码执行5次后，打印出来的count值分别为 7130，8290，9370，8790，8132。从测试的结果看出，count的值并不是我们认为的10000次，而都是小于10000次。 之所以出现上面的结果就是因为count++操作并非原子的。它其实被分成了三步： 123tp1 = count; //1tp2 = tp1 + 1; //2count = tp2; //3 所以 ，如果有两个线程m和n要执行count++操作。如果是理想状态下，m和n线程依次执行，m先执行完后，n再执行，即m1 -&gt; m2 -&gt; m3 -&gt; n1 -&gt; n2 -&gt; n3，那么结果是没问题的。但是如果线程代码的执行顺序是m1 -&gt; n1 -&gt; m2 -&gt; n2 -&gt; m3 -&gt; n3，那么很明显结果就会出错，主要原因就是 volatile 关键字 文中提到的 java 内存模型关系。 而上面的测试结果也正是由于没有做线程同步，导致的线程在执行count++时，乱序执行后count的数值就不对了。 原子操作 使用 synchronized 实现线程同步 对上面的代码做一些改造，对count++操作加入synchronized关键字修饰，实现线程同步，以保证每个线程在执行count++时，必须执行完成后，另一个线程才开始执行的。代码如下： 1234567891011121314151617181920212223242526272829@Slf4jpublic class ThreadUnsafe &#123; // 用于计数的统计变量 private static int count = 0; // 线程数量 private static final int Thread_Count = 10; // 线程池 private static ExecutorService executorService = Executors.newCachedThreadPool(); // 初始化值和线程数一致 private static CountDownLatch downLatch = new CountDownLatch(Thread_Count); public static void main(String[] args) throws Exception&#123; for (int i = 0; i &lt; Thread_Count; i++) &#123; executorService.execute(() -&gt; &#123; for (int j = 0; j &lt; 1000; j++) &#123; // 每个线程执行1000次++操作 synchronized (ThreadUnsafe.class) &#123; count++; &#125; &#125; // 一个线程执行完 downLatch.countDown(); &#125;); &#125; // 等待所有线程执行完 downLatch.await(); log.info(&quot;count is &#123;&#125;&quot;, count); &#125;&#125; 将线程不安全的测试代码添加synchronized关键字进行线程同步，保证线程在执行count++操作时，是依次执行完后，后面的线程才开始执行的。synchronized关键字可以实现原子性和可见性。 将上面的代码执行5次后，打印出来的count值均为10000，已经是正确结果了。 原子类在JDK1.5中新增了java.util.concurrent(J.U.C)包，它建立在CAS之上。而CAS采用了乐观锁思路，是非阻塞算法的一种常实现，相对于synchronized这种阻塞算法，它的性能更好。 乐观锁与 CAS 在JDK5之前，Java 是靠synchronized关键字保证线程同步的，这会导致有锁，锁机制存在以下问题： 在多线程竞争下，加锁和释放锁会导致比较多的上下文切换和调度延时，引起性能问题； 一个线程持有锁后，会导致其他所有等待该锁的线程挂起； 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致线程优先级倒置，引起风险； 独占锁采用的是悲观锁思路。synchronized就是一种独占锁，它会导致其他所有需要锁的线程挂起。而另一种更加有效的锁就是乐观锁，CAS就是一种乐观锁。乐观锁，严格来说并不是锁。它是通过原子性来保证数据的同步，比如说数据库的乐观锁，通过版本控制mvcc来实现，所以CAS不会保证线程同步，只是乐观地认为在数据更新期间没有其他线程参与。 CAS是一种无锁算法。无锁编程，即在不使用锁的情况下实现多线程间的同步，也就是在没有线程被阻塞挂起的情况下实现变量的同步。 CAS算法即是：Compare And Swap,比较并替换。 CAS算法存在着三个参数，内存值V，期望值A，以及需要更新的值B。当且仅当内存值V和期望值A相等的时候，才会将内存值修改为B，否则什么也不做，继续循环检查; 由于CAS是CPU指令，我们只能通过JNI与操作系统交互，关于CAS的方法都在sun.misc包下Unsafe的类里，java.util.concurrent.atomic包下的原子类等通过CAS来实现原子操作。 CAS特点： CAS是原子操作，保证并发安全，而不能保证并发同步 CAS是 CPU 的一个指令（需要 JNI 调用 Native 方法，才能调用 CPU 的指令） CAS是非阻塞的、轻量级的乐观锁 AtomicInteger 实现 JDK提供了原子操作类，指的是java.util.concurrent.atomic包下，一系列以Atomic开头的包装类。例如AtomicBoolean，AtomicInteger，AtomicLong。它们分别用于Boolean，Integer，Long类型的原子性操作。以下是AtomicInteger部分源代码： 123456789101112131415static &#123; try &#123; //获取value属性值在内存中的地址偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1);&#125;public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125; AtomicInteger的getAndIncrement调用了Unsafe的getAndInt方法完成 +1 原子操作。Unsafe类的getAndInt方法源码如下： 1234567891011121314//var1是this指针，var2是地址偏移量，var4是自增值，是自增1还是自增Npublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; //获取内存值 var5 = this.getIntVolatile(var1, var2); //var5是期望值，var5 + var4是要更新的值 //这个操作就是调用CAS的JNI,每个线程将自己内存里的内存值与var5期望值E作比较，如果相同，就将内存值更新为var5 + var4，否则做自旋操作 var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 实现原子操作是基于compareAndSwapInt方法，更新前先取出内存值进行比较，和期望值一致后才更新。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"HashMap 底层分析","slug":"collections/HashMap","date":"2018-05-13T04:03:22.000Z","updated":"2024-02-14T09:43:29.569Z","comments":false,"path":"2018/05/13/collections/HashMap/","permalink":"https://imalan6.github.io/hexo_blog/2018/05/13/collections/HashMap/","excerpt":"","text":"HashMap 底层分析 以下基于 JDK1.7 分析。 如图所示，HashMap底层是基于数组和链表实现的。其中有两个重要的参数： 容量 负载因子 容量的默认大小是 16，负载因子是 0.75，当 HashMap 的 size &gt; 16*0.75 时就会发生扩容(容量和负载因子都可以自由调整)。 put 方法首先会将传入的 Key 做 hash 运算计算出 hashcode,然后根据数组长度取模计算出在数组中的 index 下标。 由于在计算中位运算比取模运算效率高的多，所以HashMap规定数组的长度为 2^n 。这样用 2^n - 1 做位运算与取模效果一致，并且效率还要高出许多。 由于数组的长度有限，所以难免会出现不同的Key通过运算得到的 index 相同，这种情况可以利用链表来解决，HashMap会在 table[index]处形成链表，采用头插法将数据插入到链表中。 get 方法get和put类似，也是将传入的Key计算出index ，如果该位置上是一个链表就需要遍历整个链表，通过 key.equals(k) 来找到对应的元素。 遍历方式12345Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; entryIterator = map.entrySet().iterator(); while (entryIterator.hasNext()) &#123; Map.Entry&lt;String, Integer&gt; next = entryIterator.next(); System.out.println(&quot;key=&quot; + next.getKey() + &quot; value=&quot; + next.getValue()); &#125; 123456Iterator&lt;String&gt; iterator = map.keySet().iterator(); while (iterator.hasNext())&#123; String key = iterator.next(); System.out.println(&quot;key=&quot; + key + &quot; value=&quot; + map.get(key)); &#125; 123map.forEach((key,value)-&gt;&#123; System.out.println(&quot;key=&quot; + key + &quot; value=&quot; + value);&#125;); 强烈建议使用第一种 EntrySet 进行遍历。 第一种可以把 key value 同时取出，第二种还得需要通过 key 取一次 value，效率较低, 第三种需要 JDK1.8 以上，通过外层遍历 table，内层遍历链表或红黑树。 notice在并发环境下使用 HashMap 容易出现死循环。 并发场景发生扩容，调用 resize() 方法里的 rehash() 时，容易出现环形链表。这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标时就会出现死循环。 所以 HashMap 只能在单线程中使用，并且尽量的预设容量，尽可能的减少扩容。 在 JDK1.8 中对 HashMap 进行了优化：当 hash 碰撞之后写入链表的长度超过了阈值(默认为8)并且 table 的长度不小于64(否则扩容一次)时，链表将会转换为红黑树。 假设 hash 冲突非常严重，一个数组后面接了很长的链表，此时重新的时间复杂度就是 O(n) 。 如果是红黑树，时间复杂度就是 O(logn) 。 大大提高了查询效率。 多线程场景下推荐使用ConcurrentHashMap。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"ArrayList/Vector 的底层分析","slug":"collections/ArrayList","date":"2018-05-12T07:59:59.000Z","updated":"2024-02-14T09:43:29.540Z","comments":false,"path":"2018/05/12/collections/ArrayList/","permalink":"https://imalan6.github.io/hexo_blog/2018/05/12/collections/ArrayList/","excerpt":"","text":"ArrayList&#x2F;Vector 的底层分析ArrayListArrayList 实现于 List、RandomAccess 接口。可以插入空数据，也支持随机访问。 ArrayList 相当于动态数据，其中最重要的两个属性分别是:elementData 数组，以及 size 大小。在调用 add() 方法的时候： 12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 首先进行扩容校验。 将插入的值放到尾部，并将 size + 1 。 如果是调用 add(index,e) 在指定位置添加的话： 12345678910public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //复制，向后移动 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 也是首先扩容校验。 接着对数据进行复制，目的是把 index 位置空出来放本次插入的数据，并将后面的数据向后移动一个位置。 其实扩容最终调用的代码: 1234567891011private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 也是一个数组复制的过程。 由此可见 ArrayList 的主要消耗是数组扩容以及在指定位置添加数据，在日常使用时最好是指定大小，尽量减少扩容。更要减少在指定位置插入数据的操作。 序列化由于 ArrayList 是基于动态数组实现的，所以并不是所有的空间都被使用。因此使用了 transient 修饰，可以防止被自动序列化。 1transient Object[] elementData; 因此 ArrayList 自定义了序列化与反序列化： 1234567891011121314151617181920212223242526272829303132333435363738394041private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. //只序列化了被使用的数据 for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125;private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125; 当对象中自定义了 writeObject 和 readObject 方法时，JVM 会调用这两个自定义方法来实现序列化与反序列化。 从实现中可以看出 ArrayList 只序列化了被使用的数据。 VectorVector 也是实现于 List 接口，底层数据结构和 ArrayList 类似,也是一个动态数组存放数据。不过是在 add() 方法的时候使用 synchronized 进行同步写数据，但是开销较大，所以 Vector 是一个同步容器并不是一个并发容器。 以下是 add() 方法： 123456public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125; 以及指定位置插入数据: 1234567891011121314public void add(int index, E element) &#123; insertElementAt(element, index);&#125;public synchronized void insertElementAt(E obj, int index) &#123; modCount++; if (index &gt; elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + &quot; &gt; &quot; + elementCount); &#125; ensureCapacityHelper(elementCount + 1); System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); elementData[index] = obj; elementCount++;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"}]},{"title":"CompareAndSet (CAS)","slug":"concurrency/CompareAndSet","date":"2018-03-12T05:03:06.000Z","updated":"2024-02-14T09:52:19.091Z","comments":false,"path":"2018/03/12/concurrency/CompareAndSet/","permalink":"https://imalan6.github.io/hexo_blog/2018/03/12/concurrency/CompareAndSet/","excerpt":"","text":"CompareAndSet (CAS)CAS 简介CAS：Compare and Swap, 翻译成比较并交换。java.util.concurrent（JUC）包中借助CAS实现了区别于synchronized同步锁的一种乐观锁，使用这些类在多核CPU 的机器上会有比较好的性能。 CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 我们针对AtomicInteger的incrementAndGet做深入分析。AtomicInteger类compareAndSet通过原子操作实现了CAS操作，最底层基于汇编语言实现。简单说一下原子操作的概念，“原子”代表最小的单位，所以原子操作可以看做最小的执行单位，该操作在执行完毕前不会被任何其他任务或事件打断。 CAS是Compare And Set的一个简称，如下理解： 已知当前内存里面的值current和预期要修改成的新值new传入 内存中AtomicInteger对象地址对应的真实值 (因为有可能被修改)real与current对比相等表示real未被修改过，是 “安全” 的，将new赋给real结束然后返回；不相等说明real已经被修改，结束并重新执行上一步直到修改成功。 CAS相比synchronized，避免了锁的使用，总体性能比synchronized高很多。 代码实例compareAndSet典型应用为计数，如i++，++i，这里以i++为例： 1234567891011121314151617/** * Atomically increments by one the current value. * * @return the updated value */public final int incrementAndGet() &#123; for (;;) &#123; //获取当前值 int current = get(); //设置期望值 int next = current + 1; //调用Native方法compareAndSet，执行CAS操作 if (compareAndSet(current, next)) //成功后才会返回期望值，否则无线循环 return next; &#125;&#125; compareAndSet方法实现： JDK文档对该方法的说明如下：如果当前状态值等于预期值，则以原子方式将同步状态设置为给定的更新值。 123public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 这里解释一下valueOffset变量，首先valueOffset的初始化在static静态代码块里面，代表相对起始内存地址的字节相对偏移量。 123456789101112131415161718192021222324private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; /** * Creates a new AtomicInteger with the given initial value. * * @param initialValue the initial value */ public AtomicInteger(int initialValue) &#123; value = initialValue; &#125; /** * Creates a new AtomicInteger with initial value &#123;@code 0&#125;. */ public AtomicInteger() &#123; &#125; 在生成一个AtomicInteger对象后，可以看做生成了一段内存，对象中各个字段按一定顺序放在这段内存中，字段可能不是连续放置的，unsafe.objectFieldOffset (Field f)这个方法返回了 “value“ 属性字段相对于AtomicInteger对象的起始内存地址的字节相对偏移量。value是一个volatile变量，不同线程对这个变量进行操作时具有可见性，修改与写入操作都会立即写入主存中，并通知其他cpu中该变量缓存无效，保证了每次读取的都是最新的值。 底层原理CAS通过调用JNI的代码实现的。JNI : Java Native Interface为JAVA本地调用，允许java调用其他语言。而compareAndSwapInt就是借助C来调用CPU底层指令实现的。 下面从分析比较常用的CPU（intel x86）来解释CAS的实现原理。sun.misc.Unsafe类的compareAndSwapInt()方法的源代码： 12345678910111213141516171819202122232425262728public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); //可以看到这是个本地方法调用。这个本地方法在openjdk中依次调用的c++代码为：unsafe.cpp，atomic.cpp和atomicwindowsx86.inline.hpp。//这个本地方法的最终实现在openjdk的如下位置：openjdk-7-fcs-src-b147-27jun2011\\openjdk\\hotspot\\src\\oscpu\\windowsx86\\vm\\ atomicwindowsx86.inline.hpp（对应于windows操作系统，X86处理器）。下面是对应于intel x86处理器的源代码的片段：// Adding a lock prefix to an instruction on MP machine// VC++ doesn&#x27;t like the lock prefix to be on a single line// so we can&#x27;t insert a label after the lock prefix.// By emitting a lock prefix, we can define a label after it.#define LOCK_IF_MP(mp) __asm cmp mp, 0 \\ __asm je L0 \\ __asm _emit 0xF0 \\ __asm L0:inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm &#123; mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx &#125;&#125; 如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略 lock 前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。 intel的手册对lock前缀的说明如下： 确保对内存的读-改-写操作原子执行。在Pentium及Pentium之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其他处理器暂时无法通过总线访问内存。很显然，这会带来昂贵的开销。从Pentium 4，Intel Xeon及P6处理器开始，intel在原有总线锁的基础上做了一个很有意义的优化：如果要访问的内存区域（area of memory）在lock前缀指令执行期间已经在处理器内部的缓存中被锁定（即包含该内存区域的缓存行当前处于独占或以修改状态），并且该内存区域被完全包含在单个缓存行（cache line）中，那么处理器将直接执行该指令。由于在指令执行期间该缓存行会一直被锁定，其它处理器无法读&#x2F;写该指令要访问的内存区域，因此能保证指令执行的原子性。这个操作过程叫做缓存锁定（cache locking），缓存锁定将大大降低lock前缀指令的执行开销，但是当多处理器之间的竞争程度很高或者指令访问的内存地址未对齐时，仍然会锁住总线。 禁止该指令与之前和之后的读和写指令重排序。 把写缓冲区中的所有数据刷新到内存中。 总的来说，Atomic实现了高效无锁（底层还是用到排它锁，不过底层处理比java层处理要快很多) 与线程安全 (volatile变量特性)，CAS一般适用于计数；多线程编程也适用，多个线程执行AtomicXXX类下面的方法，当某个线程执行的时候具有排他性，在执行方法中不会被打断，直至当前线程完成才会执行其他的线程。 相关问题CAS虽然很高效的解决原子操作，但是CAS仍然存在如下三大问题： ABA 问题。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么 A－B－A就会变成1A - 2B－3A，而1A和3A肯定是不一样的。从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。关于ABA问题参考文档: http://blog.hesey.net/2011/09/resolve-aba-by-atomicstampedreference.html 循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2, j = a，合并一下ij = 2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。","categories":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]}],"categories":[{"name":"python","slug":"python","permalink":"https://imalan6.github.io/hexo_blog/categories/python/"},{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/"},{"name":"消息中间件","slug":"消息中间件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"开源组件","slug":"开源组件","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/"},{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/categories/jvm/"},{"name":"微服务","slug":"微服务","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"网络安全","slug":"docker/网络安全","permalink":"https://imalan6.github.io/hexo_blog/categories/docker/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"数据库","slug":"数据库","permalink":"https://imalan6.github.io/hexo_blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"分布式","slug":"分布式","permalink":"https://imalan6.github.io/hexo_blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/categories/redis/"},{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/categories/java/"}],"tags":[{"name":"python","slug":"python","permalink":"https://imalan6.github.io/hexo_blog/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%88%AC%E8%99%AB/"},{"name":"docker","slug":"docker","permalink":"https://imalan6.github.io/hexo_blog/tags/docker/"},{"name":"kafka","slug":"kafka","permalink":"https://imalan6.github.io/hexo_blog/tags/kafka/"},{"name":"nginx","slug":"nginx","permalink":"https://imalan6.github.io/hexo_blog/tags/nginx/"},{"name":"jvm","slug":"jvm","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm/"},{"name":"srpingcloud","slug":"srpingcloud","permalink":"https://imalan6.github.io/hexo_blog/tags/srpingcloud/"},{"name":"链路追踪","slug":"链路追踪","permalink":"https://imalan6.github.io/hexo_blog/tags/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"name":"熔断","slug":"熔断","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%86%94%E6%96%AD/"},{"name":"网关","slug":"网关","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BD%91%E5%85%B3/"},{"name":"服务注册","slug":"服务注册","permalink":"https://imalan6.github.io/hexo_blog/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C/"},{"name":"监控","slug":"监控","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%9B%91%E6%8E%A7/"},{"name":"故障排查","slug":"故障排查","permalink":"https://imalan6.github.io/hexo_blog/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"},{"name":"jvm调优","slug":"jvm调优","permalink":"https://imalan6.github.io/hexo_blog/tags/jvm%E8%B0%83%E4%BC%98/"},{"name":"springboot","slug":"springboot","permalink":"https://imalan6.github.io/hexo_blog/tags/springboot/"},{"name":"netty","slug":"netty","permalink":"https://imalan6.github.io/hexo_blog/tags/netty/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://imalan6.github.io/hexo_blog/tags/rabbitmq/"},{"name":"ssl证书","slug":"ssl证书","permalink":"https://imalan6.github.io/hexo_blog/tags/ssl%E8%AF%81%E4%B9%A6/"},{"name":"https","slug":"https","permalink":"https://imalan6.github.io/hexo_blog/tags/https/"},{"name":"网络安全","slug":"网络安全","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"nexus","slug":"nexus","permalink":"https://imalan6.github.io/hexo_blog/tags/nexus/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"mysql","slug":"mysql","permalink":"https://imalan6.github.io/hexo_blog/tags/mysql/"},{"name":"redis","slug":"redis","permalink":"https://imalan6.github.io/hexo_blog/tags/redis/"},{"name":"elk","slug":"elk","permalink":"https://imalan6.github.io/hexo_blog/tags/elk/"},{"name":"分布式限流","slug":"分布式限流","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81/"},{"name":"分布式锁","slug":"分布式锁","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"缓存","slug":"缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E7%BC%93%E5%AD%98/"},{"name":"分布式缓存","slug":"分布式缓存","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"name":"分布式id","slug":"分布式id","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%88%86%E5%B8%83%E5%BC%8Fid/"},{"name":"java","slug":"java","permalink":"https://imalan6.github.io/hexo_blog/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://imalan6.github.io/hexo_blog/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]}